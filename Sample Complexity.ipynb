{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"QupgVmcZgvyx","executionInfo":{"status":"ok","timestamp":1698908543878,"user_tz":420,"elapsed":3,"user":{"displayName":"Wentinn Liao","userId":"16122904268462266963"}}},"outputs":[],"source":["## Created by Wentinn Liao"]},{"cell_type":"markdown","metadata":{"id":"k722vkzdWafR"},"source":["# Kalman Filter Research"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"S27iMYAOuWiB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698908599204,"user_tz":420,"elapsed":55329,"user":{"displayName":"Wentinn Liao","userId":"16122904268462266963"}},"outputId":"2756c260-b1b5-49d4-b162-916853e9a6a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["#@title Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"0xHh9PF6hl3R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698908599205,"user_tz":420,"elapsed":7,"user":{"displayName":"Wentinn Liao","userId":"16122904268462266963"}},"outputId":"cfffe6b7-b8f8-4ffc-c674-784b7009c71c"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/KF_RNN\n"]}],"source":["#@title Symlink Setup\n","import os\n","\n","def ptpp(PATH: str) -> str: # Converts path to python path\n","    return PATH.replace('\\\\', '')\n","\n","DRIVE_PATH = '/content/gdrive/My\\ Drive/KF_RNN'\n","if not os.path.exists(ptpp(DRIVE_PATH)):\n","    %mkdir $DRIVE_PATH\n","SYM_PATH = '/content/KF_RNN'\n","if not os.path.exists(ptpp(SYM_PATH)):\n","    !ln -s $DRIVE_PATH $SYM_PATH\n","%cd $SYM_PATH"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"-h7SwLD3uWiC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698908720977,"user_tz":420,"elapsed":121775,"user":{"displayName":"Wentinn Liao","userId":"16122904268462266963"}},"outputId":"358f886a-6802-4813-b323-840933039c5a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.31.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Collecting torch==2.0.0\n","  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensordict\n","  Downloading tensordict-0.2.1-cp310-cp310-manylinux1_x86_64.whl (986 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m986.5/986.5 kB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1.2)\n","Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n","  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m120.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n","  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n","  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n","  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n","  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n","  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting triton==2.0.0 (from torch==2.0.0)\n","  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (67.7.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.41.2)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0) (3.27.7)\n","Collecting lit (from triton==2.0.0->torch==2.0.0)\n","  Downloading lit-17.0.4.tar.gz (153 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.1/153.1 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio) (9.4.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.43.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.3)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from tensordict) (2.2.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n","Building wheels for collected packages: lit\n","  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lit: filename=lit-17.0.4-py3-none-any.whl size=93257 sha256=127baef3eff9a8992c9e3ef013cfa0743341c9d54a6aea30e8a28be4cd1b67d7\n","  Stored in directory: /root/.cache/pip/wheels/be/ae/00/696c57d438bfc7c0e89c4c379083ea08b1c2e54d85a5f7cd7c\n","Successfully built lit\n","Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, tensordict\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.1.0\n","    Uninstalling triton-2.1.0:\n","      Successfully uninstalled triton-2.1.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.1.0+cu118\n","    Uninstalling torch-2.1.0+cu118:\n","      Successfully uninstalled torch-2.1.0+cu118\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.0.0 which is incompatible.\n","torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.0 which is incompatible.\n","torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.0 which is incompatible.\n","torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed lit-17.0.4 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 tensordict-0.2.1 torch-2.0.0 triton-2.0.0\n"]}],"source":["!pip install numpy imageio matplotlib scikit-learn torch==2.0.0 tensordict"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"9pbdKYaruWiD","executionInfo":{"status":"ok","timestamp":1698908720977,"user_tz":420,"elapsed":4,"user":{"displayName":"Wentinn Liao","userId":"16122904268462266963"}}},"outputs":[],"source":["#@title Configure Jupyter Notebook\n","import matplotlib\n","%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"uK2SmUy3uWiD","executionInfo":{"status":"ok","timestamp":1698908728330,"user_tz":420,"elapsed":7356,"user":{"displayName":"Wentinn Liao","userId":"16122904268462266963"}}},"outputs":[],"source":["#@title Library Setup\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from typing import *\n","from argparse import Namespace\n","import copy\n","import itertools\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as Fn\n","import torch.utils as ptu\n","import tensordict\n","from tensordict import TensorDict\n","\n","from model.linear_system import LinearSystem\n","from model.kf import KF\n","from model.rnn_kf import RnnKF\n","\n","from infrastructure import utils\n","from infrastructure.train import *\n","\n","# seed = 7\n","# torch.manual_seed(seed)\n","# random.seed(seed)\n","torch.set_default_dtype(torch.double)\n","\n","dev_type = 'cuda'\n","if dev_type == 'xla':\n","    !pip install torch-xla cloud-tpu-client https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl\n","    import torch_xla\n","    import torch_xla.core.xla_model as xm\n","\n","plt.rcParams['figure.figsize'] = (7.0, 5.0) # set default size of plots\n","plt.rcParams['image.interpolation'] = 'nearest'\n","plt.rcParams['image.cmap'] = 'gray'"]},{"cell_type":"markdown","metadata":{"id":"Zi9Hzsb9ndKp"},"source":["# Sample Complexity"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"pQ5I3Zj7slTY","executionInfo":{"status":"ok","timestamp":1698908728330,"user_tz":420,"elapsed":7,"user":{"displayName":"Wentinn Liao","userId":"16122904268462266963"}}},"outputs":[],"source":["#@title Model Parameters\n","ModelArgs = Namespace(\n","    S_D = 6,\n","    I_D = 6,\n","    O_D = 4,\n","    SNR = 2.\n",")"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"6Y8dOrQZLUF8","executionInfo":{"status":"ok","timestamp":1698908728331,"user_tz":420,"elapsed":6,"user":{"displayName":"Wentinn Liao","userId":"16122904268462266963"}}},"outputs":[],"source":["#@title Training Parameters\n","\n","total_trace_lengths = sorted(set(torch.ceil(torch.pow(2, torch.arange(7., 12.5, 0.5))).to(int).tolist()))\n","num_traces = sorted(set(torch.ceil(torch.pow(2, torch.arange(0., 6.5, 0.5))).to(int).tolist()))\n","\n","BaseTrainArgs = Namespace(\n","    # Dataset\n","    train_dataset_size = num_traces,\n","    valid_dataset_size = 100,\n","    total_train_sequence_length = total_trace_lengths,\n","    total_valid_sequence_length = 20000,\n","\n","    # Batch sampling\n","    subsequence_length = 10,\n","    subsequence_initial_mode = \"random\",    # {\"random\", \"replay_buffer\"}\n","    sample_efficiency = 5,\n","    replay_buffer = 10,\n","    batch_size = 128,\n","\n","    # Optimizer\n","    beta = 0.1,\n","    lr = 3e-4,\n","    momentum = 0.9,\n","    lr_decay = 0.99,\n","    optim_type = \"Adam\",                    # {\"GD\", \"SGD\", \"SGDMomentum\", \"Adam\"}\n","    l2_reg = 0.1,\n","\n","    # Iteration\n","    iterations_per_epoch = 100,\n","    epochs = 20\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"uB91NPDbt1Uw","executionInfo":{"status":"ok","timestamp":1698908728331,"user_tz":420,"elapsed":6,"user":{"displayName":"Wentinn Liao","userId":"16122904268462266963"}}},"outputs":[],"source":["#@title Experiment Parameters\n","BaseExperimentArgs = Namespace(\n","    n_systems = 16,\n","    ensemble_size = 1,\n","    log_frequency = 5,\n","    print_frequency = 20\n",")"]},{"cell_type":"code","source":["#@title Experiment Configurations\n","base_exp_name = 'SC'\n","output_dir = 'sample_complexity'\n","output_fname = 'result'\n","\n","optim_configs = [\n","    ('SGDMomentum', {\n","        'lr': 2e-4\n","    }),\n","    ('Adam', {\n","        'lr': 2e-2\n","    }),\n","    ('GD', {\n","        'lr': 2e-4\n","    }),\n","]\n","system_configs = [\n","    ('', dict())\n","]\n","\n","result = {}\n","for (optim_config_name, optim_config), (system_config_name, system_config) in itertools.product(\n","    optim_configs,\n","    system_configs\n","):\n","    TrainArgs = copy.copy(BaseTrainArgs)\n","    TrainArgs.__dict__.update(optim_config)\n","    TrainArgs.optim_type = optim_config_name\n","\n","    ExperimentArgs = copy.copy(BaseExperimentArgs)\n","    ExperimentArgs.exp_name = f'Full{system_config_name}{optim_config_name}{base_exp_name}'\n","    ExperimentArgs.output_dir = output_dir\n","\n","    Args = Namespace(\n","        model = ModelArgs,\n","        train = TrainArgs,\n","        experiment = ExperimentArgs\n","    )\n","\n","    result[optim_config_name, system_config_name] = run_experiments(\n","        Args,\n","        ['total_train_sequence_length', 'train_dataset_size'],\n","        dev_type,\n","        system_kwargs=system_config,\n","        output_kwargs={'fname': output_fname}\n","    )[0]"],"metadata":{"id":"fRwnxK3zYJW1","colab":{"base_uri":"https://localhost:8080/"},"outputId":"14a06645-7ce1-44de-eb75-a465962d1297"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["========================================================================================================================================================================================================\n","FullSGDMomentumSC\n","========================================================================================================================================================================================================\n","Hyperparameters: {\n","    \"model\": {\n","        \"S_D\": 6,\n","        \"I_D\": 6,\n","        \"O_D\": 4,\n","        \"SNR\": 2.0\n","    },\n","    \"train\": {\n","        \"train_dataset_size\": [\n","            1,\n","            2,\n","            3,\n","            4,\n","            6,\n","            8,\n","            12,\n","            16,\n","            23,\n","            32,\n","            46,\n","            64\n","        ],\n","        \"valid_dataset_size\": 100,\n","        \"total_train_sequence_length\": [\n","            128,\n","            182,\n","            256,\n","            363,\n","            512,\n","            725,\n","            1024,\n","            1449,\n","            2048,\n","            2897,\n","            4096\n","        ],\n","        \"total_valid_sequence_length\": 20000,\n","        \"subsequence_length\": 10,\n","        \"subsequence_initial_mode\": \"random\",\n","        \"sample_efficiency\": 5,\n","        \"replay_buffer\": 10,\n","        \"batch_size\": 128,\n","        \"beta\": 0.1,\n","        \"lr\": 0.0002,\n","        \"momentum\": 0.9,\n","        \"lr_decay\": 0.99,\n","        \"optim_type\": \"SGDMomentum\",\n","        \"l2_reg\": 0.1,\n","        \"iterations_per_epoch\": 100,\n","        \"epochs\": 20\n","    },\n","    \"experiment\": {\n","        \"n_systems\": 16,\n","        \"ensemble_size\": 1,\n","        \"log_frequency\": 5,\n","        \"print_frequency\": 20,\n","        \"exp_name\": \"FullSGDMomentumSC\",\n","        \"output_dir\": \"sample_complexity\"\n","    }\n","}\n","========================================================================================================================================================================================================\n","FullAdamSC\n","========================================================================================================================================================================================================\n","Hyperparameters: {\n","    \"model\": {\n","        \"S_D\": 6,\n","        \"I_D\": 6,\n","        \"O_D\": 4,\n","        \"SNR\": 2.0\n","    },\n","    \"train\": {\n","        \"train_dataset_size\": [\n","            1,\n","            2,\n","            3,\n","            4,\n","            6,\n","            8,\n","            12,\n","            16,\n","            23,\n","            32,\n","            46,\n","            64\n","        ],\n","        \"valid_dataset_size\": 100,\n","        \"total_train_sequence_length\": [\n","            128,\n","            182,\n","            256,\n","            363,\n","            512,\n","            725,\n","            1024,\n","            1449,\n","            2048,\n","            2897,\n","            4096\n","        ],\n","        \"total_valid_sequence_length\": 20000,\n","        \"subsequence_length\": 10,\n","        \"subsequence_initial_mode\": \"random\",\n","        \"sample_efficiency\": 5,\n","        \"replay_buffer\": 10,\n","        \"batch_size\": 128,\n","        \"beta\": 0.1,\n","        \"lr\": 0.02,\n","        \"momentum\": 0.9,\n","        \"lr_decay\": 0.99,\n","        \"optim_type\": \"Adam\",\n","        \"l2_reg\": 0.1,\n","        \"iterations_per_epoch\": 100,\n","        \"epochs\": 20\n","    },\n","    \"experiment\": {\n","        \"n_systems\": 16,\n","        \"ensemble_size\": 1,\n","        \"log_frequency\": 5,\n","        \"print_frequency\": 20,\n","        \"exp_name\": \"FullAdamSC\",\n","        \"output_dir\": \"sample_complexity\"\n","    }\n","}\n","========================================================================================================================================================================================================\n","FullGDSC\n","========================================================================================================================================================================================================\n","Hyperparameters: {\n","    \"model\": {\n","        \"S_D\": 6,\n","        \"I_D\": 6,\n","        \"O_D\": 4,\n","        \"SNR\": 2.0\n","    },\n","    \"train\": {\n","        \"train_dataset_size\": [\n","            1,\n","            2,\n","            3,\n","            4,\n","            6,\n","            8,\n","            12,\n","            16,\n","            23,\n","            32,\n","            46,\n","            64\n","        ],\n","        \"valid_dataset_size\": 100,\n","        \"total_train_sequence_length\": [\n","            128,\n","            182,\n","            256,\n","            363,\n","            512,\n","            725,\n","            1024,\n","            1449,\n","            2048,\n","            2897,\n","            4096\n","        ],\n","        \"total_valid_sequence_length\": 20000,\n","        \"subsequence_length\": 10,\n","        \"subsequence_initial_mode\": \"random\",\n","        \"sample_efficiency\": 5,\n","        \"replay_buffer\": 10,\n","        \"batch_size\": 128,\n","        \"beta\": 0.1,\n","        \"lr\": 0.0002,\n","        \"momentum\": 0.9,\n","        \"lr_decay\": 0.99,\n","        \"optim_type\": \"GD\",\n","        \"l2_reg\": 0.1,\n","        \"iterations_per_epoch\": 100,\n","        \"epochs\": 20\n","    },\n","    \"experiment\": {\n","        \"n_systems\": 16,\n","        \"ensemble_size\": 1,\n","        \"log_frequency\": 5,\n","        \"print_frequency\": 20,\n","        \"exp_name\": \"FullGDSC\",\n","        \"output_dir\": \"sample_complexity\"\n","    }\n","}\n","========================================================================================================================================================================================================\n","FullGDSC\n","========================================================================================================================================================================================================\n","Hyperparameters: {\n","    \"model\": {\n","        \"S_D\": 6,\n","        \"I_D\": 6,\n","        \"O_D\": 4,\n","        \"SNR\": 2.0\n","    },\n","    \"train\": {\n","        \"train_dataset_size\": 2,\n","        \"valid_dataset_size\": 100,\n","        \"total_train_sequence_length\": 2048,\n","        \"total_valid_sequence_length\": 20000,\n","        \"subsequence_length\": 10,\n","        \"subsequence_initial_mode\": \"random\",\n","        \"sample_efficiency\": 5,\n","        \"replay_buffer\": 10,\n","        \"batch_size\": 128,\n","        \"beta\": 0.1,\n","        \"lr\": 0.0002,\n","        \"momentum\": 0.9,\n","        \"lr_decay\": 0.99,\n","        \"optim_type\": \"GD\",\n","        \"l2_reg\": 0.1,\n","        \"iterations_per_epoch\": 100,\n","        \"epochs\": 20\n","    },\n","    \"experiment\": {\n","        \"n_systems\": 16,\n","        \"ensemble_size\": 1,\n","        \"log_frequency\": 5,\n","        \"print_frequency\": 20,\n","        \"exp_name\": \"FullGDSC\",\n","        \"output_dir\": \"sample_complexity\"\n","    }\n","}\n","========================================================================================================================================================================================================\n","Mean theoretical irreducible loss: 39.52325662304027\n","Epoch 1 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 224.253786, Overfit loss: 222.893269, Valid loss: 220.735414, Divergences: 0  [    0/  200]\n","\tTrain loss: 209.716057, Overfit loss: 209.192059, Valid loss: 207.567248, Divergences: 0  [   40/  200]\n","\tTrain loss: 200.359594, Overfit loss: 199.938162, Valid loss: 198.646363, Divergences: 0  [   80/  200]\n","\tTrain loss: 192.329477, Overfit loss: 191.955240, Valid loss: 190.893459, Divergences: 0  [  120/  200]\n","\tTrain loss: 185.308624, Overfit loss: 184.977706, Valid loss: 184.099999, Divergences: 0  [  160/  200]\n","Epoch 2 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 179.166778, Overfit loss: 178.878056, Valid loss: 178.148930, Divergences: 0  [    0/  200]\n","\tTrain loss: 173.547714, Overfit loss: 173.281456, Valid loss: 172.676320, Divergences: 0  [   40/  200]\n","\tTrain loss: 168.192396, Overfit loss: 167.922090, Valid loss: 167.423997, Divergences: 0  [   80/  200]\n","\tTrain loss: 162.953847, Overfit loss: 162.693721, Valid loss: 162.292071, Divergences: 0  [  120/  200]\n","\tTrain loss: 157.792754, Overfit loss: 157.547332, Valid loss: 157.238681, Divergences: 0  [  160/  200]\n","Epoch 3 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 152.678519, Overfit loss: 152.424946, Valid loss: 152.221789, Divergences: 0  [    0/  200]\n","\tTrain loss: 147.658537, Overfit loss: 147.395354, Valid loss: 147.280791, Divergences: 0  [   40/  200]\n","\tTrain loss: 142.653322, Overfit loss: 142.391976, Valid loss: 142.340698, Divergences: 0  [   80/  200]\n","\tTrain loss: 137.649710, Overfit loss: 137.422505, Valid loss: 137.406079, Divergences: 0  [  120/  200]\n","\tTrain loss: 132.694216, Overfit loss: 132.456162, Valid loss: 132.493651, Divergences: 0  [  160/  200]\n","Epoch 4 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 127.775945, Overfit loss: 127.541363, Valid loss: 127.608294, Divergences: 0  [    0/  200]\n","\tTrain loss: 122.969766, Overfit loss: 122.726701, Valid loss: 122.823581, Divergences: 0  [   40/  200]\n","\tTrain loss: 118.242697, Overfit loss: 118.011037, Valid loss: 118.114136, Divergences: 0  [   80/  200]\n","\tTrain loss: 113.627710, Overfit loss: 113.405227, Valid loss: 113.513753, Divergences: 0  [  120/  200]\n","\tTrain loss: 109.155498, Overfit loss: 108.931639, Valid loss: 109.060141, Divergences: 0  [  160/  200]\n","Epoch 5 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 104.846369, Overfit loss: 104.643890, Valid loss: 104.768089, Divergences: 0  [    0/  200]\n","\tTrain loss: 100.786196, Overfit loss: 100.584522, Valid loss: 100.719995, Divergences: 0  [   40/  200]\n","\tTrain loss: 96.905979, Overfit loss: 96.739495, Valid loss: 96.877218, Divergences: 0  [   80/  200]\n","\tTrain loss: 93.265337, Overfit loss: 93.106720, Valid loss: 93.271519, Divergences: 0  [  120/  200]\n","\tTrain loss: 89.867896, Overfit loss: 89.688496, Valid loss: 89.885012, Divergences: 0  [  160/  200]\n","Epoch 6 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 86.656939, Overfit loss: 86.506069, Valid loss: 86.729252, Divergences: 0  [    0/  200]\n","\tTrain loss: 83.689444, Overfit loss: 83.554156, Valid loss: 83.795115, Divergences: 0  [   40/  200]\n","\tTrain loss: 80.921444, Overfit loss: 80.795043, Valid loss: 81.060744, Divergences: 0  [   80/  200]\n","\tTrain loss: 78.329334, Overfit loss: 78.204520, Valid loss: 78.531450, Divergences: 0  [  120/  200]\n","\tTrain loss: 75.923040, Overfit loss: 75.810344, Valid loss: 76.148698, Divergences: 0  [  160/  200]\n","Epoch 7 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 73.685412, Overfit loss: 73.577776, Valid loss: 73.953680, Divergences: 0  [    0/  200]\n","\tTrain loss: 71.629392, Overfit loss: 71.519975, Valid loss: 71.941537, Divergences: 0  [   40/  200]\n","\tTrain loss: 69.722273, Overfit loss: 69.634246, Valid loss: 70.086287, Divergences: 0  [   80/  200]\n","\tTrain loss: 67.981362, Overfit loss: 67.888136, Valid loss: 68.366041, Divergences: 0  [  120/  200]\n","\tTrain loss: 66.370360, Overfit loss: 66.289498, Valid loss: 66.792367, Divergences: 0  [  160/  200]\n","Epoch 8 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 64.899836, Overfit loss: 64.828682, Valid loss: 65.342059, Divergences: 0  [    0/  200]\n","\tTrain loss: 63.544668, Overfit loss: 63.485042, Valid loss: 64.029282, Divergences: 0  [   40/  200]\n","\tTrain loss: 62.323924, Overfit loss: 62.253659, Valid loss: 62.812084, Divergences: 0  [   80/  200]\n","\tTrain loss: 61.163998, Overfit loss: 61.110991, Valid loss: 61.687479, Divergences: 0  [  120/  200]\n","\tTrain loss: 60.108080, Overfit loss: 60.062078, Valid loss: 60.651991, Divergences: 0  [  160/  200]\n","Epoch 9 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 59.125366, Overfit loss: 59.084896, Valid loss: 59.686732, Divergences: 0  [    0/  200]\n","\tTrain loss: 58.225308, Overfit loss: 58.182290, Valid loss: 58.797993, Divergences: 0  [   40/  200]\n","\tTrain loss: 57.382795, Overfit loss: 57.353949, Valid loss: 57.968572, Divergences: 0  [   80/  200]\n","\tTrain loss: 56.595684, Overfit loss: 56.577248, Valid loss: 57.199258, Divergences: 0  [  120/  200]\n","\tTrain loss: 55.870107, Overfit loss: 55.840784, Valid loss: 56.479025, Divergences: 0  [  160/  200]\n","Epoch 10 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 55.189776, Overfit loss: 55.160253, Valid loss: 55.811462, Divergences: 0  [    0/  200]\n","\tTrain loss: 54.556682, Overfit loss: 54.525324, Valid loss: 55.183895, Divergences: 0  [   40/  200]\n","\tTrain loss: 53.970202, Overfit loss: 53.935495, Valid loss: 54.589112, Divergences: 0  [   80/  200]\n","\tTrain loss: 53.411741, Overfit loss: 53.376497, Valid loss: 54.044892, Divergences: 0  [  120/  200]\n","\tTrain loss: 52.871896, Overfit loss: 52.851083, Valid loss: 53.530266, Divergences: 0  [  160/  200]\n","Epoch 11 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 52.397151, Overfit loss: 52.377343, Valid loss: 53.039327, Divergences: 0  [    0/  200]\n","\tTrain loss: 51.926334, Overfit loss: 51.917093, Valid loss: 52.574048, Divergences: 0  [   40/  200]\n","\tTrain loss: 51.501655, Overfit loss: 51.469780, Valid loss: 52.145380, Divergences: 0  [   80/  200]\n","\tTrain loss: 51.087120, Overfit loss: 51.064441, Valid loss: 51.727463, Divergences: 0  [  120/  200]\n","\tTrain loss: 50.703929, Overfit loss: 50.681027, Valid loss: 51.345310, Divergences: 0  [  160/  200]\n","Epoch 12 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 50.326543, Overfit loss: 50.304598, Valid loss: 50.972468, Divergences: 0  [    0/  200]\n","\tTrain loss: 49.987626, Overfit loss: 49.967157, Valid loss: 50.633360, Divergences: 0  [   40/  200]\n","\tTrain loss: 49.645502, Overfit loss: 49.640672, Valid loss: 50.307109, Divergences: 0  [   80/  200]\n","\tTrain loss: 49.350908, Overfit loss: 49.327990, Valid loss: 49.985343, Divergences: 0  [  120/  200]\n","\tTrain loss: 49.044944, Overfit loss: 49.018964, Valid loss: 49.679162, Divergences: 0  [  160/  200]\n","Epoch 13 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 48.757605, Overfit loss: 48.755567, Valid loss: 49.398582, Divergences: 0  [    0/  200]\n","\tTrain loss: 48.480392, Overfit loss: 48.461975, Valid loss: 49.117453, Divergences: 0  [   40/  200]\n","\tTrain loss: 48.228132, Overfit loss: 48.217184, Valid loss: 48.863541, Divergences: 0  [   80/  200]\n","\tTrain loss: 47.975008, Overfit loss: 47.964026, Valid loss: 48.613958, Divergences: 0  [  120/  200]\n","\tTrain loss: 47.745268, Overfit loss: 47.725798, Valid loss: 48.379760, Divergences: 0  [  160/  200]\n","Epoch 14 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 47.517498, Overfit loss: 47.494163, Valid loss: 48.149391, Divergences: 0  [    0/  200]\n","\tTrain loss: 47.298877, Overfit loss: 47.288345, Valid loss: 47.931216, Divergences: 0  [   40/  200]\n","\tTrain loss: 47.093428, Overfit loss: 47.084346, Valid loss: 47.720648, Divergences: 0  [   80/  200]\n","\tTrain loss: 46.905998, Overfit loss: 46.886370, Valid loss: 47.532973, Divergences: 0  [  120/  200]\n","\tTrain loss: 46.712430, Overfit loss: 46.690950, Valid loss: 47.338816, Divergences: 0  [  160/  200]\n","Epoch 15 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 46.524997, Overfit loss: 46.520166, Valid loss: 47.157479, Divergences: 0  [    0/  200]\n","\tTrain loss: 46.354485, Overfit loss: 46.335024, Valid loss: 46.985115, Divergences: 0  [   40/  200]\n","\tTrain loss: 46.191883, Overfit loss: 46.184706, Valid loss: 46.812670, Divergences: 0  [   80/  200]\n","\tTrain loss: 46.027080, Overfit loss: 46.018775, Valid loss: 46.654171, Divergences: 0  [  120/  200]\n","\tTrain loss: 45.875341, Overfit loss: 45.865801, Valid loss: 46.512928, Divergences: 0  [  160/  200]\n","Epoch 16 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 45.732895, Overfit loss: 45.728824, Valid loss: 46.355574, Divergences: 0  [    0/  200]\n","\tTrain loss: 45.585654, Overfit loss: 45.587491, Valid loss: 46.210842, Divergences: 0  [   40/  200]\n","\tTrain loss: 45.447697, Overfit loss: 45.444320, Valid loss: 46.077734, Divergences: 0  [   80/  200]\n","\tTrain loss: 45.322026, Overfit loss: 45.318533, Valid loss: 45.948075, Divergences: 0  [  120/  200]\n","\tTrain loss: 45.192111, Overfit loss: 45.193430, Valid loss: 45.829976, Divergences: 0  [  160/  200]\n","Epoch 17 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 45.081205, Overfit loss: 45.080729, Valid loss: 45.710238, Divergences: 0  [    0/  200]\n","\tTrain loss: 44.954389, Overfit loss: 44.954388, Valid loss: 45.589445, Divergences: 0  [   40/  200]\n","\tTrain loss: 44.859362, Overfit loss: 44.854984, Valid loss: 45.486978, Divergences: 0  [   80/  200]\n","\tTrain loss: 44.739757, Overfit loss: 44.739327, Valid loss: 45.371437, Divergences: 0  [  120/  200]\n","\tTrain loss: 44.638860, Overfit loss: 44.645587, Valid loss: 45.278631, Divergences: 0  [  160/  200]\n","Epoch 18 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 44.540632, Overfit loss: 44.539684, Valid loss: 45.180031, Divergences: 0  [    0/  200]\n","\tTrain loss: 44.440996, Overfit loss: 44.437710, Valid loss: 45.083746, Divergences: 0  [   40/  200]\n","\tTrain loss: 44.360297, Overfit loss: 44.346807, Valid loss: 44.991341, Divergences: 0  [   80/  200]\n","\tTrain loss: 44.271540, Overfit loss: 44.277204, Valid loss: 44.908547, Divergences: 0  [  120/  200]\n","\tTrain loss: 44.178741, Overfit loss: 44.178353, Valid loss: 44.818883, Divergences: 0  [  160/  200]\n","Epoch 19 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 44.109677, Overfit loss: 44.106474, Valid loss: 44.743725, Divergences: 0  [    0/  200]\n","\tTrain loss: 44.014273, Overfit loss: 44.022519, Valid loss: 44.662768, Divergences: 0  [   40/  200]\n","\tTrain loss: 43.955998, Overfit loss: 43.937925, Valid loss: 44.590516, Divergences: 0  [   80/  200]\n","\tTrain loss: 43.873125, Overfit loss: 43.867210, Valid loss: 44.509304, Divergences: 0  [  120/  200]\n","\tTrain loss: 43.788799, Overfit loss: 43.797953, Valid loss: 44.448293, Divergences: 0  [  160/  200]\n","Epoch 20 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 43.733296, Overfit loss: 43.724885, Valid loss: 44.370177, Divergences: 0  [    0/  200]\n","\tTrain loss: 43.659860, Overfit loss: 43.656856, Valid loss: 44.314775, Divergences: 0  [   40/  200]\n","\tTrain loss: 43.586848, Overfit loss: 43.590843, Valid loss: 44.247095, Divergences: 0  [   80/  200]\n","\tTrain loss: 43.546622, Overfit loss: 43.541152, Valid loss: 44.199191, Divergences: 0  [  120/  200]\n","\tTrain loss: 43.469273, Overfit loss: 43.468350, Valid loss: 44.131187, Divergences: 0  [  160/  200]\n","\n","========================================================================================================================================================================================================\n","FullGDSC\n","========================================================================================================================================================================================================\n","Hyperparameters: {\n","    \"model\": {\n","        \"S_D\": 6,\n","        \"I_D\": 6,\n","        \"O_D\": 4,\n","        \"SNR\": 2.0\n","    },\n","    \"train\": {\n","        \"train_dataset_size\": 3,\n","        \"valid_dataset_size\": 100,\n","        \"total_train_sequence_length\": 2048,\n","        \"total_valid_sequence_length\": 20000,\n","        \"subsequence_length\": 10,\n","        \"subsequence_initial_mode\": \"random\",\n","        \"sample_efficiency\": 5,\n","        \"replay_buffer\": 10,\n","        \"batch_size\": 128,\n","        \"beta\": 0.1,\n","        \"lr\": 0.0002,\n","        \"momentum\": 0.9,\n","        \"lr_decay\": 0.99,\n","        \"optim_type\": \"GD\",\n","        \"l2_reg\": 0.1,\n","        \"iterations_per_epoch\": 100,\n","        \"epochs\": 20\n","    },\n","    \"experiment\": {\n","        \"n_systems\": 16,\n","        \"ensemble_size\": 1,\n","        \"log_frequency\": 5,\n","        \"print_frequency\": 20,\n","        \"exp_name\": \"FullGDSC\",\n","        \"output_dir\": \"sample_complexity\"\n","    }\n","}\n","========================================================================================================================================================================================================\n","Mean theoretical irreducible loss: 40.140550446680265\n","Epoch 1 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 284.732824, Overfit loss: 282.199490, Valid loss: 278.278121, Divergences: 0  [    0/  300]\n","\tTrain loss: 247.546161, Overfit loss: 245.533500, Valid loss: 243.961059, Divergences: 0  [   60/  300]\n","\tTrain loss: 225.352247, Overfit loss: 224.656775, Valid loss: 224.349864, Divergences: 0  [  120/  300]\n","\tTrain loss: 212.975017, Overfit loss: 212.410058, Valid loss: 212.452727, Divergences: 0  [  180/  300]\n","\tTrain loss: 203.065161, Overfit loss: 202.629086, Valid loss: 202.939338, Divergences: 0  [  240/  300]\n","Epoch 2 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 194.534992, Overfit loss: 194.125283, Valid loss: 194.585566, Divergences: 0  [    0/  300]\n","\tTrain loss: 186.668939, Overfit loss: 186.275493, Valid loss: 186.828823, Divergences: 0  [   60/  300]\n","\tTrain loss: 179.172091, Overfit loss: 178.806320, Valid loss: 179.434016, Divergences: 0  [  120/  300]\n","\tTrain loss: 172.036496, Overfit loss: 171.691384, Valid loss: 172.392976, Divergences: 0  [  180/  300]\n","\tTrain loss: 165.178273, Overfit loss: 164.842063, Valid loss: 165.632861, Divergences: 0  [  240/  300]\n","Epoch 3 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 158.551729, Overfit loss: 158.228340, Valid loss: 159.060880, Divergences: 0  [    0/  300]\n","\tTrain loss: 152.161909, Overfit loss: 151.850838, Valid loss: 152.732625, Divergences: 0  [   60/  300]\n","\tTrain loss: 145.945472, Overfit loss: 145.653241, Valid loss: 146.557783, Divergences: 0  [  120/  300]\n","\tTrain loss: 139.964639, Overfit loss: 139.689489, Valid loss: 140.594734, Divergences: 0  [  180/  300]\n","\tTrain loss: 134.230734, Overfit loss: 133.938351, Valid loss: 134.895696, Divergences: 0  [  240/  300]\n","Epoch 4 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 128.753799, Overfit loss: 128.510636, Valid loss: 129.459483, Divergences: 0  [    0/  300]\n","\tTrain loss: 123.643740, Overfit loss: 123.409816, Valid loss: 124.347226, Divergences: 0  [   60/  300]\n","\tTrain loss: 118.800199, Overfit loss: 118.577917, Valid loss: 119.530357, Divergences: 0  [  120/  300]\n","\tTrain loss: 114.227009, Overfit loss: 114.020922, Valid loss: 114.955883, Divergences: 0  [  180/  300]\n","\tTrain loss: 110.408074, Overfit loss: 110.067682, Valid loss: 110.930668, Divergences: 0  [  240/  300]\n","Epoch 5 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 106.017194, Overfit loss: 105.792731, Valid loss: 106.716986, Divergences: 0  [    0/  300]\n","\tTrain loss: 102.335566, Overfit loss: 102.140306, Valid loss: 103.028155, Divergences: 0  [   60/  300]\n","\tTrain loss: 98.817379, Overfit loss: 98.622496, Valid loss: 99.514599, Divergences: 0  [  120/  300]\n","\tTrain loss: 95.547948, Overfit loss: 95.379142, Valid loss: 96.258033, Divergences: 0  [  180/  300]\n","\tTrain loss: 92.520817, Overfit loss: 92.338335, Valid loss: 93.212593, Divergences: 0  [  240/  300]\n","Epoch 6 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 89.690106, Overfit loss: 89.516424, Valid loss: 90.383101, Divergences: 0  [    0/  300]\n","\tTrain loss: 87.062218, Overfit loss: 86.926239, Valid loss: 87.768195, Divergences: 0  [   60/  300]\n","\tTrain loss: 84.624192, Overfit loss: 84.490242, Valid loss: 85.350430, Divergences: 0  [  120/  300]\n","\tTrain loss: 82.363891, Overfit loss: 82.233566, Valid loss: 83.100929, Divergences: 0  [  180/  300]\n","\tTrain loss: 80.253887, Overfit loss: 80.136959, Valid loss: 80.993878, Divergences: 0  [  240/  300]\n","Epoch 7 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 78.313563, Overfit loss: 78.169217, Valid loss: 79.040022, Divergences: 0  [    0/  300]\n","\tTrain loss: 76.471288, Overfit loss: 76.379291, Valid loss: 77.228950, Divergences: 0  [   60/  300]\n","\tTrain loss: 74.811886, Overfit loss: 74.701501, Valid loss: 75.556892, Divergences: 0  [  120/  300]\n","\tTrain loss: 73.231014, Overfit loss: 73.139488, Valid loss: 74.002281, Divergences: 0  [  180/  300]\n","\tTrain loss: 71.775907, Overfit loss: 71.678235, Valid loss: 72.550584, Divergences: 0  [  240/  300]\n","Epoch 8 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 70.418731, Overfit loss: 70.328253, Valid loss: 71.194620, Divergences: 0  [    0/  300]\n","\tTrain loss: 69.159432, Overfit loss: 69.078681, Valid loss: 69.948402, Divergences: 0  [   60/  300]\n","\tTrain loss: 67.985541, Overfit loss: 67.919876, Valid loss: 68.795538, Divergences: 0  [  120/  300]\n","\tTrain loss: 66.894488, Overfit loss: 66.840496, Valid loss: 67.709532, Divergences: 0  [  180/  300]\n","\tTrain loss: 65.878178, Overfit loss: 65.827200, Valid loss: 66.694792, Divergences: 0  [  240/  300]\n","Epoch 9 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 64.942916, Overfit loss: 64.883808, Valid loss: 65.756414, Divergences: 0  [    0/  300]\n","\tTrain loss: 64.045022, Overfit loss: 63.996720, Valid loss: 64.871349, Divergences: 0  [   60/  300]\n","\tTrain loss: 63.220352, Overfit loss: 63.170645, Valid loss: 64.050484, Divergences: 0  [  120/  300]\n","\tTrain loss: 62.449077, Overfit loss: 62.405296, Valid loss: 63.291888, Divergences: 0  [  180/  300]\n","\tTrain loss: 61.710144, Overfit loss: 61.675882, Valid loss: 62.554208, Divergences: 0  [  240/  300]\n","Epoch 10 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 61.044057, Overfit loss: 61.003456, Valid loss: 61.880171, Divergences: 0  [    0/  300]\n","\tTrain loss: 60.402690, Overfit loss: 60.363645, Valid loss: 61.247344, Divergences: 0  [   60/  300]\n","\tTrain loss: 59.792560, Overfit loss: 59.776821, Valid loss: 60.652631, Divergences: 0  [  120/  300]\n","\tTrain loss: 59.233309, Overfit loss: 59.201955, Valid loss: 60.080865, Divergences: 0  [  180/  300]\n","\tTrain loss: 58.680650, Overfit loss: 58.673218, Valid loss: 59.541877, Divergences: 0  [  240/  300]\n","Epoch 11 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 58.185444, Overfit loss: 58.141944, Valid loss: 59.026947, Divergences: 0  [    0/  300]\n","\tTrain loss: 57.682543, Overfit loss: 57.673410, Valid loss: 58.544792, Divergences: 0  [   60/  300]\n","\tTrain loss: 57.216949, Overfit loss: 57.189711, Valid loss: 58.071276, Divergences: 0  [  120/  300]\n","\tTrain loss: 56.768219, Overfit loss: 56.740588, Valid loss: 57.624703, Divergences: 0  [  180/  300]\n","\tTrain loss: 56.321677, Overfit loss: 56.320881, Valid loss: 57.199278, Divergences: 0  [  240/  300]\n","Epoch 12 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 55.915500, Overfit loss: 55.906460, Valid loss: 56.774778, Divergences: 0  [    0/  300]\n","\tTrain loss: 55.515005, Overfit loss: 55.501947, Valid loss: 56.371535, Divergences: 0  [   60/  300]\n","\tTrain loss: 55.128453, Overfit loss: 55.115337, Valid loss: 55.988244, Divergences: 0  [  120/  300]\n","\tTrain loss: 54.760025, Overfit loss: 54.751971, Valid loss: 55.608187, Divergences: 0  [  180/  300]\n","\tTrain loss: 54.393988, Overfit loss: 54.380816, Valid loss: 55.256537, Divergences: 0  [  240/  300]\n","Epoch 13 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 54.038815, Overfit loss: 54.023499, Valid loss: 54.880158, Divergences: 0  [    0/  300]\n","\tTrain loss: 53.693091, Overfit loss: 53.684441, Valid loss: 54.544111, Divergences: 0  [   60/  300]\n","\tTrain loss: 53.379239, Overfit loss: 53.350515, Valid loss: 54.217564, Divergences: 0  [  120/  300]\n","\tTrain loss: 53.037688, Overfit loss: 53.036623, Valid loss: 53.890994, Divergences: 0  [  180/  300]\n","\tTrain loss: 52.740769, Overfit loss: 52.719735, Valid loss: 53.576986, Divergences: 0  [  240/  300]\n","Epoch 14 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 52.438892, Overfit loss: 52.412337, Valid loss: 53.262305, Divergences: 0  [    0/  300]\n","\tTrain loss: 52.135123, Overfit loss: 52.125073, Valid loss: 52.970961, Divergences: 0  [   60/  300]\n","\tTrain loss: 51.843168, Overfit loss: 51.858055, Valid loss: 52.681882, Divergences: 0  [  120/  300]\n","\tTrain loss: 51.574498, Overfit loss: 51.549166, Valid loss: 52.401608, Divergences: 0  [  180/  300]\n","\tTrain loss: 51.290951, Overfit loss: 51.272262, Valid loss: 52.132247, Divergences: 0  [  240/  300]\n","Epoch 15 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 51.041172, Overfit loss: 51.042121, Valid loss: 51.848024, Divergences: 0  [    0/  300]\n","\tTrain loss: 50.788315, Overfit loss: 50.770968, Valid loss: 51.603066, Divergences: 0  [   60/  300]\n","\tTrain loss: 50.527559, Overfit loss: 50.514166, Valid loss: 51.354387, Divergences: 0  [  120/  300]\n","\tTrain loss: 50.286105, Overfit loss: 50.291987, Valid loss: 51.106531, Divergences: 0  [  180/  300]\n","\tTrain loss: 50.042110, Overfit loss: 50.041917, Valid loss: 50.862632, Divergences: 0  [  240/  300]\n","Epoch 16 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 49.817218, Overfit loss: 49.816017, Valid loss: 50.641208, Divergences: 0  [    0/  300]\n","\tTrain loss: 49.608845, Overfit loss: 49.598007, Valid loss: 50.416250, Divergences: 0  [   60/  300]\n","\tTrain loss: 49.379137, Overfit loss: 49.389157, Valid loss: 50.209345, Divergences: 0  [  120/  300]\n","\tTrain loss: 49.186708, Overfit loss: 49.171258, Valid loss: 49.990851, Divergences: 0  [  180/  300]\n","\tTrain loss: 48.980853, Overfit loss: 48.975963, Valid loss: 49.796739, Divergences: 0  [  240/  300]\n","Epoch 17 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 48.781989, Overfit loss: 48.769552, Valid loss: 49.593294, Divergences: 0  [    0/  300]\n","\tTrain loss: 48.593128, Overfit loss: 48.582791, Valid loss: 49.396931, Divergences: 0  [   60/  300]\n","\tTrain loss: 48.414942, Overfit loss: 48.428837, Valid loss: 49.216332, Divergences: 0  [  120/  300]\n","\tTrain loss: 48.238248, Overfit loss: 48.226743, Valid loss: 49.038628, Divergences: 0  [  180/  300]\n","\tTrain loss: 48.063053, Overfit loss: 48.060488, Valid loss: 48.872054, Divergences: 0  [  240/  300]\n","Epoch 18 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 47.898112, Overfit loss: 47.873964, Valid loss: 48.700148, Divergences: 0  [    0/  300]\n","\tTrain loss: 47.735486, Overfit loss: 47.725710, Valid loss: 48.542446, Divergences: 0  [   60/  300]\n","\tTrain loss: 47.574619, Overfit loss: 47.576029, Valid loss: 48.380611, Divergences: 0  [  120/  300]\n","\tTrain loss: 47.429380, Overfit loss: 47.423342, Valid loss: 48.233975, Divergences: 0  [  180/  300]\n","\tTrain loss: 47.291583, Overfit loss: 47.274593, Valid loss: 48.071894, Divergences: 0  [  240/  300]\n","Epoch 19 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 47.152006, Overfit loss: 47.146991, Valid loss: 47.940973, Divergences: 0  [    0/  300]\n","\tTrain loss: 47.007200, Overfit loss: 47.006781, Valid loss: 47.810514, Divergences: 0  [   60/  300]\n","\tTrain loss: 46.878466, Overfit loss: 46.866839, Valid loss: 47.669732, Divergences: 0  [  120/  300]\n","\tTrain loss: 46.747557, Overfit loss: 46.745805, Valid loss: 47.541094, Divergences: 0  [  180/  300]\n","\tTrain loss: 46.625804, Overfit loss: 46.622985, Valid loss: 47.414510, Divergences: 0  [  240/  300]\n","Epoch 20 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 46.520623, Overfit loss: 46.515224, Valid loss: 47.301629, Divergences: 0  [    0/  300]\n","\tTrain loss: 46.395632, Overfit loss: 46.388266, Valid loss: 47.185986, Divergences: 0  [   60/  300]\n","\tTrain loss: 46.294665, Overfit loss: 46.283234, Valid loss: 47.075112, Divergences: 0  [  120/  300]\n","\tTrain loss: 46.171631, Overfit loss: 46.172563, Valid loss: 46.967777, Divergences: 0  [  180/  300]\n","\tTrain loss: 46.080175, Overfit loss: 46.065736, Valid loss: 46.854224, Divergences: 0  [  240/  300]\n","\n","========================================================================================================================================================================================================\n","FullGDSC\n","========================================================================================================================================================================================================\n","Hyperparameters: {\n","    \"model\": {\n","        \"S_D\": 6,\n","        \"I_D\": 6,\n","        \"O_D\": 4,\n","        \"SNR\": 2.0\n","    },\n","    \"train\": {\n","        \"train_dataset_size\": 4,\n","        \"valid_dataset_size\": 100,\n","        \"total_train_sequence_length\": 2048,\n","        \"total_valid_sequence_length\": 20000,\n","        \"subsequence_length\": 10,\n","        \"subsequence_initial_mode\": \"random\",\n","        \"sample_efficiency\": 5,\n","        \"replay_buffer\": 10,\n","        \"batch_size\": 128,\n","        \"beta\": 0.1,\n","        \"lr\": 0.0002,\n","        \"momentum\": 0.9,\n","        \"lr_decay\": 0.99,\n","        \"optim_type\": \"GD\",\n","        \"l2_reg\": 0.1,\n","        \"iterations_per_epoch\": 100,\n","        \"epochs\": 20\n","    },\n","    \"experiment\": {\n","        \"n_systems\": 16,\n","        \"ensemble_size\": 1,\n","        \"log_frequency\": 5,\n","        \"print_frequency\": 20,\n","        \"exp_name\": \"FullGDSC\",\n","        \"output_dir\": \"sample_complexity\"\n","    }\n","}\n","========================================================================================================================================================================================================\n","Mean theoretical irreducible loss: 42.76500640982262\n","Epoch 1 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 334.140676, Overfit loss: 325.378474, Valid loss: 324.523209, Divergences: 0  [    0/  400]\n","\tTrain loss: 266.333263, Overfit loss: 265.255193, Valid loss: 266.484607, Divergences: 0  [   80/  400]\n","\tTrain loss: 248.887843, Overfit loss: 248.165427, Valid loss: 249.703653, Divergences: 0  [  160/  400]\n","\tTrain loss: 235.346152, Overfit loss: 234.710127, Valid loss: 236.349851, Divergences: 0  [  240/  400]\n","\tTrain loss: 222.984706, Overfit loss: 222.414758, Valid loss: 224.182585, Divergences: 0  [  320/  400]\n","Epoch 2 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 212.224756, Overfit loss: 211.741444, Valid loss: 213.684196, Divergences: 0  [    0/  400]\n","\tTrain loss: 202.922505, Overfit loss: 202.482085, Valid loss: 204.479653, Divergences: 0  [   80/  400]\n","\tTrain loss: 194.174931, Overfit loss: 193.766756, Valid loss: 195.799187, Divergences: 0  [  160/  400]\n","\tTrain loss: 185.752416, Overfit loss: 185.348579, Valid loss: 187.399870, Divergences: 0  [  240/  400]\n","\tTrain loss: 177.519224, Overfit loss: 177.091533, Valid loss: 179.172401, Divergences: 0  [  320/  400]\n","Epoch 3 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 169.421393, Overfit loss: 169.004901, Valid loss: 171.095205, Divergences: 0  [    0/  400]\n","\tTrain loss: 161.513342, Overfit loss: 161.122170, Valid loss: 163.236725, Divergences: 0  [   80/  400]\n","\tTrain loss: 153.800777, Overfit loss: 153.423400, Valid loss: 155.553072, Divergences: 0  [  160/  400]\n","\tTrain loss: 146.305348, Overfit loss: 145.946027, Valid loss: 148.088804, Divergences: 0  [  240/  400]\n","\tTrain loss: 139.110541, Overfit loss: 138.746289, Valid loss: 140.901246, Divergences: 0  [  320/  400]\n","Epoch 4 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 132.253726, Overfit loss: 131.918051, Valid loss: 134.074383, Divergences: 0  [    0/  400]\n","\tTrain loss: 125.905883, Overfit loss: 125.586553, Valid loss: 127.705727, Divergences: 0  [   80/  400]\n","\tTrain loss: 119.928422, Overfit loss: 119.667204, Valid loss: 121.767934, Divergences: 0  [  160/  400]\n","\tTrain loss: 114.456619, Overfit loss: 114.184200, Valid loss: 116.242733, Divergences: 0  [  240/  400]\n","\tTrain loss: 109.386752, Overfit loss: 109.137083, Valid loss: 111.149459, Divergences: 0  [  320/  400]\n","Epoch 5 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 104.713739, Overfit loss: 104.495296, Valid loss: 106.457485, Divergences: 0  [    0/  400]\n","\tTrain loss: 100.484397, Overfit loss: 100.297029, Valid loss: 102.221856, Divergences: 0  [   80/  400]\n","\tTrain loss: 96.673596, Overfit loss: 96.487351, Valid loss: 98.359940, Divergences: 0  [  160/  400]\n","\tTrain loss: 93.175123, Overfit loss: 93.033109, Valid loss: 94.853144, Divergences: 0  [  240/  400]\n","\tTrain loss: 90.047144, Overfit loss: 89.870734, Valid loss: 91.654091, Divergences: 0  [  320/  400]\n","Epoch 6 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 87.164110, Overfit loss: 87.040982, Valid loss: 88.760402, Divergences: 0  [    0/  400]\n","\tTrain loss: 84.567928, Overfit loss: 84.457551, Valid loss: 86.151440, Divergences: 0  [   80/  400]\n","\tTrain loss: 82.206957, Overfit loss: 82.086919, Valid loss: 83.752345, Divergences: 0  [  160/  400]\n","\tTrain loss: 80.008605, Overfit loss: 79.902467, Valid loss: 81.527919, Divergences: 0  [  240/  400]\n","\tTrain loss: 78.003094, Overfit loss: 77.910866, Valid loss: 79.493706, Divergences: 0  [  320/  400]\n","Epoch 7 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 76.145034, Overfit loss: 76.051671, Valid loss: 77.605786, Divergences: 0  [    0/  400]\n","\tTrain loss: 74.406992, Overfit loss: 74.334584, Valid loss: 75.862469, Divergences: 0  [   80/  400]\n","\tTrain loss: 72.834680, Overfit loss: 72.737331, Valid loss: 74.241512, Divergences: 0  [  160/  400]\n","\tTrain loss: 71.329128, Overfit loss: 71.291706, Valid loss: 72.719250, Divergences: 0  [  240/  400]\n","\tTrain loss: 69.971998, Overfit loss: 69.888761, Valid loss: 71.308364, Divergences: 0  [  320/  400]\n","Epoch 8 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 68.656050, Overfit loss: 68.604027, Valid loss: 69.986476, Divergences: 0  [    0/  400]\n","\tTrain loss: 67.467836, Overfit loss: 67.423123, Valid loss: 68.760918, Divergences: 0  [   80/  400]\n","\tTrain loss: 66.351210, Overfit loss: 66.295471, Valid loss: 67.621394, Divergences: 0  [  160/  400]\n","\tTrain loss: 65.290604, Overfit loss: 65.253391, Valid loss: 66.536618, Divergences: 0  [  240/  400]\n","\tTrain loss: 64.310307, Overfit loss: 64.263559, Valid loss: 65.521754, Divergences: 0  [  320/  400]\n","Epoch 9 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 63.388716, Overfit loss: 63.341405, Valid loss: 64.566428, Divergences: 0  [    0/  400]\n","\tTrain loss: 62.524111, Overfit loss: 62.473423, Valid loss: 63.677470, Divergences: 0  [   80/  400]\n","\tTrain loss: 61.701805, Overfit loss: 61.628050, Valid loss: 62.841289, Divergences: 0  [  160/  400]\n","\tTrain loss: 60.923789, Overfit loss: 60.878443, Valid loss: 62.036795, Divergences: 0  [  240/  400]\n","\tTrain loss: 60.195706, Overfit loss: 60.163187, Valid loss: 61.290596, Divergences: 0  [  320/  400]\n","Epoch 10 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 59.507220, Overfit loss: 59.477775, Valid loss: 60.598677, Divergences: 0  [    0/  400]\n","\tTrain loss: 58.876478, Overfit loss: 58.842565, Valid loss: 59.927542, Divergences: 0  [   80/  400]\n","\tTrain loss: 58.258955, Overfit loss: 58.237086, Valid loss: 59.307778, Divergences: 0  [  160/  400]\n","\tTrain loss: 57.665245, Overfit loss: 57.681338, Valid loss: 58.715116, Divergences: 0  [  240/  400]\n","\tTrain loss: 57.150474, Overfit loss: 57.127214, Valid loss: 58.161065, Divergences: 0  [  320/  400]\n","Epoch 11 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 56.643388, Overfit loss: 56.630278, Valid loss: 57.646784, Divergences: 0  [    0/  400]\n","\tTrain loss: 56.152841, Overfit loss: 56.128507, Valid loss: 57.159157, Divergences: 0  [   80/  400]\n","\tTrain loss: 55.710723, Overfit loss: 55.711484, Valid loss: 56.691374, Divergences: 0  [  160/  400]\n","\tTrain loss: 55.286842, Overfit loss: 55.280753, Valid loss: 56.238902, Divergences: 0  [  240/  400]\n","\tTrain loss: 54.884502, Overfit loss: 54.869826, Valid loss: 55.824354, Divergences: 0  [  320/  400]\n","Epoch 12 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 54.507495, Overfit loss: 54.474933, Valid loss: 55.428627, Divergences: 0  [    0/  400]\n","\tTrain loss: 54.161334, Overfit loss: 54.125622, Valid loss: 55.055880, Divergences: 0  [   80/  400]\n","\tTrain loss: 53.779568, Overfit loss: 53.750133, Valid loss: 54.696042, Divergences: 0  [  160/  400]\n","\tTrain loss: 53.492347, Overfit loss: 53.455818, Valid loss: 54.351820, Divergences: 0  [  240/  400]\n","\tTrain loss: 53.137806, Overfit loss: 53.115968, Valid loss: 54.032810, Divergences: 0  [  320/  400]\n","Epoch 13 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 52.861965, Overfit loss: 52.840447, Valid loss: 53.724815, Divergences: 0  [    0/  400]\n","\tTrain loss: 52.582005, Overfit loss: 52.558301, Valid loss: 53.418645, Divergences: 0  [   80/  400]\n","\tTrain loss: 52.301319, Overfit loss: 52.307155, Valid loss: 53.160552, Divergences: 0  [  160/  400]\n","\tTrain loss: 52.046721, Overfit loss: 52.007311, Valid loss: 52.861524, Divergences: 0  [  240/  400]\n","\tTrain loss: 51.785977, Overfit loss: 51.750984, Valid loss: 52.608622, Divergences: 0  [  320/  400]\n","Epoch 14 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 51.537239, Overfit loss: 51.512769, Valid loss: 52.360434, Divergences: 0  [    0/  400]\n","\tTrain loss: 51.297752, Overfit loss: 51.278628, Valid loss: 52.110932, Divergences: 0  [   80/  400]\n","\tTrain loss: 51.084040, Overfit loss: 51.073204, Valid loss: 51.890128, Divergences: 0  [  160/  400]\n","\tTrain loss: 50.857058, Overfit loss: 50.833147, Valid loss: 51.667489, Divergences: 0  [  240/  400]\n","\tTrain loss: 50.656665, Overfit loss: 50.648184, Valid loss: 51.441785, Divergences: 0  [  320/  400]\n","Epoch 15 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 50.444021, Overfit loss: 50.406289, Valid loss: 51.240716, Divergences: 0  [    0/  400]\n","\tTrain loss: 50.273297, Overfit loss: 50.236683, Valid loss: 51.041267, Divergences: 0  [   80/  400]\n","\tTrain loss: 50.047738, Overfit loss: 50.044197, Valid loss: 50.846822, Divergences: 0  [  160/  400]\n","\tTrain loss: 49.908166, Overfit loss: 49.868244, Valid loss: 50.646637, Divergences: 0  [  240/  400]\n","\tTrain loss: 49.707084, Overfit loss: 49.718504, Valid loss: 50.487330, Divergences: 0  [  320/  400]\n","Epoch 16 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 49.524213, Overfit loss: 49.504165, Valid loss: 50.297201, Divergences: 0  [    0/  400]\n","\tTrain loss: 49.343103, Overfit loss: 49.357330, Valid loss: 50.123921, Divergences: 0  [   80/  400]\n","\tTrain loss: 49.213581, Overfit loss: 49.220467, Valid loss: 49.963156, Divergences: 0  [  160/  400]\n","\tTrain loss: 49.082111, Overfit loss: 49.038204, Valid loss: 49.811040, Divergences: 0  [  240/  400]\n","\tTrain loss: 48.914623, Overfit loss: 48.893346, Valid loss: 49.660345, Divergences: 0  [  320/  400]\n","Epoch 17 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 48.750512, Overfit loss: 48.744648, Valid loss: 49.505751, Divergences: 0  [    0/  400]\n","\tTrain loss: 48.610275, Overfit loss: 48.607051, Valid loss: 49.364987, Divergences: 0  [   80/  400]\n","\tTrain loss: 48.493381, Overfit loss: 48.496714, Valid loss: 49.216628, Divergences: 0  [  160/  400]\n","\tTrain loss: 48.367175, Overfit loss: 48.350362, Valid loss: 49.083225, Divergences: 0  [  240/  400]\n","\tTrain loss: 48.251366, Overfit loss: 48.214574, Valid loss: 48.960494, Divergences: 0  [  320/  400]\n","Epoch 18 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 48.140134, Overfit loss: 48.115615, Valid loss: 48.831286, Divergences: 0  [    0/  400]\n","\tTrain loss: 47.995128, Overfit loss: 47.980595, Valid loss: 48.727096, Divergences: 0  [   80/  400]\n","\tTrain loss: 47.867941, Overfit loss: 47.889017, Valid loss: 48.599292, Divergences: 0  [  160/  400]\n","\tTrain loss: 47.799189, Overfit loss: 47.750964, Valid loss: 48.496023, Divergences: 0  [  240/  400]\n","\tTrain loss: 47.675924, Overfit loss: 47.652917, Valid loss: 48.382703, Divergences: 0  [  320/  400]\n","Epoch 19 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 47.576804, Overfit loss: 47.563031, Valid loss: 48.270947, Divergences: 0  [    0/  400]\n","\tTrain loss: 47.471833, Overfit loss: 47.471694, Valid loss: 48.164914, Divergences: 0  [   80/  400]\n","\tTrain loss: 47.371722, Overfit loss: 47.380872, Valid loss: 48.069904, Divergences: 0  [  160/  400]\n","\tTrain loss: 47.273172, Overfit loss: 47.266905, Valid loss: 47.982320, Divergences: 0  [  240/  400]\n","\tTrain loss: 47.196077, Overfit loss: 47.214960, Valid loss: 47.882391, Divergences: 0  [  320/  400]\n","Epoch 20 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 47.095192, Overfit loss: 47.107767, Valid loss: 47.807708, Divergences: 0  [    0/  400]\n","\tTrain loss: 47.046495, Overfit loss: 47.025824, Valid loss: 47.711551, Divergences: 0  [   80/  400]\n","\tTrain loss: 46.944512, Overfit loss: 46.951131, Valid loss: 47.637615, Divergences: 0  [  160/  400]\n","\tTrain loss: 46.909227, Overfit loss: 46.878640, Valid loss: 47.550128, Divergences: 0  [  240/  400]\n","\tTrain loss: 46.825668, Overfit loss: 46.793668, Valid loss: 47.476225, Divergences: 0  [  320/  400]\n","\n","========================================================================================================================================================================================================\n","FullGDSC\n","========================================================================================================================================================================================================\n","Hyperparameters: {\n","    \"model\": {\n","        \"S_D\": 6,\n","        \"I_D\": 6,\n","        \"O_D\": 4,\n","        \"SNR\": 2.0\n","    },\n","    \"train\": {\n","        \"train_dataset_size\": 6,\n","        \"valid_dataset_size\": 100,\n","        \"total_train_sequence_length\": 2048,\n","        \"total_valid_sequence_length\": 20000,\n","        \"subsequence_length\": 10,\n","        \"subsequence_initial_mode\": \"random\",\n","        \"sample_efficiency\": 5,\n","        \"replay_buffer\": 10,\n","        \"batch_size\": 128,\n","        \"beta\": 0.1,\n","        \"lr\": 0.0002,\n","        \"momentum\": 0.9,\n","        \"lr_decay\": 0.99,\n","        \"optim_type\": \"GD\",\n","        \"l2_reg\": 0.1,\n","        \"iterations_per_epoch\": 100,\n","        \"epochs\": 20\n","    },\n","    \"experiment\": {\n","        \"n_systems\": 16,\n","        \"ensemble_size\": 1,\n","        \"log_frequency\": 5,\n","        \"print_frequency\": 20,\n","        \"exp_name\": \"FullGDSC\",\n","        \"output_dir\": \"sample_complexity\"\n","    }\n","}\n","========================================================================================================================================================================================================\n","Mean theoretical irreducible loss: 47.72596093644852\n","Epoch 1 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 316.628340, Overfit loss: 313.244471, Valid loss: 313.528631, Divergences: 0  [    0/  600]\n","\tTrain loss: 286.118573, Overfit loss: 285.161386, Valid loss: 286.186948, Divergences: 0  [  120/  600]\n","\tTrain loss: 269.100522, Overfit loss: 268.312182, Valid loss: 269.529946, Divergences: 0  [  240/  600]\n","\tTrain loss: 253.467787, Overfit loss: 252.683169, Valid loss: 253.876716, Divergences: 0  [  360/  600]\n","\tTrain loss: 238.776167, Overfit loss: 238.092081, Valid loss: 239.362089, Divergences: 0  [  480/  600]\n","Epoch 2 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 226.424475, Overfit loss: 225.848736, Valid loss: 227.454934, Divergences: 0  [    0/  600]\n","\tTrain loss: 215.662699, Overfit loss: 215.175618, Valid loss: 217.075239, Divergences: 0  [  120/  600]\n","\tTrain loss: 205.962082, Overfit loss: 205.521647, Valid loss: 207.707606, Divergences: 0  [  240/  600]\n","\tTrain loss: 196.970042, Overfit loss: 196.536897, Valid loss: 198.923051, Divergences: 0  [  360/  600]\n","\tTrain loss: 188.343727, Overfit loss: 187.926416, Valid loss: 190.430495, Divergences: 0  [  480/  600]\n","Epoch 3 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 179.965179, Overfit loss: 179.542705, Valid loss: 182.096528, Divergences: 0  [    0/  600]\n","\tTrain loss: 171.726151, Overfit loss: 171.352526, Valid loss: 173.921752, Divergences: 0  [  120/  600]\n","\tTrain loss: 163.693295, Overfit loss: 163.272034, Valid loss: 165.832602, Divergences: 0  [  240/  600]\n","\tTrain loss: 155.798015, Overfit loss: 155.383538, Valid loss: 157.937990, Divergences: 0  [  360/  600]\n","\tTrain loss: 148.251085, Overfit loss: 147.845049, Valid loss: 150.320356, Divergences: 0  [  480/  600]\n","Epoch 4 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 141.036675, Overfit loss: 140.696626, Valid loss: 143.099831, Divergences: 0  [    0/  600]\n","\tTrain loss: 134.328871, Overfit loss: 134.030083, Valid loss: 136.372109, Divergences: 0  [  120/  600]\n","\tTrain loss: 128.063389, Overfit loss: 127.744641, Valid loss: 130.061004, Divergences: 0  [  240/  600]\n","\tTrain loss: 122.234173, Overfit loss: 121.940622, Valid loss: 124.205600, Divergences: 0  [  360/  600]\n","\tTrain loss: 116.870174, Overfit loss: 116.612268, Valid loss: 118.772403, Divergences: 0  [  480/  600]\n","Epoch 5 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 111.926702, Overfit loss: 111.688993, Valid loss: 113.780392, Divergences: 0  [    0/  600]\n","\tTrain loss: 107.426260, Overfit loss: 107.200009, Valid loss: 109.244088, Divergences: 0  [  120/  600]\n","\tTrain loss: 103.325963, Overfit loss: 103.154943, Valid loss: 105.088034, Divergences: 0  [  240/  600]\n","\tTrain loss: 99.526494, Overfit loss: 99.411603, Valid loss: 101.304697, Divergences: 0  [  360/  600]\n","\tTrain loss: 96.162426, Overfit loss: 95.984888, Valid loss: 97.860830, Divergences: 0  [  480/  600]\n","Epoch 6 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 93.029871, Overfit loss: 92.901655, Valid loss: 94.717681, Divergences: 0  [    0/  600]\n","\tTrain loss: 90.279422, Overfit loss: 90.146216, Valid loss: 91.880982, Divergences: 0  [  120/  600]\n","\tTrain loss: 87.730713, Overfit loss: 87.642675, Valid loss: 89.309445, Divergences: 0  [  240/  600]\n","\tTrain loss: 85.464805, Overfit loss: 85.330697, Valid loss: 86.961118, Divergences: 0  [  360/  600]\n","\tTrain loss: 83.288523, Overfit loss: 83.179241, Valid loss: 84.810160, Divergences: 0  [  480/  600]\n","Epoch 7 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 81.363939, Overfit loss: 81.273215, Valid loss: 82.848422, Divergences: 0  [    0/  600]\n","\tTrain loss: 79.611950, Overfit loss: 79.529521, Valid loss: 81.079156, Divergences: 0  [  120/  600]\n","\tTrain loss: 77.980353, Overfit loss: 77.938376, Valid loss: 79.430551, Divergences: 0  [  240/  600]\n","\tTrain loss: 76.523724, Overfit loss: 76.453243, Valid loss: 77.902521, Divergences: 0  [  360/  600]\n","\tTrain loss: 75.148608, Overfit loss: 75.071415, Valid loss: 76.511841, Divergences: 0  [  480/  600]\n","Epoch 8 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 73.838518, Overfit loss: 73.826105, Valid loss: 75.211417, Divergences: 0  [    0/  600]\n","\tTrain loss: 72.680683, Overfit loss: 72.626230, Valid loss: 74.027941, Divergences: 0  [  120/  600]\n","\tTrain loss: 71.635066, Overfit loss: 71.545522, Valid loss: 72.913464, Divergences: 0  [  240/  600]\n","\tTrain loss: 70.566037, Overfit loss: 70.525513, Valid loss: 71.872494, Divergences: 0  [  360/  600]\n","\tTrain loss: 69.634741, Overfit loss: 69.575623, Valid loss: 70.894996, Divergences: 0  [  480/  600]\n","Epoch 9 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 68.713196, Overfit loss: 68.664409, Valid loss: 69.988513, Divergences: 0  [    0/  600]\n","\tTrain loss: 67.886677, Overfit loss: 67.806809, Valid loss: 69.108819, Divergences: 0  [  120/  600]\n","\tTrain loss: 67.079192, Overfit loss: 67.025550, Valid loss: 68.308307, Divergences: 0  [  240/  600]\n","\tTrain loss: 66.303422, Overfit loss: 66.272338, Valid loss: 67.526418, Divergences: 0  [  360/  600]\n","\tTrain loss: 65.585559, Overfit loss: 65.537937, Valid loss: 66.782353, Divergences: 0  [  480/  600]\n","Epoch 10 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 64.876868, Overfit loss: 64.843390, Valid loss: 66.069066, Divergences: 0  [    0/  600]\n","\tTrain loss: 64.247281, Overfit loss: 64.209224, Valid loss: 65.415080, Divergences: 0  [  120/  600]\n","\tTrain loss: 63.603163, Overfit loss: 63.552644, Valid loss: 64.777416, Divergences: 0  [  240/  600]\n","\tTrain loss: 62.995294, Overfit loss: 62.984076, Valid loss: 64.161745, Divergences: 0  [  360/  600]\n","\tTrain loss: 62.430768, Overfit loss: 62.404152, Valid loss: 63.567979, Divergences: 0  [  480/  600]\n","Epoch 11 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 61.900825, Overfit loss: 61.846065, Valid loss: 63.026128, Divergences: 0  [    0/  600]\n","\tTrain loss: 61.385162, Overfit loss: 61.331702, Valid loss: 62.509605, Divergences: 0  [  120/  600]\n","\tTrain loss: 60.864739, Overfit loss: 60.849853, Valid loss: 62.014679, Divergences: 0  [  240/  600]\n","\tTrain loss: 60.421099, Overfit loss: 60.392681, Valid loss: 61.511313, Divergences: 0  [  360/  600]\n","\tTrain loss: 59.967219, Overfit loss: 59.954901, Valid loss: 61.073823, Divergences: 0  [  480/  600]\n","Epoch 12 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 59.561740, Overfit loss: 59.499733, Valid loss: 60.643170, Divergences: 0  [    0/  600]\n","\tTrain loss: 59.133821, Overfit loss: 59.094278, Valid loss: 60.233129, Divergences: 0  [  120/  600]\n","\tTrain loss: 58.744422, Overfit loss: 58.723726, Valid loss: 59.841261, Divergences: 0  [  240/  600]\n","\tTrain loss: 58.369694, Overfit loss: 58.389357, Valid loss: 59.463487, Divergences: 0  [  360/  600]\n","\tTrain loss: 58.059972, Overfit loss: 58.020039, Valid loss: 59.119816, Divergences: 0  [  480/  600]\n","Epoch 13 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 57.722500, Overfit loss: 57.689520, Valid loss: 58.785798, Divergences: 0  [    0/  600]\n","\tTrain loss: 57.398553, Overfit loss: 57.341806, Valid loss: 58.465007, Divergences: 0  [  120/  600]\n","\tTrain loss: 57.122371, Overfit loss: 57.108854, Valid loss: 58.160905, Divergences: 0  [  240/  600]\n","\tTrain loss: 56.786261, Overfit loss: 56.810911, Valid loss: 57.865132, Divergences: 0  [  360/  600]\n","\tTrain loss: 56.542814, Overfit loss: 56.515906, Valid loss: 57.592140, Divergences: 0  [  480/  600]\n","Epoch 14 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 56.243331, Overfit loss: 56.219307, Valid loss: 57.321552, Divergences: 0  [    0/  600]\n","\tTrain loss: 56.030011, Overfit loss: 56.017352, Valid loss: 57.073853, Divergences: 0  [  120/  600]\n","\tTrain loss: 55.761669, Overfit loss: 55.778131, Valid loss: 56.830274, Divergences: 0  [  240/  600]\n","\tTrain loss: 55.542116, Overfit loss: 55.529635, Valid loss: 56.617507, Divergences: 0  [  360/  600]\n","\tTrain loss: 55.334659, Overfit loss: 55.310084, Valid loss: 56.377905, Divergences: 0  [  480/  600]\n","Epoch 15 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 55.146898, Overfit loss: 55.103840, Valid loss: 56.157558, Divergences: 0  [    0/  600]\n","\tTrain loss: 54.957162, Overfit loss: 54.900628, Valid loss: 55.973728, Divergences: 0  [  120/  600]\n","\tTrain loss: 54.719041, Overfit loss: 54.713469, Valid loss: 55.768412, Divergences: 0  [  240/  600]\n","\tTrain loss: 54.511971, Overfit loss: 54.503658, Valid loss: 55.577909, Divergences: 0  [  360/  600]\n","\tTrain loss: 54.351251, Overfit loss: 54.333843, Valid loss: 55.398485, Divergences: 0  [  480/  600]\n","Epoch 16 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 54.202216, Overfit loss: 54.180402, Valid loss: 55.222617, Divergences: 0  [    0/  600]\n","\tTrain loss: 53.995665, Overfit loss: 53.980204, Valid loss: 55.058837, Divergences: 0  [  120/  600]\n","\tTrain loss: 53.854813, Overfit loss: 53.862732, Valid loss: 54.893280, Divergences: 0  [  240/  600]\n","\tTrain loss: 53.689970, Overfit loss: 53.713790, Valid loss: 54.739407, Divergences: 0  [  360/  600]\n","\tTrain loss: 53.582360, Overfit loss: 53.551252, Valid loss: 54.590409, Divergences: 0  [  480/  600]\n","Epoch 17 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 53.395085, Overfit loss: 53.447518, Valid loss: 54.445593, Divergences: 0  [    0/  600]\n","\tTrain loss: 53.278859, Overfit loss: 53.283681, Valid loss: 54.317370, Divergences: 0  [  120/  600]\n","\tTrain loss: 53.148392, Overfit loss: 53.143775, Valid loss: 54.174205, Divergences: 0  [  240/  600]\n","\tTrain loss: 53.010606, Overfit loss: 53.022656, Valid loss: 54.055118, Divergences: 0  [  360/  600]\n","\tTrain loss: 52.898833, Overfit loss: 52.862451, Valid loss: 53.932883, Divergences: 0  [  480/  600]\n","Epoch 18 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 52.763138, Overfit loss: 52.773932, Valid loss: 53.810786, Divergences: 0  [    0/  600]\n","\tTrain loss: 52.677479, Overfit loss: 52.676976, Valid loss: 53.703793, Divergences: 0  [  120/  600]\n","\tTrain loss: 52.563903, Overfit loss: 52.570320, Valid loss: 53.590793, Divergences: 0  [  240/  600]\n","\tTrain loss: 52.438056, Overfit loss: 52.433048, Valid loss: 53.493868, Divergences: 0  [  360/  600]\n","\tTrain loss: 52.348759, Overfit loss: 52.343604, Valid loss: 53.401560, Divergences: 0  [  480/  600]\n","Epoch 19 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 52.273490, Overfit loss: 52.254711, Valid loss: 53.310353, Divergences: 0  [    0/  600]\n","\tTrain loss: 52.199280, Overfit loss: 52.147164, Valid loss: 53.214434, Divergences: 0  [  120/  600]\n","\tTrain loss: 52.109133, Overfit loss: 52.076350, Valid loss: 53.137413, Divergences: 0  [  240/  600]\n","\tTrain loss: 52.004042, Overfit loss: 51.971688, Valid loss: 53.034075, Divergences: 0  [  360/  600]\n","\tTrain loss: 51.928327, Overfit loss: 51.927576, Valid loss: 52.951265, Divergences: 0  [  480/  600]\n","Epoch 20 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 51.818084, Overfit loss: 51.874267, Valid loss: 52.887695, Divergences: 0  [    0/  600]\n","\tTrain loss: 51.780840, Overfit loss: 51.776515, Valid loss: 52.814696, Divergences: 0  [  120/  600]\n","\tTrain loss: 51.746730, Overfit loss: 51.704778, Valid loss: 52.748057, Divergences: 0  [  240/  600]\n","\tTrain loss: 51.650271, Overfit loss: 51.617065, Valid loss: 52.680234, Divergences: 0  [  360/  600]\n","\tTrain loss: 51.549264, Overfit loss: 51.561232, Valid loss: 52.608043, Divergences: 0  [  480/  600]\n","\n","========================================================================================================================================================================================================\n","FullGDSC\n","========================================================================================================================================================================================================\n","Hyperparameters: {\n","    \"model\": {\n","        \"S_D\": 6,\n","        \"I_D\": 6,\n","        \"O_D\": 4,\n","        \"SNR\": 2.0\n","    },\n","    \"train\": {\n","        \"train_dataset_size\": 8,\n","        \"valid_dataset_size\": 100,\n","        \"total_train_sequence_length\": 2048,\n","        \"total_valid_sequence_length\": 20000,\n","        \"subsequence_length\": 10,\n","        \"subsequence_initial_mode\": \"random\",\n","        \"sample_efficiency\": 5,\n","        \"replay_buffer\": 10,\n","        \"batch_size\": 128,\n","        \"beta\": 0.1,\n","        \"lr\": 0.0002,\n","        \"momentum\": 0.9,\n","        \"lr_decay\": 0.99,\n","        \"optim_type\": \"GD\",\n","        \"l2_reg\": 0.1,\n","        \"iterations_per_epoch\": 100,\n","        \"epochs\": 20\n","    },\n","    \"experiment\": {\n","        \"n_systems\": 16,\n","        \"ensemble_size\": 1,\n","        \"log_frequency\": 5,\n","        \"print_frequency\": 20,\n","        \"exp_name\": \"FullGDSC\",\n","        \"output_dir\": \"sample_complexity\"\n","    }\n","}\n","========================================================================================================================================================================================================\n","Mean theoretical irreducible loss: 51.210225574075764\n","Epoch 1 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 312.028953, Overfit loss: 308.706740, Valid loss: 310.157951, Divergences: 0  [    0/  800]\n","\tTrain loss: 282.718872, Overfit loss: 281.836592, Valid loss: 282.763563, Divergences: 0  [  160/  800]\n","\tTrain loss: 267.386888, Overfit loss: 266.704154, Valid loss: 267.422408, Divergences: 0  [  320/  800]\n","\tTrain loss: 254.147558, Overfit loss: 253.527569, Valid loss: 254.206510, Divergences: 0  [  480/  800]\n","\tTrain loss: 241.413504, Overfit loss: 240.782891, Valid loss: 241.455867, Divergences: 0  [  640/  800]\n","Epoch 2 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 229.057214, Overfit loss: 228.473318, Valid loss: 229.102445, Divergences: 0  [    0/  800]\n","\tTrain loss: 218.093315, Overfit loss: 217.590040, Valid loss: 218.301010, Divergences: 0  [  160/  800]\n","\tTrain loss: 208.331023, Overfit loss: 207.857876, Valid loss: 208.684666, Divergences: 0  [  320/  800]\n","\tTrain loss: 199.258837, Overfit loss: 198.841202, Valid loss: 199.787054, Divergences: 0  [  480/  800]\n","\tTrain loss: 190.733696, Overfit loss: 190.329832, Valid loss: 191.367120, Divergences: 0  [  640/  800]\n","Epoch 3 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 182.594072, Overfit loss: 182.217898, Valid loss: 183.334439, Divergences: 0  [    0/  800]\n","\tTrain loss: 174.914929, Overfit loss: 174.563255, Valid loss: 175.731371, Divergences: 0  [  160/  800]\n","\tTrain loss: 167.548312, Overfit loss: 167.217318, Valid loss: 168.461621, Divergences: 0  [  320/  800]\n","\tTrain loss: 160.629968, Overfit loss: 160.326851, Valid loss: 161.575571, Divergences: 0  [  480/  800]\n","\tTrain loss: 154.116120, Overfit loss: 153.798404, Valid loss: 155.060149, Divergences: 0  [  640/  800]\n","Epoch 4 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 147.982527, Overfit loss: 147.659794, Valid loss: 148.954110, Divergences: 0  [    0/  800]\n","\tTrain loss: 142.256163, Overfit loss: 141.983356, Valid loss: 143.255605, Divergences: 0  [  160/  800]\n","\tTrain loss: 136.899416, Overfit loss: 136.655009, Valid loss: 137.884480, Divergences: 0  [  320/  800]\n","\tTrain loss: 131.862665, Overfit loss: 131.587955, Valid loss: 132.835896, Divergences: 0  [  480/  800]\n","\tTrain loss: 127.069351, Overfit loss: 126.837571, Valid loss: 128.063876, Divergences: 0  [  640/  800]\n","Epoch 5 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 122.532132, Overfit loss: 122.285984, Valid loss: 123.544562, Divergences: 0  [    0/  800]\n","\tTrain loss: 118.286078, Overfit loss: 118.064747, Valid loss: 119.297436, Divergences: 0  [  160/  800]\n","\tTrain loss: 114.258774, Overfit loss: 114.067872, Valid loss: 115.254322, Divergences: 0  [  320/  800]\n","\tTrain loss: 110.387805, Overfit loss: 110.186622, Valid loss: 111.433025, Divergences: 0  [  480/  800]\n","\tTrain loss: 106.717289, Overfit loss: 106.580523, Valid loss: 107.776026, Divergences: 0  [  640/  800]\n","Epoch 6 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 103.259294, Overfit loss: 103.059055, Valid loss: 104.297713, Divergences: 0  [    0/  800]\n","\tTrain loss: 99.949545, Overfit loss: 99.773154, Valid loss: 101.027973, Divergences: 0  [  160/  800]\n","\tTrain loss: 96.870528, Overfit loss: 96.691882, Valid loss: 97.913028, Divergences: 0  [  320/  800]\n","\tTrain loss: 93.915089, Overfit loss: 93.818743, Valid loss: 94.979596, Divergences: 0  [  480/  800]\n","\tTrain loss: 91.157570, Overfit loss: 90.980877, Valid loss: 92.190250, Divergences: 0  [  640/  800]\n","Epoch 7 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 88.551302, Overfit loss: 88.421329, Valid loss: 89.604721, Divergences: 0  [    0/  800]\n","\tTrain loss: 86.094258, Overfit loss: 85.991397, Valid loss: 87.205513, Divergences: 0  [  160/  800]\n","\tTrain loss: 83.878771, Overfit loss: 83.756004, Valid loss: 84.971511, Divergences: 0  [  320/  800]\n","\tTrain loss: 81.843159, Overfit loss: 81.709463, Valid loss: 82.922191, Divergences: 0  [  480/  800]\n","\tTrain loss: 79.947735, Overfit loss: 79.834515, Valid loss: 81.041968, Divergences: 0  [  640/  800]\n","Epoch 8 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 78.169059, Overfit loss: 78.155879, Valid loss: 79.315808, Divergences: 0  [    0/  800]\n","\tTrain loss: 76.676046, Overfit loss: 76.593367, Valid loss: 77.768163, Divergences: 0  [  160/  800]\n","\tTrain loss: 75.209600, Overfit loss: 75.143146, Valid loss: 76.360591, Divergences: 0  [  320/  800]\n","\tTrain loss: 73.922279, Overfit loss: 73.914646, Valid loss: 75.043865, Divergences: 0  [  480/  800]\n","\tTrain loss: 72.719470, Overfit loss: 72.719672, Valid loss: 73.872570, Divergences: 0  [  640/  800]\n","Epoch 9 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 71.644479, Overfit loss: 71.577540, Valid loss: 72.768855, Divergences: 0  [    0/  800]\n","\tTrain loss: 70.649860, Overfit loss: 70.541884, Valid loss: 71.794146, Divergences: 0  [  160/  800]\n","\tTrain loss: 69.691900, Overfit loss: 69.667265, Valid loss: 70.883479, Divergences: 0  [  320/  800]\n","\tTrain loss: 68.875169, Overfit loss: 68.860576, Valid loss: 70.060378, Divergences: 0  [  480/  800]\n","\tTrain loss: 68.152353, Overfit loss: 68.097815, Valid loss: 69.345866, Divergences: 0  [  640/  800]\n","Epoch 10 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 67.466009, Overfit loss: 67.428770, Valid loss: 68.611964, Divergences: 0  [    0/  800]\n","\tTrain loss: 66.676341, Overfit loss: 66.640128, Valid loss: 67.859826, Divergences: 0  [  160/  800]\n","\tTrain loss: 66.044204, Overfit loss: 65.986087, Valid loss: 67.207398, Divergences: 0  [  320/  800]\n","\tTrain loss: 65.485106, Overfit loss: 65.482716, Valid loss: 66.657047, Divergences: 0  [  480/  800]\n","\tTrain loss: 64.914654, Overfit loss: 64.960795, Valid loss: 66.120477, Divergences: 0  [  640/  800]\n","Epoch 11 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 64.351036, Overfit loss: 64.312973, Valid loss: 65.537076, Divergences: 0  [    0/  800]\n","\tTrain loss: 63.860658, Overfit loss: 63.879756, Valid loss: 65.046084, Divergences: 0  [  160/  800]\n","\tTrain loss: 63.398019, Overfit loss: 63.362472, Valid loss: 64.587419, Divergences: 0  [  320/  800]\n","\tTrain loss: 62.951981, Overfit loss: 62.961249, Valid loss: 64.176904, Divergences: 0  [  480/  800]\n","\tTrain loss: 62.572920, Overfit loss: 62.502520, Valid loss: 63.755764, Divergences: 0  [  640/  800]\n","Epoch 12 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 62.157183, Overfit loss: 62.126223, Valid loss: 63.347003, Divergences: 0  [    0/  800]\n","\tTrain loss: 61.750592, Overfit loss: 61.742392, Valid loss: 62.958236, Divergences: 0  [  160/  800]\n","\tTrain loss: 61.403440, Overfit loss: 61.367345, Valid loss: 62.618146, Divergences: 0  [  320/  800]\n","\tTrain loss: 61.078513, Overfit loss: 61.054679, Valid loss: 62.312379, Divergences: 0  [  480/  800]\n","\tTrain loss: 60.778754, Overfit loss: 60.736811, Valid loss: 61.972920, Divergences: 0  [  640/  800]\n","Epoch 13 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 60.466338, Overfit loss: 60.432478, Valid loss: 61.661186, Divergences: 0  [    0/  800]\n","\tTrain loss: 60.171207, Overfit loss: 60.173451, Valid loss: 61.366924, Divergences: 0  [  160/  800]\n","\tTrain loss: 59.961358, Overfit loss: 59.926741, Valid loss: 61.120121, Divergences: 0  [  320/  800]\n","\tTrain loss: 59.603951, Overfit loss: 59.588084, Valid loss: 60.843133, Divergences: 0  [  480/  800]\n","\tTrain loss: 59.326397, Overfit loss: 59.369327, Valid loss: 60.612425, Divergences: 0  [  640/  800]\n","Epoch 14 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 59.116257, Overfit loss: 59.164039, Valid loss: 60.348640, Divergences: 0  [    0/  800]\n","\tTrain loss: 58.869490, Overfit loss: 58.867672, Valid loss: 60.106651, Divergences: 0  [  160/  800]\n","\tTrain loss: 58.644213, Overfit loss: 58.638789, Valid loss: 59.902401, Divergences: 0  [  320/  800]\n","\tTrain loss: 58.439465, Overfit loss: 58.401887, Valid loss: 59.723814, Divergences: 0  [  480/  800]\n","\tTrain loss: 58.234767, Overfit loss: 58.209894, Valid loss: 59.515640, Divergences: 0  [  640/  800]\n","Epoch 15 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 58.078760, Overfit loss: 58.040796, Valid loss: 59.299424, Divergences: 0  [    0/  800]\n","\tTrain loss: 57.843183, Overfit loss: 57.811679, Valid loss: 59.086227, Divergences: 0  [  160/  800]\n","\tTrain loss: 57.632474, Overfit loss: 57.624830, Valid loss: 58.935815, Divergences: 0  [  320/  800]\n","\tTrain loss: 57.482402, Overfit loss: 57.517633, Valid loss: 58.754165, Divergences: 0  [  480/  800]\n","\tTrain loss: 57.308799, Overfit loss: 57.273803, Valid loss: 58.615441, Divergences: 0  [  640/  800]\n","Epoch 16 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 57.160086, Overfit loss: 57.155786, Valid loss: 58.435588, Divergences: 0  [    0/  800]\n","\tTrain loss: 57.004702, Overfit loss: 56.971038, Valid loss: 58.248690, Divergences: 0  [  160/  800]\n","\tTrain loss: 56.850171, Overfit loss: 56.806348, Valid loss: 58.090874, Divergences: 0  [  320/  800]\n","\tTrain loss: 56.682312, Overfit loss: 56.691394, Valid loss: 57.981501, Divergences: 0  [  480/  800]\n","\tTrain loss: 56.542355, Overfit loss: 56.515806, Valid loss: 57.842739, Divergences: 0  [  640/  800]\n","Epoch 17 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 56.438231, Overfit loss: 56.395491, Valid loss: 57.703170, Divergences: 0  [    0/  800]\n","\tTrain loss: 56.217209, Overfit loss: 56.240616, Valid loss: 57.559129, Divergences: 0  [  160/  800]\n","\tTrain loss: 56.131091, Overfit loss: 56.154927, Valid loss: 57.448756, Divergences: 0  [  320/  800]\n","\tTrain loss: 56.006446, Overfit loss: 56.003719, Valid loss: 57.331130, Divergences: 0  [  480/  800]\n","\tTrain loss: 55.889386, Overfit loss: 55.896296, Valid loss: 57.219179, Divergences: 0  [  640/  800]\n","Epoch 18 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 55.766187, Overfit loss: 55.735184, Valid loss: 57.110227, Divergences: 0  [    0/  800]\n","\tTrain loss: 55.685661, Overfit loss: 55.642788, Valid loss: 56.992369, Divergences: 0  [  160/  800]\n","\tTrain loss: 55.546751, Overfit loss: 55.539085, Valid loss: 56.884080, Divergences: 0  [  320/  800]\n","\tTrain loss: 55.412492, Overfit loss: 55.395615, Valid loss: 56.809160, Divergences: 0  [  480/  800]\n","\tTrain loss: 55.345996, Overfit loss: 55.352863, Valid loss: 56.701985, Divergences: 0  [  640/  800]\n","Epoch 19 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 55.273241, Overfit loss: 55.248992, Valid loss: 56.586853, Divergences: 0  [    0/  800]\n","\tTrain loss: 55.134243, Overfit loss: 55.109423, Valid loss: 56.494243, Divergences: 0  [  160/  800]\n","\tTrain loss: 55.069554, Overfit loss: 55.120888, Valid loss: 56.406682, Divergences: 0  [  320/  800]\n","\tTrain loss: 54.961307, Overfit loss: 54.980156, Valid loss: 56.353102, Divergences: 0  [  480/  800]\n","\tTrain loss: 54.902060, Overfit loss: 54.847132, Valid loss: 56.273419, Divergences: 0  [  640/  800]\n","Epoch 20 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 54.834767, Overfit loss: 54.788812, Valid loss: 56.189476, Divergences: 0  [    0/  800]\n","\tTrain loss: 54.711032, Overfit loss: 54.691872, Valid loss: 56.093424, Divergences: 0  [  160/  800]\n","\tTrain loss: 54.645085, Overfit loss: 54.627909, Valid loss: 56.015916, Divergences: 0  [  320/  800]\n","\tTrain loss: 54.550945, Overfit loss: 54.559417, Valid loss: 55.944401, Divergences: 0  [  480/  800]\n","\tTrain loss: 54.505166, Overfit loss: 54.516713, Valid loss: 55.887435, Divergences: 0  [  640/  800]\n","\n","========================================================================================================================================================================================================\n","FullGDSC\n","========================================================================================================================================================================================================\n","Hyperparameters: {\n","    \"model\": {\n","        \"S_D\": 6,\n","        \"I_D\": 6,\n","        \"O_D\": 4,\n","        \"SNR\": 2.0\n","    },\n","    \"train\": {\n","        \"train_dataset_size\": 12,\n","        \"valid_dataset_size\": 100,\n","        \"total_train_sequence_length\": 2048,\n","        \"total_valid_sequence_length\": 20000,\n","        \"subsequence_length\": 10,\n","        \"subsequence_initial_mode\": \"random\",\n","        \"sample_efficiency\": 5,\n","        \"replay_buffer\": 10,\n","        \"batch_size\": 128,\n","        \"beta\": 0.1,\n","        \"lr\": 0.0002,\n","        \"momentum\": 0.9,\n","        \"lr_decay\": 0.99,\n","        \"optim_type\": \"GD\",\n","        \"l2_reg\": 0.1,\n","        \"iterations_per_epoch\": 100,\n","        \"epochs\": 20\n","    },\n","    \"experiment\": {\n","        \"n_systems\": 16,\n","        \"ensemble_size\": 1,\n","        \"log_frequency\": 5,\n","        \"print_frequency\": 20,\n","        \"exp_name\": \"FullGDSC\",\n","        \"output_dir\": \"sample_complexity\"\n","    }\n","}\n","========================================================================================================================================================================================================\n","Mean theoretical irreducible loss: 39.383420418886665\n","Epoch 1 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 257.466634, Overfit loss: 253.771690, Valid loss: 253.946639, Divergences: 0  [    0/ 1200]\n","\tTrain loss: 228.762659, Overfit loss: 227.933825, Valid loss: 228.167041, Divergences: 0  [  240/ 1200]\n","\tTrain loss: 213.697306, Overfit loss: 212.998692, Valid loss: 213.282910, Divergences: 0  [  480/ 1200]\n","\tTrain loss: 202.099645, Overfit loss: 201.583765, Valid loss: 201.911323, Divergences: 0  [  720/ 1200]\n","\tTrain loss: 192.960770, Overfit loss: 192.558308, Valid loss: 192.979470, Divergences: 0  [  960/ 1200]\n","Epoch 2 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 185.016154, Overfit loss: 184.659093, Valid loss: 185.151101, Divergences: 0  [    0/ 1200]\n","\tTrain loss: 177.787396, Overfit loss: 177.476554, Valid loss: 178.024507, Divergences: 0  [  240/ 1200]\n","\tTrain loss: 171.176943, Overfit loss: 170.845565, Valid loss: 171.492079, Divergences: 0  [  480/ 1200]\n","\tTrain loss: 164.982570, Overfit loss: 164.685083, Valid loss: 165.428289, Divergences: 0  [  720/ 1200]\n","\tTrain loss: 159.092052, Overfit loss: 158.794713, Valid loss: 159.610394, Divergences: 0  [  960/ 1200]\n","Epoch 3 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 153.257975, Overfit loss: 152.953471, Valid loss: 153.914387, Divergences: 0  [    0/ 1200]\n","\tTrain loss: 147.577566, Overfit loss: 147.312880, Valid loss: 148.327399, Divergences: 0  [  240/ 1200]\n","\tTrain loss: 141.954685, Overfit loss: 141.684772, Valid loss: 142.774507, Divergences: 0  [  480/ 1200]\n","\tTrain loss: 136.418364, Overfit loss: 136.140446, Valid loss: 137.283116, Divergences: 0  [  720/ 1200]\n","\tTrain loss: 130.969796, Overfit loss: 130.694763, Valid loss: 131.890230, Divergences: 0  [  960/ 1200]\n","Epoch 4 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 125.700436, Overfit loss: 125.447077, Valid loss: 126.634549, Divergences: 0  [    0/ 1200]\n","\tTrain loss: 120.671791, Overfit loss: 120.449136, Valid loss: 121.633298, Divergences: 0  [  240/ 1200]\n","\tTrain loss: 115.895777, Overfit loss: 115.646591, Valid loss: 116.831804, Divergences: 0  [  480/ 1200]\n","\tTrain loss: 111.300812, Overfit loss: 111.060760, Valid loss: 112.246765, Divergences: 0  [  720/ 1200]\n","\tTrain loss: 106.915983, Overfit loss: 106.704268, Valid loss: 107.861839, Divergences: 0  [  960/ 1200]\n","Epoch 5 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 102.703249, Overfit loss: 102.510977, Valid loss: 103.658675, Divergences: 0  [    0/ 1200]\n","\tTrain loss: 98.768636, Overfit loss: 98.563152, Valid loss: 99.703027, Divergences: 0  [  240/ 1200]\n","\tTrain loss: 95.046609, Overfit loss: 94.840716, Valid loss: 95.970112, Divergences: 0  [  480/ 1200]\n","\tTrain loss: 91.530584, Overfit loss: 91.380434, Valid loss: 92.475155, Divergences: 0  [  720/ 1200]\n","\tTrain loss: 88.290903, Overfit loss: 88.080846, Valid loss: 89.221913, Divergences: 0  [  960/ 1200]\n","Epoch 6 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 85.242318, Overfit loss: 85.096798, Valid loss: 86.213154, Divergences: 0  [    0/ 1200]\n","\tTrain loss: 82.461614, Overfit loss: 82.364220, Valid loss: 83.448978, Divergences: 0  [  240/ 1200]\n","\tTrain loss: 79.904341, Overfit loss: 79.787825, Valid loss: 80.902547, Divergences: 0  [  480/ 1200]\n","\tTrain loss: 77.533494, Overfit loss: 77.439929, Valid loss: 78.548204, Divergences: 0  [  720/ 1200]\n","\tTrain loss: 75.352455, Overfit loss: 75.255414, Valid loss: 76.368498, Divergences: 0  [  960/ 1200]\n","Epoch 7 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 73.370318, Overfit loss: 73.242218, Valid loss: 74.373416, Divergences: 0  [    0/ 1200]\n","\tTrain loss: 71.486389, Overfit loss: 71.407026, Valid loss: 72.538896, Divergences: 0  [  240/ 1200]\n","\tTrain loss: 69.757674, Overfit loss: 69.705751, Valid loss: 70.849095, Divergences: 0  [  480/ 1200]\n","\tTrain loss: 68.237389, Overfit loss: 68.123738, Valid loss: 69.296269, Divergences: 0  [  720/ 1200]\n","\tTrain loss: 66.752764, Overfit loss: 66.703575, Valid loss: 67.852152, Divergences: 0  [  960/ 1200]\n","Epoch 8 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 65.418162, Overfit loss: 65.365154, Valid loss: 66.529663, Divergences: 0  [    0/ 1200]\n","\tTrain loss: 64.228487, Overfit loss: 64.186253, Valid loss: 65.323609, Divergences: 0  [  240/ 1200]\n","\tTrain loss: 63.125036, Overfit loss: 63.057814, Valid loss: 64.203536, Divergences: 0  [  480/ 1200]\n","\tTrain loss: 62.059147, Overfit loss: 62.009930, Valid loss: 63.175595, Divergences: 0  [  720/ 1200]\n","\tTrain loss: 61.130360, Overfit loss: 61.045909, Valid loss: 62.198248, Divergences: 0  [  960/ 1200]\n","Epoch 9 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 60.202508, Overfit loss: 60.126235, Valid loss: 61.313288, Divergences: 0  [    0/ 1200]\n","\tTrain loss: 59.359766, Overfit loss: 59.323935, Valid loss: 60.494648, Divergences: 0  [  240/ 1200]\n","\tTrain loss: 58.617837, Overfit loss: 58.555050, Valid loss: 59.717503, Divergences: 0  [  480/ 1200]\n","\tTrain loss: 57.887679, Overfit loss: 57.852945, Valid loss: 59.010999, Divergences: 0  [  720/ 1200]\n","\tTrain loss: 57.228422, Overfit loss: 57.184615, Valid loss: 58.344136, Divergences: 0  [  960/ 1200]\n","Epoch 10 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 56.630114, Overfit loss: 56.594541, Valid loss: 57.720395, Divergences: 0  [    0/ 1200]\n","\tTrain loss: 56.039459, Overfit loss: 55.996720, Valid loss: 57.148305, Divergences: 0  [  240/ 1200]\n","\tTrain loss: 55.477759, Overfit loss: 55.465370, Valid loss: 56.597968, Divergences: 0  [  480/ 1200]\n","\tTrain loss: 54.985852, Overfit loss: 54.948275, Valid loss: 56.088775, Divergences: 0  [  720/ 1200]\n","\tTrain loss: 54.501844, Overfit loss: 54.458347, Valid loss: 55.613062, Divergences: 0  [  960/ 1200]\n","Epoch 11 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 54.032664, Overfit loss: 54.026259, Valid loss: 55.153509, Divergences: 0  [    0/ 1200]\n","\tTrain loss: 53.598299, Overfit loss: 53.607739, Valid loss: 54.737210, Divergences: 0  [  240/ 1200]\n","\tTrain loss: 53.221966, Overfit loss: 53.202219, Valid loss: 54.324791, Divergences: 0  [  480/ 1200]\n","\tTrain loss: 52.822867, Overfit loss: 52.836314, Valid loss: 53.958143, Divergences: 0  [  720/ 1200]\n","\tTrain loss: 52.482710, Overfit loss: 52.426302, Valid loss: 53.594818, Divergences: 0  [  960/ 1200]\n","Epoch 12 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 52.094332, Overfit loss: 52.127330, Valid loss: 53.244876, Divergences: 0  [    0/ 1200]\n","\tTrain loss: 51.807790, Overfit loss: 51.818529, Valid loss: 52.917853, Divergences: 0  [  240/ 1200]\n","\tTrain loss: 51.507702, Overfit loss: 51.479273, Valid loss: 52.614923, Divergences: 0  [  480/ 1200]\n","\tTrain loss: 51.202044, Overfit loss: 51.210134, Valid loss: 52.321377, Divergences: 0  [  720/ 1200]\n","\tTrain loss: 50.925698, Overfit loss: 50.899858, Valid loss: 52.041285, Divergences: 0  [  960/ 1200]\n","Epoch 13 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 50.653330, Overfit loss: 50.644264, Valid loss: 51.771851, Divergences: 0  [    0/ 1200]\n","\tTrain loss: 50.387626, Overfit loss: 50.410747, Valid loss: 51.523284, Divergences: 0  [  240/ 1200]\n","\tTrain loss: 50.192721, Overfit loss: 50.117479, Valid loss: 51.272316, Divergences: 0  [  480/ 1200]\n","\tTrain loss: 49.941223, Overfit loss: 49.931382, Valid loss: 51.051274, Divergences: 0  [  720/ 1200]\n","\tTrain loss: 49.712127, Overfit loss: 49.669031, Valid loss: 50.815034, Divergences: 0  [  960/ 1200]\n","Epoch 14 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 49.496325, Overfit loss: 49.467533, Valid loss: 50.601907, Divergences: 0  [    0/ 1200]\n","\tTrain loss: 49.292978, Overfit loss: 49.290919, Valid loss: 50.400249, Divergences: 0  [  240/ 1200]\n","\tTrain loss: 49.111699, Overfit loss: 49.081156, Valid loss: 50.205264, Divergences: 0  [  480/ 1200]\n","\tTrain loss: 48.938765, Overfit loss: 48.889499, Valid loss: 50.013334, Divergences: 0  [  720/ 1200]\n","\tTrain loss: 48.712325, Overfit loss: 48.722327, Valid loss: 49.832740, Divergences: 0  [  960/ 1200]\n","Epoch 15 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 48.553233, Overfit loss: 48.549817, Valid loss: 49.647874, Divergences: 0  [    0/ 1200]\n","\tTrain loss: 48.378667, Overfit loss: 48.361693, Valid loss: 49.477901, Divergences: 0  [  240/ 1200]\n","\tTrain loss: 48.225970, Overfit loss: 48.253991, Valid loss: 49.313683, Divergences: 0  [  480/ 1200]\n","\tTrain loss: 48.078428, Overfit loss: 48.078428, Valid loss: 49.151103, Divergences: 0  [  720/ 1200]\n","\tTrain loss: 47.915868, Overfit loss: 47.912940, Valid loss: 49.008233, Divergences: 0  [  960/ 1200]\n","Epoch 16 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 47.770877, Overfit loss: 47.762257, Valid loss: 48.854375, Divergences: 0  [    0/ 1200]\n","\tTrain loss: 47.601173, Overfit loss: 47.593964, Valid loss: 48.702875, Divergences: 0  [  240/ 1200]\n","\tTrain loss: 47.481991, Overfit loss: 47.480130, Valid loss: 48.568885, Divergences: 0  [  480/ 1200]\n","\tTrain loss: 47.314688, Overfit loss: 47.332671, Valid loss: 48.429154, Divergences: 0  [  720/ 1200]\n","\tTrain loss: 47.201926, Overfit loss: 47.217111, Valid loss: 48.301971, Divergences: 0  [  960/ 1200]\n","Epoch 17 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 47.084860, Overfit loss: 47.114842, Valid loss: 48.166520, Divergences: 0  [    0/ 1200]\n","\tTrain loss: 46.935444, Overfit loss: 46.968060, Valid loss: 48.038331, Divergences: 0  [  240/ 1200]\n","\tTrain loss: 46.859290, Overfit loss: 46.877994, Valid loss: 47.916999, Divergences: 0  [  480/ 1200]\n","\tTrain loss: 46.733644, Overfit loss: 46.748458, Valid loss: 47.797864, Divergences: 0  [  720/ 1200]\n","\tTrain loss: 46.616034, Overfit loss: 46.618949, Valid loss: 47.671813, Divergences: 0  [  960/ 1200]\n","Epoch 18 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 46.502819, Overfit loss: 46.485743, Valid loss: 47.557393, Divergences: 0  [    0/ 1200]\n","\tTrain loss: 46.407639, Overfit loss: 46.367109, Valid loss: 47.459101, Divergences: 0  [  240/ 1200]\n","\tTrain loss: 46.299067, Overfit loss: 46.257295, Valid loss: 47.341983, Divergences: 0  [  480/ 1200]\n","\tTrain loss: 46.171863, Overfit loss: 46.170950, Valid loss: 47.243222, Divergences: 0  [  720/ 1200]\n","\tTrain loss: 46.069697, Overfit loss: 46.069550, Valid loss: 47.139099, Divergences: 0  [  960/ 1200]\n","Epoch 19 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 45.969273, Overfit loss: 45.974033, Valid loss: 47.031297, Divergences: 0  [    0/ 1200]\n","\tTrain loss: 45.863086, Overfit loss: 45.887538, Valid loss: 46.939239, Divergences: 0  [  240/ 1200]\n","\tTrain loss: 45.772342, Overfit loss: 45.764080, Valid loss: 46.841803, Divergences: 0  [  480/ 1200]\n","\tTrain loss: 45.693209, Overfit loss: 45.663882, Valid loss: 46.758193, Divergences: 0  [  720/ 1200]\n","\tTrain loss: 45.578816, Overfit loss: 45.617102, Valid loss: 46.658736, Divergences: 0  [  960/ 1200]\n","Epoch 20 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 45.513151, Overfit loss: 45.500216, Valid loss: 46.558389, Divergences: 0  [    0/ 1200]\n","\tTrain loss: 45.452622, Overfit loss: 45.442111, Valid loss: 46.477939, Divergences: 0  [  240/ 1200]\n","\tTrain loss: 45.354568, Overfit loss: 45.346475, Valid loss: 46.396343, Divergences: 0  [  480/ 1200]\n","\tTrain loss: 45.252562, Overfit loss: 45.290332, Valid loss: 46.303465, Divergences: 0  [  720/ 1200]\n","\tTrain loss: 45.206985, Overfit loss: 45.164488, Valid loss: 46.221560, Divergences: 0  [  960/ 1200]\n","\n","========================================================================================================================================================================================================\n","FullGDSC\n","========================================================================================================================================================================================================\n","Hyperparameters: {\n","    \"model\": {\n","        \"S_D\": 6,\n","        \"I_D\": 6,\n","        \"O_D\": 4,\n","        \"SNR\": 2.0\n","    },\n","    \"train\": {\n","        \"train_dataset_size\": 16,\n","        \"valid_dataset_size\": 100,\n","        \"total_train_sequence_length\": 2048,\n","        \"total_valid_sequence_length\": 20000,\n","        \"subsequence_length\": 10,\n","        \"subsequence_initial_mode\": \"random\",\n","        \"sample_efficiency\": 5,\n","        \"replay_buffer\": 10,\n","        \"batch_size\": 128,\n","        \"beta\": 0.1,\n","        \"lr\": 0.0002,\n","        \"momentum\": 0.9,\n","        \"lr_decay\": 0.99,\n","        \"optim_type\": \"GD\",\n","        \"l2_reg\": 0.1,\n","        \"iterations_per_epoch\": 100,\n","        \"epochs\": 20\n","    },\n","    \"experiment\": {\n","        \"n_systems\": 16,\n","        \"ensemble_size\": 1,\n","        \"log_frequency\": 5,\n","        \"print_frequency\": 20,\n","        \"exp_name\": \"FullGDSC\",\n","        \"output_dir\": \"sample_complexity\"\n","    }\n","}\n","========================================================================================================================================================================================================\n","Mean theoretical irreducible loss: 40.545419240630316\n","Epoch 1 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 277.500676, Overfit loss: 273.052346, Valid loss: 273.885682, Divergences: 0  [    0/ 1600]\n","\tTrain loss: 239.260574, Overfit loss: 237.803419, Valid loss: 237.816397, Divergences: 0  [  320/ 1600]\n","\tTrain loss: 215.874689, Overfit loss: 215.015377, Valid loss: 214.631600, Divergences: 0  [  640/ 1600]\n","\tTrain loss: 202.595067, Overfit loss: 202.050958, Valid loss: 201.606246, Divergences: 0  [  960/ 1600]\n","\tTrain loss: 192.419251, Overfit loss: 191.943636, Valid loss: 191.620553, Divergences: 0  [ 1280/ 1600]\n","Epoch 2 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 183.497059, Overfit loss: 183.097615, Valid loss: 182.892680, Divergences: 0  [    0/ 1600]\n","\tTrain loss: 175.403344, Overfit loss: 175.050759, Valid loss: 174.967693, Divergences: 0  [  320/ 1600]\n","\tTrain loss: 167.925100, Overfit loss: 167.561127, Valid loss: 167.618790, Divergences: 0  [  640/ 1600]\n","\tTrain loss: 160.905242, Overfit loss: 160.593727, Valid loss: 160.800445, Divergences: 0  [  960/ 1600]\n","\tTrain loss: 154.368244, Overfit loss: 154.038048, Valid loss: 154.413523, Divergences: 0  [ 1280/ 1600]\n","Epoch 3 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 148.139913, Overfit loss: 147.855675, Valid loss: 148.362810, Divergences: 0  [    0/ 1600]\n","\tTrain loss: 142.292208, Overfit loss: 142.004382, Valid loss: 142.652491, Divergences: 0  [  320/ 1600]\n","\tTrain loss: 136.736407, Overfit loss: 136.454454, Valid loss: 137.202960, Divergences: 0  [  640/ 1600]\n","\tTrain loss: 131.428706, Overfit loss: 131.185063, Valid loss: 132.036631, Divergences: 0  [  960/ 1600]\n","\tTrain loss: 126.423621, Overfit loss: 126.175302, Valid loss: 127.113473, Divergences: 0  [ 1280/ 1600]\n","Epoch 4 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 121.659845, Overfit loss: 121.406180, Valid loss: 122.441513, Divergences: 0  [    0/ 1600]\n","\tTrain loss: 117.169249, Overfit loss: 117.002484, Valid loss: 118.029612, Divergences: 0  [  320/ 1600]\n","\tTrain loss: 112.960934, Overfit loss: 112.784119, Valid loss: 113.829575, Divergences: 0  [  640/ 1600]\n","\tTrain loss: 108.925743, Overfit loss: 108.746859, Valid loss: 109.827255, Divergences: 0  [  960/ 1600]\n","\tTrain loss: 105.159309, Overfit loss: 104.945402, Valid loss: 106.019497, Divergences: 0  [ 1280/ 1600]\n","Epoch 5 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 101.713400, Overfit loss: 101.476420, Valid loss: 102.570796, Divergences: 0  [    0/ 1600]\n","\tTrain loss: 98.150306, Overfit loss: 97.962335, Valid loss: 99.030613, Divergences: 0  [  320/ 1600]\n","\tTrain loss: 94.962901, Overfit loss: 94.793166, Valid loss: 95.835354, Divergences: 0  [  640/ 1600]\n","\tTrain loss: 91.897181, Overfit loss: 91.733335, Valid loss: 92.762028, Divergences: 0  [  960/ 1600]\n","\tTrain loss: 89.019029, Overfit loss: 88.891087, Valid loss: 89.880658, Divergences: 0  [ 1280/ 1600]\n","Epoch 6 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 86.346889, Overfit loss: 86.158581, Valid loss: 87.152704, Divergences: 0  [    0/ 1600]\n","\tTrain loss: 83.804198, Overfit loss: 83.673897, Valid loss: 84.607448, Divergences: 0  [  320/ 1600]\n","\tTrain loss: 81.460824, Overfit loss: 81.325486, Valid loss: 82.236124, Divergences: 0  [  640/ 1600]\n","\tTrain loss: 79.272019, Overfit loss: 79.118325, Valid loss: 80.011474, Divergences: 0  [  960/ 1600]\n","\tTrain loss: 77.193196, Overfit loss: 77.087946, Valid loss: 77.935993, Divergences: 0  [ 1280/ 1600]\n","Epoch 7 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 75.242252, Overfit loss: 75.120190, Valid loss: 75.980951, Divergences: 0  [    0/ 1600]\n","\tTrain loss: 73.508798, Overfit loss: 73.377751, Valid loss: 74.184459, Divergences: 0  [  320/ 1600]\n","\tTrain loss: 71.797108, Overfit loss: 71.736650, Valid loss: 72.510731, Divergences: 0  [  640/ 1600]\n","\tTrain loss: 70.271005, Overfit loss: 70.190433, Valid loss: 70.961425, Divergences: 0  [  960/ 1600]\n","\tTrain loss: 68.813849, Overfit loss: 68.740537, Valid loss: 69.493727, Divergences: 0  [ 1280/ 1600]\n","Epoch 8 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 67.488980, Overfit loss: 67.444770, Valid loss: 68.138550, Divergences: 0  [    0/ 1600]\n","\tTrain loss: 66.200258, Overfit loss: 66.160282, Valid loss: 66.873539, Divergences: 0  [  320/ 1600]\n","\tTrain loss: 65.021408, Overfit loss: 64.988255, Valid loss: 65.685996, Divergences: 0  [  640/ 1600]\n","\tTrain loss: 63.957879, Overfit loss: 63.938071, Valid loss: 64.574938, Divergences: 0  [  960/ 1600]\n","\tTrain loss: 62.929653, Overfit loss: 62.867301, Valid loss: 63.537056, Divergences: 0  [ 1280/ 1600]\n","Epoch 9 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 61.971924, Overfit loss: 61.952501, Valid loss: 62.545852, Divergences: 0  [    0/ 1600]\n","\tTrain loss: 61.028578, Overfit loss: 60.969622, Valid loss: 61.630143, Divergences: 0  [  320/ 1600]\n","\tTrain loss: 60.219196, Overfit loss: 60.160057, Valid loss: 60.775629, Divergences: 0  [  640/ 1600]\n","\tTrain loss: 59.436745, Overfit loss: 59.340083, Valid loss: 59.954626, Divergences: 0  [  960/ 1600]\n","\tTrain loss: 58.606898, Overfit loss: 58.596066, Valid loss: 59.190368, Divergences: 0  [ 1280/ 1600]\n","Epoch 10 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 57.899903, Overfit loss: 57.889023, Valid loss: 58.466093, Divergences: 0  [    0/ 1600]\n","\tTrain loss: 57.221661, Overfit loss: 57.209430, Valid loss: 57.790350, Divergences: 0  [  320/ 1600]\n","\tTrain loss: 56.584221, Overfit loss: 56.566434, Valid loss: 57.153976, Divergences: 0  [  640/ 1600]\n","\tTrain loss: 56.022647, Overfit loss: 55.965260, Valid loss: 56.542422, Divergences: 0  [  960/ 1600]\n","\tTrain loss: 55.443219, Overfit loss: 55.382760, Valid loss: 55.974542, Divergences: 0  [ 1280/ 1600]\n","Epoch 11 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 54.923728, Overfit loss: 54.878531, Valid loss: 55.439208, Divergences: 0  [    0/ 1600]\n","\tTrain loss: 54.404673, Overfit loss: 54.368150, Valid loss: 54.934172, Divergences: 0  [  320/ 1600]\n","\tTrain loss: 53.979494, Overfit loss: 53.925339, Valid loss: 54.448461, Divergences: 0  [  640/ 1600]\n","\tTrain loss: 53.477737, Overfit loss: 53.433623, Valid loss: 54.000615, Divergences: 0  [  960/ 1600]\n","\tTrain loss: 53.054551, Overfit loss: 52.986028, Valid loss: 53.573034, Divergences: 0  [ 1280/ 1600]\n","Epoch 12 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 52.644451, Overfit loss: 52.635548, Valid loss: 53.169990, Divergences: 0  [    0/ 1600]\n","\tTrain loss: 52.272927, Overfit loss: 52.192952, Valid loss: 52.790007, Divergences: 0  [  320/ 1600]\n","\tTrain loss: 51.871758, Overfit loss: 51.821807, Valid loss: 52.416425, Divergences: 0  [  640/ 1600]\n","\tTrain loss: 51.526636, Overfit loss: 51.501668, Valid loss: 52.070796, Divergences: 0  [  960/ 1600]\n","\tTrain loss: 51.200410, Overfit loss: 51.161059, Valid loss: 51.739580, Divergences: 0  [ 1280/ 1600]\n","Epoch 13 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 50.904818, Overfit loss: 50.894154, Valid loss: 51.442809, Divergences: 0  [    0/ 1600]\n","\tTrain loss: 50.625758, Overfit loss: 50.609621, Valid loss: 51.139564, Divergences: 0  [  320/ 1600]\n","\tTrain loss: 50.318518, Overfit loss: 50.280334, Valid loss: 50.862880, Divergences: 0  [  640/ 1600]\n","\tTrain loss: 50.040653, Overfit loss: 50.052830, Valid loss: 50.595493, Divergences: 0  [  960/ 1600]\n","\tTrain loss: 49.758693, Overfit loss: 49.766798, Valid loss: 50.336674, Divergences: 0  [ 1280/ 1600]\n","Epoch 14 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 49.534163, Overfit loss: 49.553266, Valid loss: 50.079942, Divergences: 0  [    0/ 1600]\n","\tTrain loss: 49.322747, Overfit loss: 49.264361, Valid loss: 49.853320, Divergences: 0  [  320/ 1600]\n","\tTrain loss: 49.082271, Overfit loss: 49.129129, Valid loss: 49.621800, Divergences: 0  [  640/ 1600]\n","\tTrain loss: 48.864319, Overfit loss: 48.836604, Valid loss: 49.420656, Divergences: 0  [  960/ 1600]\n","\tTrain loss: 48.685804, Overfit loss: 48.687519, Valid loss: 49.215123, Divergences: 0  [ 1280/ 1600]\n","Epoch 15 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 48.463029, Overfit loss: 48.478365, Valid loss: 49.014952, Divergences: 0  [    0/ 1600]\n","\tTrain loss: 48.312637, Overfit loss: 48.222221, Valid loss: 48.829832, Divergences: 0  [  320/ 1600]\n","\tTrain loss: 48.058591, Overfit loss: 48.086181, Valid loss: 48.646588, Divergences: 0  [  640/ 1600]\n","\tTrain loss: 47.916424, Overfit loss: 47.916663, Valid loss: 48.472265, Divergences: 0  [  960/ 1600]\n","\tTrain loss: 47.747455, Overfit loss: 47.749309, Valid loss: 48.289401, Divergences: 0  [ 1280/ 1600]\n","Epoch 16 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 47.569575, Overfit loss: 47.577204, Valid loss: 48.131528, Divergences: 0  [    0/ 1600]\n","\tTrain loss: 47.407734, Overfit loss: 47.421798, Valid loss: 47.976921, Divergences: 0  [  320/ 1600]\n","\tTrain loss: 47.248134, Overfit loss: 47.216981, Valid loss: 47.846268, Divergences: 0  [  640/ 1600]\n","\tTrain loss: 47.122043, Overfit loss: 47.153857, Valid loss: 47.686949, Divergences: 0  [  960/ 1600]\n","\tTrain loss: 47.008138, Overfit loss: 46.968007, Valid loss: 47.548897, Divergences: 0  [ 1280/ 1600]\n","Epoch 17 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 46.850012, Overfit loss: 46.831029, Valid loss: 47.405083, Divergences: 0  [    0/ 1600]\n","\tTrain loss: 46.698181, Overfit loss: 46.784102, Valid loss: 47.286738, Divergences: 0  [  320/ 1600]\n","\tTrain loss: 46.585818, Overfit loss: 46.561356, Valid loss: 47.146857, Divergences: 0  [  640/ 1600]\n","\tTrain loss: 46.480585, Overfit loss: 46.466152, Valid loss: 47.019086, Divergences: 0  [  960/ 1600]\n","\tTrain loss: 46.355280, Overfit loss: 46.338473, Valid loss: 46.920858, Divergences: 0  [ 1280/ 1600]\n","Epoch 18 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 46.240115, Overfit loss: 46.210124, Valid loss: 46.798019, Divergences: 0  [    0/ 1600]\n","\tTrain loss: 46.081409, Overfit loss: 46.097441, Valid loss: 46.685539, Divergences: 0  [  320/ 1600]\n","\tTrain loss: 45.985510, Overfit loss: 46.035052, Valid loss: 46.562523, Divergences: 0  [  640/ 1600]\n","\tTrain loss: 45.945688, Overfit loss: 45.886529, Valid loss: 46.464135, Divergences: 0  [  960/ 1600]\n","\tTrain loss: 45.783836, Overfit loss: 45.776557, Valid loss: 46.353825, Divergences: 0  [ 1280/ 1600]\n","Epoch 19 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 45.688241, Overfit loss: 45.645646, Valid loss: 46.253389, Divergences: 0  [    0/ 1600]\n","\tTrain loss: 45.600815, Overfit loss: 45.544202, Valid loss: 46.146352, Divergences: 0  [  320/ 1600]\n","\tTrain loss: 45.485773, Overfit loss: 45.465743, Valid loss: 46.056533, Divergences: 0  [  640/ 1600]\n","\tTrain loss: 45.374385, Overfit loss: 45.422687, Valid loss: 45.970680, Divergences: 0  [  960/ 1600]\n","\tTrain loss: 45.304030, Overfit loss: 45.310759, Valid loss: 45.877551, Divergences: 0  [ 1280/ 1600]\n","Epoch 20 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 45.239281, Overfit loss: 45.187910, Valid loss: 45.785695, Divergences: 0  [    0/ 1600]\n","\tTrain loss: 45.133933, Overfit loss: 45.144258, Valid loss: 45.714855, Divergences: 0  [  320/ 1600]\n","\tTrain loss: 45.058609, Overfit loss: 45.001815, Valid loss: 45.601479, Divergences: 0  [  640/ 1600]\n","\tTrain loss: 44.980379, Overfit loss: 44.960490, Valid loss: 45.527956, Divergences: 0  [  960/ 1600]\n","\tTrain loss: 44.877081, Overfit loss: 44.851401, Valid loss: 45.458137, Divergences: 0  [ 1280/ 1600]\n","\n","========================================================================================================================================================================================================\n","FullGDSC\n","========================================================================================================================================================================================================\n","Hyperparameters: {\n","    \"model\": {\n","        \"S_D\": 6,\n","        \"I_D\": 6,\n","        \"O_D\": 4,\n","        \"SNR\": 2.0\n","    },\n","    \"train\": {\n","        \"train_dataset_size\": 23,\n","        \"valid_dataset_size\": 100,\n","        \"total_train_sequence_length\": 2048,\n","        \"total_valid_sequence_length\": 20000,\n","        \"subsequence_length\": 10,\n","        \"subsequence_initial_mode\": \"random\",\n","        \"sample_efficiency\": 5,\n","        \"replay_buffer\": 10,\n","        \"batch_size\": 128,\n","        \"beta\": 0.1,\n","        \"lr\": 0.0002,\n","        \"momentum\": 0.9,\n","        \"lr_decay\": 0.99,\n","        \"optim_type\": \"GD\",\n","        \"l2_reg\": 0.1,\n","        \"iterations_per_epoch\": 100,\n","        \"epochs\": 20\n","    },\n","    \"experiment\": {\n","        \"n_systems\": 16,\n","        \"ensemble_size\": 1,\n","        \"log_frequency\": 5,\n","        \"print_frequency\": 20,\n","        \"exp_name\": \"FullGDSC\",\n","        \"output_dir\": \"sample_complexity\"\n","    }\n","}\n","========================================================================================================================================================================================================\n","Mean theoretical irreducible loss: 35.8539395998215\n","Epoch 1 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 281.906042, Overfit loss: 277.408151, Valid loss: 283.707301, Divergences: 0  [    0/ 2300]\n","\tTrain loss: 240.820341, Overfit loss: 239.387481, Valid loss: 244.326782, Divergences: 0  [  460/ 2300]\n","\tTrain loss: 217.492760, Overfit loss: 216.671887, Valid loss: 220.835535, Divergences: 0  [  920/ 2300]\n","\tTrain loss: 202.464600, Overfit loss: 201.829719, Valid loss: 205.658142, Divergences: 0  [ 1380/ 2300]\n","\tTrain loss: 192.080409, Overfit loss: 191.543355, Valid loss: 195.185034, Divergences: 0  [ 1840/ 2300]\n","Epoch 2 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 183.806097, Overfit loss: 183.391568, Valid loss: 186.905358, Divergences: 0  [    0/ 2300]\n","\tTrain loss: 176.648774, Overfit loss: 176.318012, Valid loss: 179.765353, Divergences: 0  [  460/ 2300]\n","\tTrain loss: 170.015683, Overfit loss: 169.670241, Valid loss: 173.160029, Divergences: 0  [  920/ 2300]\n","\tTrain loss: 163.715995, Overfit loss: 163.403018, Valid loss: 166.829852, Divergences: 0  [ 1380/ 2300]\n","\tTrain loss: 157.531014, Overfit loss: 157.218866, Valid loss: 160.683307, Divergences: 0  [ 1840/ 2300]\n","Epoch 3 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 151.559858, Overfit loss: 151.249557, Valid loss: 154.631091, Divergences: 0  [    0/ 2300]\n","\tTrain loss: 145.556748, Overfit loss: 145.281728, Valid loss: 148.566739, Divergences: 0  [  460/ 2300]\n","\tTrain loss: 139.595463, Overfit loss: 139.288393, Valid loss: 142.488158, Divergences: 0  [  920/ 2300]\n","\tTrain loss: 133.620270, Overfit loss: 133.326703, Valid loss: 136.424825, Divergences: 0  [ 1380/ 2300]\n","\tTrain loss: 127.708812, Overfit loss: 127.416437, Valid loss: 130.391705, Divergences: 0  [ 1840/ 2300]\n","Epoch 4 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 121.927467, Overfit loss: 121.571233, Valid loss: 124.444775, Divergences: 0  [    0/ 2300]\n","\tTrain loss: 116.237411, Overfit loss: 116.037118, Valid loss: 118.698467, Divergences: 0  [  460/ 2300]\n","\tTrain loss: 110.879694, Overfit loss: 110.621953, Valid loss: 113.163054, Divergences: 0  [  920/ 2300]\n","\tTrain loss: 105.687594, Overfit loss: 105.471358, Valid loss: 107.890041, Divergences: 0  [ 1380/ 2300]\n","\tTrain loss: 100.835907, Overfit loss: 100.567908, Valid loss: 102.888691, Divergences: 0  [ 1840/ 2300]\n","Epoch 5 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 96.237142, Overfit loss: 96.044052, Valid loss: 98.234280, Divergences: 0  [    0/ 2300]\n","\tTrain loss: 92.073973, Overfit loss: 91.874163, Valid loss: 93.950348, Divergences: 0  [  460/ 2300]\n","\tTrain loss: 88.222461, Overfit loss: 88.020561, Valid loss: 90.013241, Divergences: 0  [  920/ 2300]\n","\tTrain loss: 84.681153, Overfit loss: 84.457141, Valid loss: 86.397643, Divergences: 0  [ 1380/ 2300]\n","\tTrain loss: 81.424658, Overfit loss: 81.269112, Valid loss: 83.108236, Divergences: 0  [ 1840/ 2300]\n","Epoch 6 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 78.461052, Overfit loss: 78.365364, Valid loss: 80.101485, Divergences: 0  [    0/ 2300]\n","\tTrain loss: 75.871903, Overfit loss: 75.728513, Valid loss: 77.391923, Divergences: 0  [  460/ 2300]\n","\tTrain loss: 73.429033, Overfit loss: 73.308375, Valid loss: 74.929919, Divergences: 0  [  920/ 2300]\n","\tTrain loss: 71.223137, Overfit loss: 71.115475, Valid loss: 72.682740, Divergences: 0  [ 1380/ 2300]\n","\tTrain loss: 69.207232, Overfit loss: 69.112538, Valid loss: 70.621274, Divergences: 0  [ 1840/ 2300]\n","Epoch 7 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 67.336398, Overfit loss: 67.300989, Valid loss: 68.734219, Divergences: 0  [    0/ 2300]\n","\tTrain loss: 65.650058, Overfit loss: 65.587505, Valid loss: 67.030707, Divergences: 0  [  460/ 2300]\n","\tTrain loss: 64.155703, Overfit loss: 64.031544, Valid loss: 65.447138, Divergences: 0  [  920/ 2300]\n","\tTrain loss: 62.680825, Overfit loss: 62.707073, Valid loss: 64.005405, Divergences: 0  [ 1380/ 2300]\n","\tTrain loss: 61.436075, Overfit loss: 61.330800, Valid loss: 62.664728, Divergences: 0  [ 1840/ 2300]\n","Epoch 8 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 60.189285, Overfit loss: 60.143164, Valid loss: 61.423250, Divergences: 0  [    0/ 2300]\n","\tTrain loss: 59.045509, Overfit loss: 59.001769, Valid loss: 60.279333, Divergences: 0  [  460/ 2300]\n","\tTrain loss: 57.965529, Overfit loss: 57.948462, Valid loss: 59.207570, Divergences: 0  [  920/ 2300]\n","\tTrain loss: 57.014746, Overfit loss: 56.997866, Valid loss: 58.211473, Divergences: 0  [ 1380/ 2300]\n","\tTrain loss: 56.148698, Overfit loss: 56.068560, Valid loss: 57.277213, Divergences: 0  [ 1840/ 2300]\n","Epoch 9 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 55.228084, Overfit loss: 55.211477, Valid loss: 56.398527, Divergences: 0  [    0/ 2300]\n","\tTrain loss: 54.420447, Overfit loss: 54.432087, Valid loss: 55.585120, Divergences: 0  [  460/ 2300]\n","\tTrain loss: 53.712685, Overfit loss: 53.617195, Valid loss: 54.810446, Divergences: 0  [  920/ 2300]\n","\tTrain loss: 52.950860, Overfit loss: 52.908142, Valid loss: 54.085037, Divergences: 0  [ 1380/ 2300]\n","\tTrain loss: 52.322656, Overfit loss: 52.273752, Valid loss: 53.411160, Divergences: 0  [ 1840/ 2300]\n","Epoch 10 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 51.680729, Overfit loss: 51.658615, Valid loss: 52.784417, Divergences: 0  [    0/ 2300]\n","\tTrain loss: 51.112608, Overfit loss: 51.095727, Valid loss: 52.185429, Divergences: 0  [  460/ 2300]\n","\tTrain loss: 50.597276, Overfit loss: 50.509020, Valid loss: 51.639234, Divergences: 0  [  920/ 2300]\n","\tTrain loss: 50.079731, Overfit loss: 50.005773, Valid loss: 51.107011, Divergences: 0  [ 1380/ 2300]\n","\tTrain loss: 49.545383, Overfit loss: 49.513236, Valid loss: 50.613912, Divergences: 0  [ 1840/ 2300]\n","Epoch 11 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 49.098506, Overfit loss: 49.059949, Valid loss: 50.141272, Divergences: 0  [    0/ 2300]\n","\tTrain loss: 48.693635, Overfit loss: 48.622833, Valid loss: 49.700392, Divergences: 0  [  460/ 2300]\n","\tTrain loss: 48.265024, Overfit loss: 48.270752, Valid loss: 49.282268, Divergences: 0  [  920/ 2300]\n","\tTrain loss: 47.898677, Overfit loss: 47.827428, Valid loss: 48.881327, Divergences: 0  [ 1380/ 2300]\n","\tTrain loss: 47.506468, Overfit loss: 47.516141, Valid loss: 48.495077, Divergences: 0  [ 1840/ 2300]\n","Epoch 12 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 47.199342, Overfit loss: 47.155549, Valid loss: 48.140250, Divergences: 0  [    0/ 2300]\n","\tTrain loss: 46.844030, Overfit loss: 46.808016, Valid loss: 47.791753, Divergences: 0  [  460/ 2300]\n","\tTrain loss: 46.505452, Overfit loss: 46.477866, Valid loss: 47.464424, Divergences: 0  [  920/ 2300]\n","\tTrain loss: 46.180518, Overfit loss: 46.159678, Valid loss: 47.165366, Divergences: 0  [ 1380/ 2300]\n","\tTrain loss: 45.932676, Overfit loss: 45.921906, Valid loss: 46.872795, Divergences: 0  [ 1840/ 2300]\n","Epoch 13 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 45.609992, Overfit loss: 45.617737, Valid loss: 46.579342, Divergences: 0  [    0/ 2300]\n","\tTrain loss: 45.384892, Overfit loss: 45.364524, Valid loss: 46.317446, Divergences: 0  [  460/ 2300]\n","\tTrain loss: 45.129740, Overfit loss: 45.166080, Valid loss: 46.060143, Divergences: 0  [  920/ 2300]\n","\tTrain loss: 44.901199, Overfit loss: 44.901273, Valid loss: 45.821180, Divergences: 0  [ 1380/ 2300]\n","\tTrain loss: 44.677810, Overfit loss: 44.694596, Valid loss: 45.587248, Divergences: 0  [ 1840/ 2300]\n","Epoch 14 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 44.457217, Overfit loss: 44.448690, Valid loss: 45.351376, Divergences: 0  [    0/ 2300]\n","\tTrain loss: 44.264123, Overfit loss: 44.262785, Valid loss: 45.151517, Divergences: 0  [  460/ 2300]\n","\tTrain loss: 44.045465, Overfit loss: 44.082535, Valid loss: 44.950532, Divergences: 0  [  920/ 2300]\n","\tTrain loss: 43.898079, Overfit loss: 43.887490, Valid loss: 44.751948, Divergences: 0  [ 1380/ 2300]\n","\tTrain loss: 43.729368, Overfit loss: 43.703843, Valid loss: 44.565836, Divergences: 0  [ 1840/ 2300]\n","Epoch 15 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 43.489122, Overfit loss: 43.513087, Valid loss: 44.391304, Divergences: 0  [    0/ 2300]\n","\tTrain loss: 43.338960, Overfit loss: 43.335214, Valid loss: 44.229806, Divergences: 0  [  460/ 2300]\n","\tTrain loss: 43.168380, Overfit loss: 43.173725, Valid loss: 44.059105, Divergences: 0  [  920/ 2300]\n","\tTrain loss: 43.050488, Overfit loss: 43.016614, Valid loss: 43.903034, Divergences: 0  [ 1380/ 2300]\n","\tTrain loss: 42.876768, Overfit loss: 42.912244, Valid loss: 43.745473, Divergences: 0  [ 1840/ 2300]\n","Epoch 16 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 42.754252, Overfit loss: 42.800091, Valid loss: 43.606668, Divergences: 0  [    0/ 2300]\n","\tTrain loss: 42.590080, Overfit loss: 42.597703, Valid loss: 43.460330, Divergences: 0  [  460/ 2300]\n","\tTrain loss: 42.544135, Overfit loss: 42.489337, Valid loss: 43.344162, Divergences: 0  [  920/ 2300]\n","\tTrain loss: 42.350501, Overfit loss: 42.337978, Valid loss: 43.218184, Divergences: 0  [ 1380/ 2300]\n","\tTrain loss: 42.261172, Overfit loss: 42.240187, Valid loss: 43.085899, Divergences: 0  [ 1840/ 2300]\n","Epoch 17 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 42.092000, Overfit loss: 42.140330, Valid loss: 42.958658, Divergences: 0  [    0/ 2300]\n","\tTrain loss: 42.053043, Overfit loss: 42.076372, Valid loss: 42.855215, Divergences: 0  [  460/ 2300]\n","\tTrain loss: 41.941002, Overfit loss: 41.889016, Valid loss: 42.742101, Divergences: 0  [  920/ 2300]\n","\tTrain loss: 41.799805, Overfit loss: 41.789117, Valid loss: 42.620320, Divergences: 0  [ 1380/ 2300]\n","\tTrain loss: 41.725695, Overfit loss: 41.738683, Valid loss: 42.530683, Divergences: 0  [ 1840/ 2300]\n","Epoch 18 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 41.630023, Overfit loss: 41.632168, Valid loss: 42.426663, Divergences: 0  [    0/ 2300]\n","\tTrain loss: 41.543833, Overfit loss: 41.510831, Valid loss: 42.333568, Divergences: 0  [  460/ 2300]\n","\tTrain loss: 41.446792, Overfit loss: 41.446979, Valid loss: 42.245979, Divergences: 0  [  920/ 2300]\n","\tTrain loss: 41.375012, Overfit loss: 41.301702, Valid loss: 42.150102, Divergences: 0  [ 1380/ 2300]\n","\tTrain loss: 41.281389, Overfit loss: 41.247919, Valid loss: 42.067912, Divergences: 0  [ 1840/ 2300]\n","Epoch 19 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 41.206813, Overfit loss: 41.159291, Valid loss: 41.977865, Divergences: 0  [    0/ 2300]\n","\tTrain loss: 41.113720, Overfit loss: 41.114125, Valid loss: 41.893181, Divergences: 0  [  460/ 2300]\n","\tTrain loss: 41.031990, Overfit loss: 40.983079, Valid loss: 41.814460, Divergences: 0  [  920/ 2300]\n","\tTrain loss: 40.943496, Overfit loss: 40.942211, Valid loss: 41.739390, Divergences: 0  [ 1380/ 2300]\n","\tTrain loss: 40.839913, Overfit loss: 40.898397, Valid loss: 41.660245, Divergences: 0  [ 1840/ 2300]\n","Epoch 20 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 40.793204, Overfit loss: 40.790830, Valid loss: 41.593365, Divergences: 0  [    0/ 2300]\n","\tTrain loss: 40.745071, Overfit loss: 40.717475, Valid loss: 41.514316, Divergences: 0  [  460/ 2300]\n","\tTrain loss: 40.639852, Overfit loss: 40.684487, Valid loss: 41.440635, Divergences: 0  [  920/ 2300]\n","\tTrain loss: 40.552032, Overfit loss: 40.618382, Valid loss: 41.375840, Divergences: 0  [ 1380/ 2300]\n","\tTrain loss: 40.495145, Overfit loss: 40.484524, Valid loss: 41.307456, Divergences: 0  [ 1840/ 2300]\n","\n","========================================================================================================================================================================================================\n","FullGDSC\n","========================================================================================================================================================================================================\n","Hyperparameters: {\n","    \"model\": {\n","        \"S_D\": 6,\n","        \"I_D\": 6,\n","        \"O_D\": 4,\n","        \"SNR\": 2.0\n","    },\n","    \"train\": {\n","        \"train_dataset_size\": 32,\n","        \"valid_dataset_size\": 100,\n","        \"total_train_sequence_length\": 2048,\n","        \"total_valid_sequence_length\": 20000,\n","        \"subsequence_length\": 10,\n","        \"subsequence_initial_mode\": \"random\",\n","        \"sample_efficiency\": 5,\n","        \"replay_buffer\": 10,\n","        \"batch_size\": 128,\n","        \"beta\": 0.1,\n","        \"lr\": 0.0002,\n","        \"momentum\": 0.9,\n","        \"lr_decay\": 0.99,\n","        \"optim_type\": \"GD\",\n","        \"l2_reg\": 0.1,\n","        \"iterations_per_epoch\": 100,\n","        \"epochs\": 20\n","    },\n","    \"experiment\": {\n","        \"n_systems\": 16,\n","        \"ensemble_size\": 1,\n","        \"log_frequency\": 5,\n","        \"print_frequency\": 20,\n","        \"exp_name\": \"FullGDSC\",\n","        \"output_dir\": \"sample_complexity\"\n","    }\n","}\n","========================================================================================================================================================================================================\n","Mean theoretical irreducible loss: 35.07695237012446\n","Epoch 1 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 261.492860, Overfit loss: 258.444753, Valid loss: 261.953688, Divergences: 0  [    0/ 3200]\n","\tTrain loss: 237.338621, Overfit loss: 236.603359, Valid loss: 239.725754, Divergences: 0  [  640/ 3200]\n","\tTrain loss: 224.252041, Overfit loss: 223.650137, Valid loss: 226.679698, Divergences: 0  [ 1280/ 3200]\n","\tTrain loss: 212.539112, Overfit loss: 211.945113, Valid loss: 214.958803, Divergences: 0  [ 1920/ 3200]\n","\tTrain loss: 201.912811, Overfit loss: 201.431338, Valid loss: 204.377054, Divergences: 0  [ 2560/ 3200]\n","Epoch 2 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 192.752368, Overfit loss: 192.340376, Valid loss: 195.173046, Divergences: 0  [    0/ 3200]\n","\tTrain loss: 184.434335, Overfit loss: 184.018926, Valid loss: 186.903664, Divergences: 0  [  640/ 3200]\n","\tTrain loss: 176.541198, Overfit loss: 176.223677, Valid loss: 179.055288, Divergences: 0  [ 1280/ 3200]\n","\tTrain loss: 168.970753, Overfit loss: 168.584631, Valid loss: 171.446707, Divergences: 0  [ 1920/ 3200]\n","\tTrain loss: 161.468559, Overfit loss: 161.175660, Valid loss: 163.983107, Divergences: 0  [ 2560/ 3200]\n","Epoch 3 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 154.249054, Overfit loss: 153.921085, Valid loss: 156.682068, Divergences: 0  [    0/ 3200]\n","\tTrain loss: 147.270237, Overfit loss: 146.929611, Valid loss: 149.673906, Divergences: 0  [  640/ 3200]\n","\tTrain loss: 140.545742, Overfit loss: 140.245804, Valid loss: 142.907139, Divergences: 0  [ 1280/ 3200]\n","\tTrain loss: 134.163305, Overfit loss: 133.838206, Valid loss: 136.425752, Divergences: 0  [ 1920/ 3200]\n","\tTrain loss: 127.999832, Overfit loss: 127.727455, Valid loss: 130.267208, Divergences: 0  [ 2560/ 3200]\n","Epoch 4 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 122.280307, Overfit loss: 122.003837, Valid loss: 124.484171, Divergences: 0  [    0/ 3200]\n","\tTrain loss: 116.940781, Overfit loss: 116.677325, Valid loss: 119.095203, Divergences: 0  [  640/ 3200]\n","\tTrain loss: 111.997306, Overfit loss: 111.749951, Valid loss: 114.075985, Divergences: 0  [ 1280/ 3200]\n","\tTrain loss: 107.348527, Overfit loss: 107.100658, Valid loss: 109.373644, Divergences: 0  [ 1920/ 3200]\n","\tTrain loss: 103.000005, Overfit loss: 102.822775, Valid loss: 104.989548, Divergences: 0  [ 2560/ 3200]\n","Epoch 5 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 98.920792, Overfit loss: 98.740054, Valid loss: 100.883020, Divergences: 0  [    0/ 3200]\n","\tTrain loss: 95.159833, Overfit loss: 94.971542, Valid loss: 97.066442, Divergences: 0  [  640/ 3200]\n","\tTrain loss: 91.659025, Overfit loss: 91.502726, Valid loss: 93.490610, Divergences: 0  [ 1280/ 3200]\n","\tTrain loss: 88.283667, Overfit loss: 88.137338, Valid loss: 90.139971, Divergences: 0  [ 1920/ 3200]\n","\tTrain loss: 85.228275, Overfit loss: 85.087887, Valid loss: 86.987331, Divergences: 0  [ 2560/ 3200]\n","Epoch 6 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 82.277741, Overfit loss: 82.163670, Valid loss: 84.043313, Divergences: 0  [    0/ 3200]\n","\tTrain loss: 79.578492, Overfit loss: 79.510300, Valid loss: 81.320900, Divergences: 0  [  640/ 3200]\n","\tTrain loss: 77.093078, Overfit loss: 77.015281, Valid loss: 78.771248, Divergences: 0  [ 1280/ 3200]\n","\tTrain loss: 74.725923, Overfit loss: 74.591791, Valid loss: 76.385895, Divergences: 0  [ 1920/ 3200]\n","\tTrain loss: 72.529240, Overfit loss: 72.473495, Valid loss: 74.160807, Divergences: 0  [ 2560/ 3200]\n","Epoch 7 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 70.496625, Overfit loss: 70.441451, Valid loss: 72.090927, Divergences: 0  [    0/ 3200]\n","\tTrain loss: 68.577434, Overfit loss: 68.529685, Valid loss: 70.162592, Divergences: 0  [  640/ 3200]\n","\tTrain loss: 66.837673, Overfit loss: 66.795030, Valid loss: 68.370807, Divergences: 0  [ 1280/ 3200]\n","\tTrain loss: 65.195881, Overfit loss: 65.170178, Valid loss: 66.692113, Divergences: 0  [ 1920/ 3200]\n","\tTrain loss: 63.646179, Overfit loss: 63.573293, Valid loss: 65.106734, Divergences: 0  [ 2560/ 3200]\n","Epoch 8 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 62.208731, Overfit loss: 62.122150, Valid loss: 63.627069, Divergences: 0  [    0/ 3200]\n","\tTrain loss: 60.876083, Overfit loss: 60.768889, Valid loss: 62.235116, Divergences: 0  [  640/ 3200]\n","\tTrain loss: 59.562300, Overfit loss: 59.538948, Valid loss: 60.953547, Divergences: 0  [ 1280/ 3200]\n","\tTrain loss: 58.375783, Overfit loss: 58.351797, Valid loss: 59.731162, Divergences: 0  [ 1920/ 3200]\n","\tTrain loss: 57.306613, Overfit loss: 57.210738, Valid loss: 58.599954, Divergences: 0  [ 2560/ 3200]\n","Epoch 9 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 56.247642, Overfit loss: 56.150688, Valid loss: 57.530090, Divergences: 0  [    0/ 3200]\n","\tTrain loss: 55.270164, Overfit loss: 55.230169, Valid loss: 56.527679, Divergences: 0  [  640/ 3200]\n","\tTrain loss: 54.309572, Overfit loss: 54.298453, Valid loss: 55.600500, Divergences: 0  [ 1280/ 3200]\n","\tTrain loss: 53.477881, Overfit loss: 53.403340, Valid loss: 54.712220, Divergences: 0  [ 1920/ 3200]\n","\tTrain loss: 52.615132, Overfit loss: 52.605803, Valid loss: 53.878774, Divergences: 0  [ 2560/ 3200]\n","Epoch 10 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 51.899415, Overfit loss: 51.860631, Valid loss: 53.105171, Divergences: 0  [    0/ 3200]\n","\tTrain loss: 51.169045, Overfit loss: 51.144659, Valid loss: 52.377160, Divergences: 0  [  640/ 3200]\n","\tTrain loss: 50.499447, Overfit loss: 50.477665, Valid loss: 51.687295, Divergences: 0  [ 1280/ 3200]\n","\tTrain loss: 49.901933, Overfit loss: 49.876601, Valid loss: 51.041663, Divergences: 0  [ 1920/ 3200]\n","\tTrain loss: 49.345654, Overfit loss: 49.290999, Valid loss: 50.440126, Divergences: 0  [ 2560/ 3200]\n","Epoch 11 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 48.759489, Overfit loss: 48.711343, Valid loss: 49.871098, Divergences: 0  [    0/ 3200]\n","\tTrain loss: 48.243900, Overfit loss: 48.217140, Valid loss: 49.347673, Divergences: 0  [  640/ 3200]\n","\tTrain loss: 47.764408, Overfit loss: 47.723923, Valid loss: 48.852753, Divergences: 0  [ 1280/ 3200]\n","\tTrain loss: 47.317388, Overfit loss: 47.283006, Valid loss: 48.389502, Divergences: 0  [ 1920/ 3200]\n","\tTrain loss: 46.880822, Overfit loss: 46.868794, Valid loss: 47.939589, Divergences: 0  [ 2560/ 3200]\n","Epoch 12 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 46.489904, Overfit loss: 46.466068, Valid loss: 47.526963, Divergences: 0  [    0/ 3200]\n","\tTrain loss: 46.103478, Overfit loss: 46.071086, Valid loss: 47.129567, Divergences: 0  [  640/ 3200]\n","\tTrain loss: 45.727986, Overfit loss: 45.741120, Valid loss: 46.762627, Divergences: 0  [ 1280/ 3200]\n","\tTrain loss: 45.402058, Overfit loss: 45.370117, Valid loss: 46.416535, Divergences: 0  [ 1920/ 3200]\n","\tTrain loss: 45.077325, Overfit loss: 45.053908, Valid loss: 46.079694, Divergences: 0  [ 2560/ 3200]\n","Epoch 13 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 44.756215, Overfit loss: 44.773719, Valid loss: 45.766971, Divergences: 0  [    0/ 3200]\n","\tTrain loss: 44.502766, Overfit loss: 44.449665, Valid loss: 45.460204, Divergences: 0  [  640/ 3200]\n","\tTrain loss: 44.215257, Overfit loss: 44.195843, Valid loss: 45.169951, Divergences: 0  [ 1280/ 3200]\n","\tTrain loss: 43.951915, Overfit loss: 43.994295, Valid loss: 44.898388, Divergences: 0  [ 1920/ 3200]\n","\tTrain loss: 43.675188, Overfit loss: 43.655591, Valid loss: 44.643779, Divergences: 0  [ 2560/ 3200]\n","Epoch 14 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 43.466645, Overfit loss: 43.447046, Valid loss: 44.387964, Divergences: 0  [    0/ 3200]\n","\tTrain loss: 43.231906, Overfit loss: 43.205696, Valid loss: 44.149334, Divergences: 0  [  640/ 3200]\n","\tTrain loss: 43.042764, Overfit loss: 42.980159, Valid loss: 43.921721, Divergences: 0  [ 1280/ 3200]\n","\tTrain loss: 42.795519, Overfit loss: 42.821480, Valid loss: 43.699918, Divergences: 0  [ 1920/ 3200]\n","\tTrain loss: 42.589496, Overfit loss: 42.571329, Valid loss: 43.492381, Divergences: 0  [ 2560/ 3200]\n","Epoch 15 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 42.359539, Overfit loss: 42.385999, Valid loss: 43.285732, Divergences: 0  [    0/ 3200]\n","\tTrain loss: 42.204962, Overfit loss: 42.212108, Valid loss: 43.088340, Divergences: 0  [  640/ 3200]\n","\tTrain loss: 42.058063, Overfit loss: 42.066745, Valid loss: 42.906887, Divergences: 0  [ 1280/ 3200]\n","\tTrain loss: 41.840770, Overfit loss: 41.865787, Valid loss: 42.730071, Divergences: 0  [ 1920/ 3200]\n","\tTrain loss: 41.689304, Overfit loss: 41.699042, Valid loss: 42.551342, Divergences: 0  [ 2560/ 3200]\n","Epoch 16 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 41.553856, Overfit loss: 41.551786, Valid loss: 42.391625, Divergences: 0  [    0/ 3200]\n","\tTrain loss: 41.398740, Overfit loss: 41.392272, Valid loss: 42.225332, Divergences: 0  [  640/ 3200]\n","\tTrain loss: 41.278486, Overfit loss: 41.208464, Valid loss: 42.071635, Divergences: 0  [ 1280/ 3200]\n","\tTrain loss: 41.117124, Overfit loss: 41.086219, Valid loss: 41.915379, Divergences: 0  [ 1920/ 3200]\n","\tTrain loss: 40.966271, Overfit loss: 40.959705, Valid loss: 41.778514, Divergences: 0  [ 2560/ 3200]\n","Epoch 17 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 40.829159, Overfit loss: 40.814720, Valid loss: 41.637115, Divergences: 0  [    0/ 3200]\n","\tTrain loss: 40.689262, Overfit loss: 40.689020, Valid loss: 41.501971, Divergences: 0  [  640/ 3200]\n","\tTrain loss: 40.584577, Overfit loss: 40.583493, Valid loss: 41.370805, Divergences: 0  [ 1280/ 3200]\n","\tTrain loss: 40.459484, Overfit loss: 40.468485, Valid loss: 41.243801, Divergences: 0  [ 1920/ 3200]\n","\tTrain loss: 40.355081, Overfit loss: 40.351540, Valid loss: 41.126239, Divergences: 0  [ 2560/ 3200]\n","Epoch 18 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 40.209436, Overfit loss: 40.200489, Valid loss: 40.999325, Divergences: 0  [    0/ 3200]\n","\tTrain loss: 40.157513, Overfit loss: 40.107955, Valid loss: 40.884034, Divergences: 0  [  640/ 3200]\n","\tTrain loss: 40.029901, Overfit loss: 40.055222, Valid loss: 40.785899, Divergences: 0  [ 1280/ 3200]\n","\tTrain loss: 39.897070, Overfit loss: 39.907882, Valid loss: 40.667484, Divergences: 0  [ 1920/ 3200]\n","\tTrain loss: 39.834008, Overfit loss: 39.809091, Valid loss: 40.576033, Divergences: 0  [ 2560/ 3200]\n","Epoch 19 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 39.710557, Overfit loss: 39.728249, Valid loss: 40.466804, Divergences: 0  [    0/ 3200]\n","\tTrain loss: 39.619316, Overfit loss: 39.618920, Valid loss: 40.371019, Divergences: 0  [  640/ 3200]\n","\tTrain loss: 39.515680, Overfit loss: 39.526777, Valid loss: 40.280686, Divergences: 0  [ 1280/ 3200]\n","\tTrain loss: 39.474591, Overfit loss: 39.449411, Valid loss: 40.196959, Divergences: 0  [ 1920/ 3200]\n","\tTrain loss: 39.373422, Overfit loss: 39.342545, Valid loss: 40.093163, Divergences: 0  [ 2560/ 3200]\n","Epoch 20 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 39.299305, Overfit loss: 39.294635, Valid loss: 40.014552, Divergences: 0  [    0/ 3200]\n","\tTrain loss: 39.184630, Overfit loss: 39.229741, Valid loss: 39.928838, Divergences: 0  [  640/ 3200]\n","\tTrain loss: 39.124879, Overfit loss: 39.138379, Valid loss: 39.851749, Divergences: 0  [ 1280/ 3200]\n","\tTrain loss: 39.100003, Overfit loss: 39.076310, Valid loss: 39.776550, Divergences: 0  [ 1920/ 3200]\n","\tTrain loss: 39.003792, Overfit loss: 38.989843, Valid loss: 39.702700, Divergences: 0  [ 2560/ 3200]\n","\n","========================================================================================================================================================================================================\n","FullGDSC\n","========================================================================================================================================================================================================\n","Hyperparameters: {\n","    \"model\": {\n","        \"S_D\": 6,\n","        \"I_D\": 6,\n","        \"O_D\": 4,\n","        \"SNR\": 2.0\n","    },\n","    \"train\": {\n","        \"train_dataset_size\": 46,\n","        \"valid_dataset_size\": 100,\n","        \"total_train_sequence_length\": 2048,\n","        \"total_valid_sequence_length\": 20000,\n","        \"subsequence_length\": 10,\n","        \"subsequence_initial_mode\": \"random\",\n","        \"sample_efficiency\": 5,\n","        \"replay_buffer\": 10,\n","        \"batch_size\": 128,\n","        \"beta\": 0.1,\n","        \"lr\": 0.0002,\n","        \"momentum\": 0.9,\n","        \"lr_decay\": 0.99,\n","        \"optim_type\": \"GD\",\n","        \"l2_reg\": 0.1,\n","        \"iterations_per_epoch\": 100,\n","        \"epochs\": 20\n","    },\n","    \"experiment\": {\n","        \"n_systems\": 16,\n","        \"ensemble_size\": 1,\n","        \"log_frequency\": 5,\n","        \"print_frequency\": 20,\n","        \"exp_name\": \"FullGDSC\",\n","        \"output_dir\": \"sample_complexity\"\n","    }\n","}\n","========================================================================================================================================================================================================\n","Mean theoretical irreducible loss: 49.139793959708115\n","Epoch 1 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 298.866114, Overfit loss: 295.599651, Valid loss: 297.435101, Divergences: 0  [    0/ 4600]\n","\tTrain loss: 262.052085, Overfit loss: 260.848694, Valid loss: 262.324830, Divergences: 0  [  920/ 4600]\n","\tTrain loss: 242.913991, Overfit loss: 242.152803, Valid loss: 243.606878, Divergences: 0  [ 1840/ 4600]\n","\tTrain loss: 228.435203, Overfit loss: 227.748331, Valid loss: 229.301954, Divergences: 0  [ 2760/ 4600]\n","\tTrain loss: 215.643840, Overfit loss: 215.065079, Valid loss: 216.753391, Divergences: 0  [ 3680/ 4600]\n","Epoch 2 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 204.856960, Overfit loss: 204.354811, Valid loss: 206.245539, Divergences: 0  [    0/ 4600]\n","\tTrain loss: 195.664095, Overfit loss: 195.181605, Valid loss: 197.231777, Divergences: 0  [  920/ 4600]\n","\tTrain loss: 187.551454, Overfit loss: 187.127014, Valid loss: 189.161017, Divergences: 0  [ 1840/ 4600]\n","\tTrain loss: 180.060133, Overfit loss: 179.667115, Valid loss: 181.782915, Divergences: 0  [ 2760/ 4600]\n","\tTrain loss: 173.193987, Overfit loss: 172.764299, Valid loss: 174.883582, Divergences: 0  [ 3680/ 4600]\n","Epoch 3 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 166.539694, Overfit loss: 166.279982, Valid loss: 168.266437, Divergences: 0  [    0/ 4600]\n","\tTrain loss: 160.207698, Overfit loss: 159.846223, Valid loss: 161.893109, Divergences: 0  [  920/ 4600]\n","\tTrain loss: 154.053209, Overfit loss: 153.737129, Valid loss: 155.677880, Divergences: 0  [ 1840/ 4600]\n","\tTrain loss: 148.017211, Overfit loss: 147.706951, Valid loss: 149.643762, Divergences: 0  [ 2760/ 4600]\n","\tTrain loss: 142.153994, Overfit loss: 141.872581, Valid loss: 143.772645, Divergences: 0  [ 3680/ 4600]\n","Epoch 4 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 136.614821, Overfit loss: 136.240522, Valid loss: 138.150965, Divergences: 0  [    0/ 4600]\n","\tTrain loss: 131.208760, Overfit loss: 131.042544, Valid loss: 132.823878, Divergences: 0  [  920/ 4600]\n","\tTrain loss: 126.214642, Overfit loss: 125.958043, Valid loss: 127.757500, Divergences: 0  [ 1840/ 4600]\n","\tTrain loss: 121.453120, Overfit loss: 121.199894, Valid loss: 122.969449, Divergences: 0  [ 2760/ 4600]\n","\tTrain loss: 116.913400, Overfit loss: 116.745022, Valid loss: 118.449194, Divergences: 0  [ 3680/ 4600]\n","Epoch 5 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 112.723936, Overfit loss: 112.483811, Valid loss: 114.200989, Divergences: 0  [    0/ 4600]\n","\tTrain loss: 108.765263, Overfit loss: 108.617958, Valid loss: 110.264958, Divergences: 0  [  920/ 4600]\n","\tTrain loss: 105.070366, Overfit loss: 104.934223, Valid loss: 106.566703, Divergences: 0  [ 1840/ 4600]\n","\tTrain loss: 101.694713, Overfit loss: 101.519272, Valid loss: 103.108300, Divergences: 0  [ 2760/ 4600]\n","\tTrain loss: 98.483928, Overfit loss: 98.259805, Valid loss: 99.891106, Divergences: 0  [ 3680/ 4600]\n","Epoch 6 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 95.513065, Overfit loss: 95.319836, Valid loss: 96.893187, Divergences: 0  [    0/ 4600]\n","\tTrain loss: 92.719079, Overfit loss: 92.586864, Valid loss: 94.121104, Divergences: 0  [  920/ 4600]\n","\tTrain loss: 90.127197, Overfit loss: 90.076378, Valid loss: 91.540195, Divergences: 0  [ 1840/ 4600]\n","\tTrain loss: 87.692326, Overfit loss: 87.621888, Valid loss: 89.155969, Divergences: 0  [ 2760/ 4600]\n","\tTrain loss: 85.552449, Overfit loss: 85.369283, Valid loss: 86.929559, Divergences: 0  [ 3680/ 4600]\n","Epoch 7 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 83.395326, Overfit loss: 83.351649, Valid loss: 84.878087, Divergences: 0  [    0/ 4600]\n","\tTrain loss: 81.549493, Overfit loss: 81.482661, Valid loss: 82.981375, Divergences: 0  [  920/ 4600]\n","\tTrain loss: 79.745313, Overfit loss: 79.683287, Valid loss: 81.216250, Divergences: 0  [ 1840/ 4600]\n","\tTrain loss: 78.125839, Overfit loss: 78.038898, Valid loss: 79.576640, Divergences: 0  [ 2760/ 4600]\n","\tTrain loss: 76.606460, Overfit loss: 76.551787, Valid loss: 78.049822, Divergences: 0  [ 3680/ 4600]\n","Epoch 8 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 75.139775, Overfit loss: 75.124223, Valid loss: 76.640496, Divergences: 0  [    0/ 4600]\n","\tTrain loss: 73.874887, Overfit loss: 73.843669, Valid loss: 75.331866, Divergences: 0  [  920/ 4600]\n","\tTrain loss: 72.632394, Overfit loss: 72.655496, Valid loss: 74.110276, Divergences: 0  [ 1840/ 4600]\n","\tTrain loss: 71.538716, Overfit loss: 71.490586, Valid loss: 72.971466, Divergences: 0  [ 2760/ 4600]\n","\tTrain loss: 70.484271, Overfit loss: 70.436852, Valid loss: 71.905062, Divergences: 0  [ 3680/ 4600]\n","Epoch 9 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 69.523882, Overfit loss: 69.449193, Valid loss: 70.912446, Divergences: 0  [    0/ 4600]\n","\tTrain loss: 68.572142, Overfit loss: 68.526465, Valid loss: 69.984998, Divergences: 0  [  920/ 4600]\n","\tTrain loss: 67.788152, Overfit loss: 67.738086, Valid loss: 69.126452, Divergences: 0  [ 1840/ 4600]\n","\tTrain loss: 66.937785, Overfit loss: 67.006516, Valid loss: 68.324237, Divergences: 0  [ 2760/ 4600]\n","\tTrain loss: 66.240333, Overfit loss: 66.198937, Valid loss: 67.567329, Divergences: 0  [ 3680/ 4600]\n","Epoch 10 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 65.529433, Overfit loss: 65.517449, Valid loss: 66.852214, Divergences: 0  [    0/ 4600]\n","\tTrain loss: 64.867606, Overfit loss: 64.853961, Valid loss: 66.202300, Divergences: 0  [  920/ 4600]\n","\tTrain loss: 64.262303, Overfit loss: 64.222687, Valid loss: 65.588023, Divergences: 0  [ 1840/ 4600]\n","\tTrain loss: 63.682997, Overfit loss: 63.704783, Valid loss: 64.998168, Divergences: 0  [ 2760/ 4600]\n","\tTrain loss: 63.146621, Overfit loss: 63.125491, Valid loss: 64.449841, Divergences: 0  [ 3680/ 4600]\n","Epoch 11 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 62.623095, Overfit loss: 62.611887, Valid loss: 63.934188, Divergences: 0  [    0/ 4600]\n","\tTrain loss: 62.205900, Overfit loss: 62.144743, Valid loss: 63.447812, Divergences: 0  [  920/ 4600]\n","\tTrain loss: 61.724005, Overfit loss: 61.711733, Valid loss: 62.987170, Divergences: 0  [ 1840/ 4600]\n","\tTrain loss: 61.294564, Overfit loss: 61.235404, Valid loss: 62.551611, Divergences: 0  [ 2760/ 4600]\n","\tTrain loss: 60.849453, Overfit loss: 60.838686, Valid loss: 62.141809, Divergences: 0  [ 3680/ 4600]\n","Epoch 12 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 60.498252, Overfit loss: 60.459273, Valid loss: 61.744871, Divergences: 0  [    0/ 4600]\n","\tTrain loss: 60.107267, Overfit loss: 60.128139, Valid loss: 61.370005, Divergences: 0  [  920/ 4600]\n","\tTrain loss: 59.824572, Overfit loss: 59.829701, Valid loss: 61.021397, Divergences: 0  [ 1840/ 4600]\n","\tTrain loss: 59.455254, Overfit loss: 59.458776, Valid loss: 60.682449, Divergences: 0  [ 2760/ 4600]\n","\tTrain loss: 59.157134, Overfit loss: 59.134411, Valid loss: 60.359528, Divergences: 0  [ 3680/ 4600]\n","Epoch 13 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 58.818841, Overfit loss: 58.816292, Valid loss: 60.058318, Divergences: 0  [    0/ 4600]\n","\tTrain loss: 58.527530, Overfit loss: 58.489955, Valid loss: 59.760623, Divergences: 0  [  920/ 4600]\n","\tTrain loss: 58.283635, Overfit loss: 58.264012, Valid loss: 59.483095, Divergences: 0  [ 1840/ 4600]\n","\tTrain loss: 57.993356, Overfit loss: 57.994871, Valid loss: 59.206754, Divergences: 0  [ 2760/ 4600]\n","\tTrain loss: 57.759621, Overfit loss: 57.726081, Valid loss: 58.956746, Divergences: 0  [ 3680/ 4600]\n","Epoch 14 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 57.479355, Overfit loss: 57.505029, Valid loss: 58.721301, Divergences: 0  [    0/ 4600]\n","\tTrain loss: 57.270791, Overfit loss: 57.242269, Valid loss: 58.480482, Divergences: 0  [  920/ 4600]\n","\tTrain loss: 57.040609, Overfit loss: 57.028513, Valid loss: 58.244536, Divergences: 0  [ 1840/ 4600]\n","\tTrain loss: 56.841856, Overfit loss: 56.814144, Valid loss: 58.029791, Divergences: 0  [ 2760/ 4600]\n","\tTrain loss: 56.600360, Overfit loss: 56.620718, Valid loss: 57.814375, Divergences: 0  [ 3680/ 4600]\n","Epoch 15 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 56.390095, Overfit loss: 56.420085, Valid loss: 57.625866, Divergences: 0  [    0/ 4600]\n","\tTrain loss: 56.198645, Overfit loss: 56.199569, Valid loss: 57.426515, Divergences: 0  [  920/ 4600]\n","\tTrain loss: 56.023110, Overfit loss: 56.029106, Valid loss: 57.234379, Divergences: 0  [ 1840/ 4600]\n","\tTrain loss: 55.856090, Overfit loss: 55.865769, Valid loss: 57.062785, Divergences: 0  [ 2760/ 4600]\n","\tTrain loss: 55.669837, Overfit loss: 55.673694, Valid loss: 56.889611, Divergences: 0  [ 3680/ 4600]\n","Epoch 16 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 55.499488, Overfit loss: 55.539263, Valid loss: 56.719219, Divergences: 0  [    0/ 4600]\n","\tTrain loss: 55.349075, Overfit loss: 55.395096, Valid loss: 56.561684, Divergences: 0  [  920/ 4600]\n","\tTrain loss: 55.113217, Overfit loss: 55.239981, Valid loss: 56.409415, Divergences: 0  [ 1840/ 4600]\n","\tTrain loss: 55.034167, Overfit loss: 55.058710, Valid loss: 56.259209, Divergences: 0  [ 2760/ 4600]\n","\tTrain loss: 54.925860, Overfit loss: 54.916572, Valid loss: 56.104937, Divergences: 0  [ 3680/ 4600]\n","Epoch 17 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 54.764876, Overfit loss: 54.743397, Valid loss: 55.967633, Divergences: 0  [    0/ 4600]\n","\tTrain loss: 54.642564, Overfit loss: 54.738257, Valid loss: 55.825216, Divergences: 0  [  920/ 4600]\n","\tTrain loss: 54.588263, Overfit loss: 54.524355, Valid loss: 55.704376, Divergences: 0  [ 1840/ 4600]\n","\tTrain loss: 54.380171, Overfit loss: 54.388791, Valid loss: 55.586499, Divergences: 0  [ 2760/ 4600]\n","\tTrain loss: 54.255182, Overfit loss: 54.293632, Valid loss: 55.454693, Divergences: 0  [ 3680/ 4600]\n","Epoch 18 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 54.142963, Overfit loss: 54.149423, Valid loss: 55.333849, Divergences: 0  [    0/ 4600]\n","\tTrain loss: 54.040443, Overfit loss: 54.055539, Valid loss: 55.232706, Divergences: 0  [  920/ 4600]\n","\tTrain loss: 53.921378, Overfit loss: 53.936754, Valid loss: 55.126307, Divergences: 0  [ 1840/ 4600]\n","\tTrain loss: 53.830207, Overfit loss: 53.843651, Valid loss: 55.017769, Divergences: 0  [ 2760/ 4600]\n","\tTrain loss: 53.784258, Overfit loss: 53.782801, Valid loss: 54.909144, Divergences: 0  [ 3680/ 4600]\n","Epoch 19 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 53.673711, Overfit loss: 53.580825, Valid loss: 54.806280, Divergences: 0  [    0/ 4600]\n","\tTrain loss: 53.580524, Overfit loss: 53.508666, Valid loss: 54.719112, Divergences: 0  [  920/ 4600]\n","\tTrain loss: 53.413070, Overfit loss: 53.473385, Valid loss: 54.625072, Divergences: 0  [ 1840/ 4600]\n","\tTrain loss: 53.307718, Overfit loss: 53.345942, Valid loss: 54.523299, Divergences: 0  [ 2760/ 4600]\n","\tTrain loss: 53.197786, Overfit loss: 53.260307, Valid loss: 54.446048, Divergences: 0  [ 3680/ 4600]\n","Epoch 20 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 53.200602, Overfit loss: 53.188619, Valid loss: 54.356833, Divergences: 0  [    0/ 4600]\n","\tTrain loss: 53.090453, Overfit loss: 53.087886, Valid loss: 54.276499, Divergences: 0  [  920/ 4600]\n","\tTrain loss: 53.030122, Overfit loss: 53.045255, Valid loss: 54.192733, Divergences: 0  [ 1840/ 4600]\n","\tTrain loss: 52.945506, Overfit loss: 52.942436, Valid loss: 54.122160, Divergences: 0  [ 2760/ 4600]\n","\tTrain loss: 52.842692, Overfit loss: 52.817979, Valid loss: 54.050081, Divergences: 0  [ 3680/ 4600]\n","\n","========================================================================================================================================================================================================\n","FullGDSC\n","========================================================================================================================================================================================================\n","Hyperparameters: {\n","    \"model\": {\n","        \"S_D\": 6,\n","        \"I_D\": 6,\n","        \"O_D\": 4,\n","        \"SNR\": 2.0\n","    },\n","    \"train\": {\n","        \"train_dataset_size\": 64,\n","        \"valid_dataset_size\": 100,\n","        \"total_train_sequence_length\": 2048,\n","        \"total_valid_sequence_length\": 20000,\n","        \"subsequence_length\": 10,\n","        \"subsequence_initial_mode\": \"random\",\n","        \"sample_efficiency\": 5,\n","        \"replay_buffer\": 10,\n","        \"batch_size\": 128,\n","        \"beta\": 0.1,\n","        \"lr\": 0.0002,\n","        \"momentum\": 0.9,\n","        \"lr_decay\": 0.99,\n","        \"optim_type\": \"GD\",\n","        \"l2_reg\": 0.1,\n","        \"iterations_per_epoch\": 100,\n","        \"epochs\": 20\n","    },\n","    \"experiment\": {\n","        \"n_systems\": 16,\n","        \"ensemble_size\": 1,\n","        \"log_frequency\": 5,\n","        \"print_frequency\": 20,\n","        \"exp_name\": \"FullGDSC\",\n","        \"output_dir\": \"sample_complexity\"\n","    }\n","}\n","========================================================================================================================================================================================================\n","Mean theoretical irreducible loss: 50.206006976562364\n","Epoch 1 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 289.521997, Overfit loss: 287.084262, Valid loss: 288.464146, Divergences: 0  [    0/ 6400]\n","\tTrain loss: 263.255352, Overfit loss: 262.162653, Valid loss: 263.032687, Divergences: 0  [ 1280/ 6400]\n","\tTrain loss: 243.093281, Overfit loss: 242.258768, Valid loss: 242.693621, Divergences: 0  [ 2560/ 6400]\n","\tTrain loss: 230.192566, Overfit loss: 229.689951, Valid loss: 230.131836, Divergences: 0  [ 3840/ 6400]\n","\tTrain loss: 220.447227, Overfit loss: 220.073251, Valid loss: 220.712800, Divergences: 0  [ 5120/ 6400]\n","Epoch 2 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 211.840717, Overfit loss: 211.435118, Valid loss: 212.234125, Divergences: 0  [    0/ 6400]\n","\tTrain loss: 203.617416, Overfit loss: 203.171290, Valid loss: 204.058871, Divergences: 0  [ 1280/ 6400]\n","\tTrain loss: 195.499744, Overfit loss: 195.080652, Valid loss: 196.042066, Divergences: 0  [ 2560/ 6400]\n","\tTrain loss: 187.653585, Overfit loss: 187.263092, Valid loss: 188.244860, Divergences: 0  [ 3840/ 6400]\n","\tTrain loss: 179.986182, Overfit loss: 179.611806, Valid loss: 180.638998, Divergences: 0  [ 5120/ 6400]\n","Epoch 3 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 172.562178, Overfit loss: 172.192033, Valid loss: 173.257294, Divergences: 0  [    0/ 6400]\n","\tTrain loss: 165.394901, Overfit loss: 165.076200, Valid loss: 166.166082, Divergences: 0  [ 1280/ 6400]\n","\tTrain loss: 158.609845, Overfit loss: 158.227493, Valid loss: 159.342905, Divergences: 0  [ 2560/ 6400]\n","\tTrain loss: 152.043562, Overfit loss: 151.725232, Valid loss: 152.826650, Divergences: 0  [ 3840/ 6400]\n","\tTrain loss: 145.810693, Overfit loss: 145.554608, Valid loss: 146.633557, Divergences: 0  [ 5120/ 6400]\n","Epoch 4 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 139.992226, Overfit loss: 139.726114, Valid loss: 140.771342, Divergences: 0  [    0/ 6400]\n","\tTrain loss: 134.543339, Overfit loss: 134.271563, Valid loss: 135.302022, Divergences: 0  [ 1280/ 6400]\n","\tTrain loss: 129.449483, Overfit loss: 129.186801, Valid loss: 130.168229, Divergences: 0  [ 2560/ 6400]\n","\tTrain loss: 124.672691, Overfit loss: 124.345703, Valid loss: 125.355780, Divergences: 0  [ 3840/ 6400]\n","\tTrain loss: 120.092977, Overfit loss: 119.873372, Valid loss: 120.835210, Divergences: 0  [ 5120/ 6400]\n","Epoch 5 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 115.878045, Overfit loss: 115.783112, Valid loss: 116.625915, Divergences: 0  [    0/ 6400]\n","\tTrain loss: 111.982165, Overfit loss: 111.777460, Valid loss: 112.735189, Divergences: 0  [ 1280/ 6400]\n","\tTrain loss: 108.355132, Overfit loss: 108.181559, Valid loss: 109.113741, Divergences: 0  [ 2560/ 6400]\n","\tTrain loss: 104.949690, Overfit loss: 104.867871, Valid loss: 105.732610, Divergences: 0  [ 3840/ 6400]\n","\tTrain loss: 101.895676, Overfit loss: 101.723807, Valid loss: 102.576582, Divergences: 0  [ 5120/ 6400]\n","Epoch 6 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 98.876275, Overfit loss: 98.705694, Valid loss: 99.635386, Divergences: 0  [    0/ 6400]\n","\tTrain loss: 96.144961, Overfit loss: 95.991085, Valid loss: 96.882885, Divergences: 0  [ 1280/ 6400]\n","\tTrain loss: 93.561957, Overfit loss: 93.379447, Valid loss: 94.314162, Divergences: 0  [ 2560/ 6400]\n","\tTrain loss: 91.128661, Overfit loss: 90.979743, Valid loss: 91.896439, Divergences: 0  [ 3840/ 6400]\n","\tTrain loss: 88.865758, Overfit loss: 88.736049, Valid loss: 89.632664, Divergences: 0  [ 5120/ 6400]\n","Epoch 7 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 86.727954, Overfit loss: 86.630561, Valid loss: 87.515858, Divergences: 0  [    0/ 6400]\n","\tTrain loss: 84.771243, Overfit loss: 84.690814, Valid loss: 85.556976, Divergences: 0  [ 1280/ 6400]\n","\tTrain loss: 82.971185, Overfit loss: 82.821998, Valid loss: 83.722424, Divergences: 0  [ 2560/ 6400]\n","\tTrain loss: 81.210000, Overfit loss: 81.118215, Valid loss: 82.023962, Divergences: 0  [ 3840/ 6400]\n","\tTrain loss: 79.667812, Overfit loss: 79.646927, Valid loss: 80.425871, Divergences: 0  [ 5120/ 6400]\n","Epoch 8 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 78.126903, Overfit loss: 78.026301, Valid loss: 78.942793, Divergences: 0  [    0/ 6400]\n","\tTrain loss: 76.768020, Overfit loss: 76.617993, Valid loss: 77.582202, Divergences: 0  [ 1280/ 6400]\n","\tTrain loss: 75.510508, Overfit loss: 75.399352, Valid loss: 76.330234, Divergences: 0  [ 2560/ 6400]\n","\tTrain loss: 74.328102, Overfit loss: 74.288830, Valid loss: 75.154206, Divergences: 0  [ 3840/ 6400]\n","\tTrain loss: 73.250210, Overfit loss: 73.177955, Valid loss: 74.060562, Divergences: 0  [ 5120/ 6400]\n","Epoch 9 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 72.196105, Overfit loss: 72.229269, Valid loss: 73.044498, Divergences: 0  [    0/ 6400]\n","\tTrain loss: 71.246998, Overfit loss: 71.246838, Valid loss: 72.108720, Divergences: 0  [ 1280/ 6400]\n","\tTrain loss: 70.437239, Overfit loss: 70.359700, Valid loss: 71.228119, Divergences: 0  [ 2560/ 6400]\n","\tTrain loss: 69.596237, Overfit loss: 69.536631, Valid loss: 70.418028, Divergences: 0  [ 3840/ 6400]\n","\tTrain loss: 68.808994, Overfit loss: 68.739256, Valid loss: 69.657732, Divergences: 0  [ 5120/ 6400]\n","Epoch 10 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 68.084311, Overfit loss: 68.067378, Valid loss: 68.949034, Divergences: 0  [    0/ 6400]\n","\tTrain loss: 67.476409, Overfit loss: 67.418895, Valid loss: 68.299846, Divergences: 0  [ 1280/ 6400]\n","\tTrain loss: 66.832920, Overfit loss: 66.786630, Valid loss: 67.691565, Divergences: 0  [ 2560/ 6400]\n","\tTrain loss: 66.194553, Overfit loss: 66.205677, Valid loss: 67.126817, Divergences: 0  [ 3840/ 6400]\n","\tTrain loss: 65.802183, Overfit loss: 65.702121, Valid loss: 66.581374, Divergences: 0  [ 5120/ 6400]\n","Epoch 11 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 65.270741, Overfit loss: 65.232734, Valid loss: 66.087118, Divergences: 0  [    0/ 6400]\n","\tTrain loss: 64.781104, Overfit loss: 64.670592, Valid loss: 65.614180, Divergences: 0  [ 1280/ 6400]\n","\tTrain loss: 64.296196, Overfit loss: 64.399319, Valid loss: 65.172280, Divergences: 0  [ 2560/ 6400]\n","\tTrain loss: 63.851441, Overfit loss: 63.865010, Valid loss: 64.758446, Divergences: 0  [ 3840/ 6400]\n","\tTrain loss: 63.474517, Overfit loss: 63.525317, Valid loss: 64.356993, Divergences: 0  [ 5120/ 6400]\n","Epoch 12 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 63.160448, Overfit loss: 63.116770, Valid loss: 63.999106, Divergences: 0  [    0/ 6400]\n","\tTrain loss: 62.859709, Overfit loss: 62.804599, Valid loss: 63.640310, Divergences: 0  [ 1280/ 6400]\n","\tTrain loss: 62.403982, Overfit loss: 62.410659, Valid loss: 63.301071, Divergences: 0  [ 2560/ 6400]\n","\tTrain loss: 62.137687, Overfit loss: 62.146933, Valid loss: 62.991109, Divergences: 0  [ 3840/ 6400]\n","\tTrain loss: 61.847341, Overfit loss: 61.808834, Valid loss: 62.678944, Divergences: 0  [ 5120/ 6400]\n","Epoch 13 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 61.533005, Overfit loss: 61.515582, Valid loss: 62.392188, Divergences: 0  [    0/ 6400]\n","\tTrain loss: 61.254334, Overfit loss: 61.301179, Valid loss: 62.115798, Divergences: 0  [ 1280/ 6400]\n","\tTrain loss: 60.974744, Overfit loss: 60.951562, Valid loss: 61.865671, Divergences: 0  [ 2560/ 6400]\n","\tTrain loss: 60.744737, Overfit loss: 60.768328, Valid loss: 61.610842, Divergences: 0  [ 3840/ 6400]\n","\tTrain loss: 60.521533, Overfit loss: 60.449047, Valid loss: 61.366797, Divergences: 0  [ 5120/ 6400]\n","Epoch 14 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 60.298000, Overfit loss: 60.330807, Valid loss: 61.127708, Divergences: 0  [    0/ 6400]\n","\tTrain loss: 60.065152, Overfit loss: 59.983984, Valid loss: 60.908919, Divergences: 0  [ 1280/ 6400]\n","\tTrain loss: 59.842532, Overfit loss: 59.857670, Valid loss: 60.697123, Divergences: 0  [ 2560/ 6400]\n","\tTrain loss: 59.633035, Overfit loss: 59.608382, Valid loss: 60.497665, Divergences: 0  [ 3840/ 6400]\n","\tTrain loss: 59.477432, Overfit loss: 59.426686, Valid loss: 60.291197, Divergences: 0  [ 5120/ 6400]\n","Epoch 15 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 59.279740, Overfit loss: 59.264777, Valid loss: 60.100041, Divergences: 0  [    0/ 6400]\n","\tTrain loss: 59.117903, Overfit loss: 59.046207, Valid loss: 59.913967, Divergences: 0  [ 1280/ 6400]\n","\tTrain loss: 58.879272, Overfit loss: 58.882497, Valid loss: 59.747905, Divergences: 0  [ 2560/ 6400]\n","\tTrain loss: 58.724323, Overfit loss: 58.703077, Valid loss: 59.576560, Divergences: 0  [ 3840/ 6400]\n","\tTrain loss: 58.495474, Overfit loss: 58.576333, Valid loss: 59.397363, Divergences: 0  [ 5120/ 6400]\n","Epoch 16 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 58.455137, Overfit loss: 58.486759, Valid loss: 59.236286, Divergences: 0  [    0/ 6400]\n","\tTrain loss: 58.225379, Overfit loss: 58.270671, Valid loss: 59.076509, Divergences: 0  [ 1280/ 6400]\n","\tTrain loss: 58.084100, Overfit loss: 58.139081, Valid loss: 58.914575, Divergences: 0  [ 2560/ 6400]\n","\tTrain loss: 57.924404, Overfit loss: 57.972649, Valid loss: 58.766458, Divergences: 0  [ 3840/ 6400]\n","\tTrain loss: 57.804510, Overfit loss: 57.855667, Valid loss: 58.623990, Divergences: 0  [ 5120/ 6400]\n","Epoch 17 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 57.738471, Overfit loss: 57.683826, Valid loss: 58.473023, Divergences: 0  [    0/ 6400]\n","\tTrain loss: 57.505302, Overfit loss: 57.562273, Valid loss: 58.335069, Divergences: 0  [ 1280/ 6400]\n","\tTrain loss: 57.455725, Overfit loss: 57.470262, Valid loss: 58.200098, Divergences: 0  [ 2560/ 6400]\n","\tTrain loss: 57.279598, Overfit loss: 57.297964, Valid loss: 58.066637, Divergences: 0  [ 3840/ 6400]\n","\tTrain loss: 57.138991, Overfit loss: 57.156374, Valid loss: 57.936888, Divergences: 0  [ 5120/ 6400]\n","Epoch 18 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 56.980129, Overfit loss: 57.032103, Valid loss: 57.808730, Divergences: 0  [    0/ 6400]\n","\tTrain loss: 56.845800, Overfit loss: 56.978150, Valid loss: 57.678433, Divergences: 0  [ 1280/ 6400]\n","\tTrain loss: 56.875947, Overfit loss: 56.755828, Valid loss: 57.566983, Divergences: 0  [ 2560/ 6400]\n","\tTrain loss: 56.746254, Overfit loss: 56.719424, Valid loss: 57.427761, Divergences: 0  [ 3840/ 6400]\n","\tTrain loss: 56.583445, Overfit loss: 56.516622, Valid loss: 57.313310, Divergences: 0  [ 5120/ 6400]\n","Epoch 19 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 56.370082, Overfit loss: 56.447307, Valid loss: 57.196896, Divergences: 0  [    0/ 6400]\n","\tTrain loss: 56.348719, Overfit loss: 56.391370, Valid loss: 57.084253, Divergences: 0  [ 1280/ 6400]\n","\tTrain loss: 56.281945, Overfit loss: 56.242500, Valid loss: 56.974713, Divergences: 0  [ 2560/ 6400]\n","\tTrain loss: 56.155598, Overfit loss: 56.067905, Valid loss: 56.877728, Divergences: 0  [ 3840/ 6400]\n","\tTrain loss: 56.003284, Overfit loss: 56.058883, Valid loss: 56.762723, Divergences: 0  [ 5120/ 6400]\n","Epoch 20 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 56.019743, Overfit loss: 55.922685, Valid loss: 56.667061, Divergences: 0  [    0/ 6400]\n","\tTrain loss: 55.831252, Overfit loss: 55.802158, Valid loss: 56.555184, Divergences: 0  [ 1280/ 6400]\n","\tTrain loss: 55.821163, Overfit loss: 55.717316, Valid loss: 56.480747, Divergences: 0  [ 2560/ 6400]\n","\tTrain loss: 55.649015, Overfit loss: 55.617496, Valid loss: 56.376445, Divergences: 0  [ 3840/ 6400]\n","\tTrain loss: 55.604470, Overfit loss: 55.535154, Valid loss: 56.299008, Divergences: 0  [ 5120/ 6400]\n","\n","========================================================================================================================================================================================================\n","FullGDSC\n","========================================================================================================================================================================================================\n","Hyperparameters: {\n","    \"model\": {\n","        \"S_D\": 6,\n","        \"I_D\": 6,\n","        \"O_D\": 4,\n","        \"SNR\": 2.0\n","    },\n","    \"train\": {\n","        \"train_dataset_size\": 1,\n","        \"valid_dataset_size\": 100,\n","        \"total_train_sequence_length\": 2897,\n","        \"total_valid_sequence_length\": 20000,\n","        \"subsequence_length\": 10,\n","        \"subsequence_initial_mode\": \"random\",\n","        \"sample_efficiency\": 5,\n","        \"replay_buffer\": 10,\n","        \"batch_size\": 128,\n","        \"beta\": 0.1,\n","        \"lr\": 0.0002,\n","        \"momentum\": 0.9,\n","        \"lr_decay\": 0.99,\n","        \"optim_type\": \"GD\",\n","        \"l2_reg\": 0.1,\n","        \"iterations_per_epoch\": 100,\n","        \"epochs\": 20\n","    },\n","    \"experiment\": {\n","        \"n_systems\": 16,\n","        \"ensemble_size\": 1,\n","        \"log_frequency\": 5,\n","        \"print_frequency\": 20,\n","        \"exp_name\": \"FullGDSC\",\n","        \"output_dir\": \"sample_complexity\"\n","    }\n","}\n","========================================================================================================================================================================================================\n","Mean theoretical irreducible loss: 44.2327078120765\n","Epoch 1 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 362.319704, Overfit loss: 358.828563, Valid loss: 356.075475, Divergences: 0  [    0/  100]\n","\tTrain loss: 322.928737, Overfit loss: 321.678488, Valid loss: 319.365797, Divergences: 0  [   20/  100]\n","\tTrain loss: 302.338320, Overfit loss: 301.411386, Valid loss: 299.386086, Divergences: 0  [   40/  100]\n","\tTrain loss: 284.079227, Overfit loss: 283.185644, Valid loss: 281.268520, Divergences: 0  [   60/  100]\n","\tTrain loss: 266.418053, Overfit loss: 265.549994, Valid loss: 263.734485, Divergences: 0  [   80/  100]\n","Epoch 2 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 249.481224, Overfit loss: 248.661712, Valid loss: 246.974418, Divergences: 0  [    0/  100]\n","\tTrain loss: 233.577928, Overfit loss: 232.807024, Valid loss: 231.277858, Divergences: 0  [   20/  100]\n","\tTrain loss: 218.668796, Overfit loss: 217.958737, Valid loss: 216.585244, Divergences: 0  [   40/  100]\n","\tTrain loss: 205.016184, Overfit loss: 204.365050, Valid loss: 203.154960, Divergences: 0  [   60/  100]\n","\tTrain loss: 192.657168, Overfit loss: 192.071842, Valid loss: 191.048761, Divergences: 0  [   80/  100]\n","Epoch 3 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 181.391535, Overfit loss: 180.856509, Valid loss: 180.046058, Divergences: 0  [    0/  100]\n","\tTrain loss: 170.977536, Overfit loss: 170.480409, Valid loss: 169.885778, Divergences: 0  [   20/  100]\n","\tTrain loss: 161.125113, Overfit loss: 160.643137, Valid loss: 160.274391, Divergences: 0  [   40/  100]\n","\tTrain loss: 151.781109, Overfit loss: 151.330922, Valid loss: 151.171568, Divergences: 0  [   60/  100]\n","\tTrain loss: 143.003245, Overfit loss: 142.572243, Valid loss: 142.613901, Divergences: 0  [   80/  100]\n","Epoch 4 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 134.796537, Overfit loss: 134.409466, Valid loss: 134.615579, Divergences: 0  [    0/  100]\n","\tTrain loss: 127.292022, Overfit loss: 126.925644, Valid loss: 127.281245, Divergences: 0  [   20/  100]\n","\tTrain loss: 120.397627, Overfit loss: 120.076580, Valid loss: 120.533085, Divergences: 0  [   40/  100]\n","\tTrain loss: 114.148664, Overfit loss: 113.846745, Valid loss: 114.400420, Divergences: 0  [   60/  100]\n","\tTrain loss: 108.501317, Overfit loss: 108.226719, Valid loss: 108.855342, Divergences: 0  [   80/  100]\n","Epoch 5 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 103.432035, Overfit loss: 103.190393, Valid loss: 103.873232, Divergences: 0  [    0/  100]\n","\tTrain loss: 98.907269, Overfit loss: 98.692148, Valid loss: 99.406410, Divergences: 0  [   20/  100]\n","\tTrain loss: 94.832435, Overfit loss: 94.645121, Valid loss: 95.393441, Divergences: 0  [   40/  100]\n","\tTrain loss: 91.177596, Overfit loss: 91.005984, Valid loss: 91.763565, Divergences: 0  [   60/  100]\n","\tTrain loss: 87.891857, Overfit loss: 87.737282, Valid loss: 88.495145, Divergences: 0  [   80/  100]\n","Epoch 6 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 84.931965, Overfit loss: 84.790392, Valid loss: 85.552399, Divergences: 0  [    0/  100]\n","\tTrain loss: 82.288288, Overfit loss: 82.172488, Valid loss: 82.933863, Divergences: 0  [   20/  100]\n","\tTrain loss: 79.919592, Overfit loss: 79.819572, Valid loss: 80.583415, Divergences: 0  [   40/  100]\n","\tTrain loss: 77.796832, Overfit loss: 77.688839, Valid loss: 78.459818, Divergences: 0  [   60/  100]\n","\tTrain loss: 75.877789, Overfit loss: 75.791670, Valid loss: 76.552847, Divergences: 0  [   80/  100]\n","Epoch 7 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 74.154961, Overfit loss: 74.073252, Valid loss: 74.838947, Divergences: 0  [    0/  100]\n","\tTrain loss: 72.616285, Overfit loss: 72.541638, Valid loss: 73.299255, Divergences: 0  [   20/  100]\n","\tTrain loss: 71.221552, Overfit loss: 71.147718, Valid loss: 71.903505, Divergences: 0  [   40/  100]\n","\tTrain loss: 69.942719, Overfit loss: 69.884998, Valid loss: 70.637029, Divergences: 0  [   60/  100]\n","\tTrain loss: 68.795174, Overfit loss: 68.735162, Valid loss: 69.475103, Divergences: 0  [   80/  100]\n","Epoch 8 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 67.731749, Overfit loss: 67.685068, Valid loss: 68.433096, Divergences: 0  [    0/  100]\n","\tTrain loss: 66.774425, Overfit loss: 66.729415, Valid loss: 67.471637, Divergences: 0  [   20/  100]\n","\tTrain loss: 65.879691, Overfit loss: 65.840853, Valid loss: 66.588447, Divergences: 0  [   40/  100]\n","\tTrain loss: 65.058966, Overfit loss: 65.016329, Valid loss: 65.756020, Divergences: 0  [   60/  100]\n","\tTrain loss: 64.298373, Overfit loss: 64.257358, Valid loss: 65.003670, Divergences: 0  [   80/  100]\n","Epoch 9 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 63.573499, Overfit loss: 63.546039, Valid loss: 64.289243, Divergences: 0  [    0/  100]\n","\tTrain loss: 62.924045, Overfit loss: 62.891369, Valid loss: 63.631815, Divergences: 0  [   20/  100]\n","\tTrain loss: 62.303010, Overfit loss: 62.275631, Valid loss: 63.008817, Divergences: 0  [   40/  100]\n","\tTrain loss: 61.733425, Overfit loss: 61.694089, Valid loss: 62.442867, Divergences: 0  [   60/  100]\n","\tTrain loss: 61.174722, Overfit loss: 61.148790, Valid loss: 61.877524, Divergences: 0  [   80/  100]\n","Epoch 10 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 60.659246, Overfit loss: 60.632809, Valid loss: 61.353839, Divergences: 0  [    0/  100]\n","\tTrain loss: 60.181996, Overfit loss: 60.158694, Valid loss: 60.877447, Divergences: 0  [   20/  100]\n","\tTrain loss: 59.717028, Overfit loss: 59.691995, Valid loss: 60.414496, Divergences: 0  [   40/  100]\n","\tTrain loss: 59.280080, Overfit loss: 59.255261, Valid loss: 59.976547, Divergences: 0  [   60/  100]\n","\tTrain loss: 58.857848, Overfit loss: 58.859434, Valid loss: 59.568324, Divergences: 0  [   80/  100]\n","Epoch 11 ----------------------------------------------------------------------------------------------------\n","\tTrain loss: 58.460535, Overfit loss: 58.442910, Valid loss: 59.171642, Divergences: 0  [    0/  100]\n","\tTrain loss: 58.085111, Overfit loss: 58.063305, Valid loss: 58.773189, Divergences: 0  [   20/  100]\n","\tTrain loss: 57.718300, Overfit loss: 57.701288, Valid loss: 58.402017, Divergences: 0  [   40/  100]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j4U0zXpJQXCj"},"outputs":[],"source":["H, W = len(optim_configs), len(system_configs)\n","plt.rcParams['figure.figsize'] = (12.0, 20.0)\n","fig, axs = plt.subplots(H, 2 * W, subplot_kw={'projection': '3d'})\n","\n","tail = 10\n","c = 5.\n","for (h, (optim_config_name, _)), (w, (system_config_name, _)) in itertools.product(\n","    enumerate(optim_configs),\n","    enumerate(system_configs)\n","):\n","    exp_name = system_config_name + optim_config_name + base_exp_name\n","    r = result[optim_config_name, system_config_name]\n","\n","    training_loss, overfit_loss, validation_loss, irreducible_loss = (r[k].detach().cpu() for k in (\n","        'training_loss',\n","        'overfit_loss',\n","        'validation_loss',\n","        'irreducible_loss'\n","    ))\n","\n","    normalized_validation_loss = torch.mean(validation_loss[:, :, :, :, -tail:], dim=-1) / irreducible_loss\n","    mean_normalized_validation_loss = torch.nan_to_num(torch.mean(normalized_validation_loss, dim=(2, 3)), nan=c)\n","    # mean_normalized_validation_loss[mean_normalized_validation_loss > 10000.] = c\n","\n","    x_mesh, y_mesh = torch.meshgrid(\n","        torch.DoubleTensor(total_trace_lengths),\n","        torch.DoubleTensor(num_traces)\n","    )\n","\n","\n","    axs[h, 2 * w].view_init(elev=15., azim=90.)\n","    axs[h, 2 * w].scatter(x_mesh, y_mesh, mean_normalized_validation_loss, s=20, c=mean_normalized_validation_loss, cmap=plt.cm.YlOrRd_r)\n","\n","    axs[h, 2 * w].set_xlabel('total_trace_length')\n","    axs[h, 2 * w].set_xscale('log')\n","    axs[h, 2 * w].set_ylabel('num_traces')\n","    axs[h, 2 * w].set_yscale('log')\n","    axs[h, 2 * w].set_zlim(bottom=0)\n","    axs[h, 2 * w].set_zlabel('validation_loss')\n","    axs[h, 2 * w].set_title(exp_name)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JcVgS_-eb_d8"},"outputs":[],"source":["H, W = len(optim_configs), len(system_configs)\n","plt.rcParams['figure.figsize'] = (12.0, 20.0)\n","fig, axs = plt.subplots(H, 2 * W, subplot_kw={'projection': '3d'})\n","\n","tail = 10\n","c = 5.\n","for (h, (optim_config_name, _)), (w, (system_config_name, _)) in itertools.product(\n","    enumerate(optim_configs),\n","    enumerate(system_configs)\n","):\n","    exp_name = system_config_name + optim_config_name + base_exp_name\n","    r = result[optim_config_name, system_config_name]\n","\n","    training_loss, overfit_loss, validation_loss, irreducible_loss = (r[k].detach().cpu() for k in (\n","        'training_loss',\n","        'overfit_loss',\n","        'validation_loss',\n","        'irreducible_loss'\n","    ))\n","\n","    print(validation_loss.shape, irreducible_loss.shape)\n","\n","    normalized_validation_loss = torch.mean(validation_loss[:, :, :, :, -tail:], dim=-1) / irreducible_loss\n","    mean_normalized_validation_loss = torch.nan_to_num(torch.mean(normalized_validation_loss, dim=(2, 3)), nan=c)\n","    mean_normalized_validation_loss[mean_normalized_validation_loss > 10000.] = c\n","\n","    lr_factors_mesh, momentums_mesh = torch.meshgrid(torch.log2(torch.DoubleTensor(total_trace_lengths)), torch.log2(torch.DoubleTensor(num_traces)))\n","\n","    # View 1\n","    axs[h, 2 * w].view_init(elev=15., azim=105.)\n","    axs[h, 2 * w].plot_surface(lr_factors_mesh[:, 2:], momentums_mesh[:, 2:], mean_normalized_validation_loss[:, 2:], c=mean_normalized_validation_loss, s=10, cmap=plt.cm.YlOrRd_r)\n","\n","    axs[h, 2 * w].set_xlabel('total_trace_length')\n","    axs[h, 2 * w].set_ylabel('num_traces')\n","    axs[h, 2 * w].set_zlim(bottom=0)\n","    axs[h, 2 * w].set_zlabel('validation_loss')\n","    axs[h, 2 * w].set_title(exp_name)\n","\n","    # View 2\n","    axs[h, 2 * w + 1].view_init(elev=15., azim=90.)\n","    axs[h, 2 * w + 1].plot_surface(lr_factors_mesh[:, 2:], momentums_mesh[:, 2:], mean_normalized_validation_loss[:, 2:], c=mean_normalized_validation_loss, s=10, cmap=plt.cm.YlOrRd_r)\n","\n","    axs[h, 2 * w + 1].set_xlabel('total_trace_length')\n","    axs[h, 2 * w + 1].set_ylabel('num_traces')\n","    axs[h, 2 * w + 1].set_zlim(bottom=0)\n","    axs[h, 2 * w + 1].set_zlabel('validation_loss')\n","    axs[h, 2 * w + 1].set_title(exp_name)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K-vHA1WL5uR2"},"outputs":[],"source":["H, W = len(optim_configs), len(system_configs)\n","plt.rcParams['figure.figsize'] = (12.0, 20.0)\n","fig, axs = plt.subplots(H, W)\n","\n","for h, (optim_config_name, _) in enumerate(optim_configs):\n","    for w, (system_config_name, _) in enumerate(system_configs):\n","        exp_name = system_config_name + optim_config_name + base_exp_name\n","\n","        r = result[optim_config_name][system_config_name]\n","\n","        training_loss, overfit_loss, validation_loss, irreducible_loss = (r[k].detach().cpu() for k in (\n","            'training_loss',\n","            'overfit_loss',\n","            'validation_loss',\n","            'irreducible_loss'\n","        ))\n","\n","        x = torch.arange(training_loss.shape[-1], dtype=float)\n","        irreducible_loss = irreducible_loss[:, :1]\n","\n","        axs[h, w].plot(x, torch.ones_like(x), linestyle='--', linewidth=0.5, color='black', label='normalized irreducible_loss')\n","        for lname in ('training_loss', 'overfit_loss', 'validation_loss'):\n","            loss = torch.mean(eval(lname), dim=1)\n","            normalized_loss = loss / irreducible_loss\n","\n","            mean_normalized_loss = torch.mean(normalized_loss, dim=0)\n","            min_normalized_loss = torch.min(normalized_loss, dim=0)\n","            max_normalized_loss = torch.max(normalized_loss, dim=0)\n","\n","            axs[h, w].plot(x, min_normalized_loss.values, linewidth=0.5, label=f'mean normalized {lname}')\n","        #     plt.fill_between(x, min_normalized_loss, max_normalized_loss, alpha=0.2)\n","\n","        axs[h, w].set_xlabel('Batch')\n","        axs[h, w].set_ylabel('Normalized Loss')\n","        axs[h, w].set_title(exp_name)\n","        # axs[h, w].legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ySyo5rO2k5sP"},"outputs":[],"source":["H, W = len(optim_configs), len(system_configs)\n","plt.rcParams['figure.figsize'] = (12.0, 20.0)\n","fig, axs = plt.subplots(H, W)\n","\n","tail = 10\n","cutoff = 100\n","for h, (optim_config_name, _) in enumerate(optim_configs):\n","    for w, (system_config_name, _) in enumerate(system_configs):\n","        exp_name = system_config_name + optim_config_name + base_exp_name\n","\n","        r = result[optim_config_name][system_config_name]\n","\n","        training_loss, overfit_loss, validation_loss, irreducible_loss = (r[k].detach().cpu() for k in (\n","            'training_loss',\n","            'overfit_loss',\n","            'validation_loss',\n","            'irreducible_loss'\n","        ))\n","\n","        x = torch.arange(cutoff, training_loss.shape[-1], dtype=float)\n","\n","        axs[h, w].plot(x, torch.ones_like(x), linestyle='--', linewidth=1., color='black', label='normalized irreducible_loss')\n","        normalized_overfit_loss = overfit_loss / irreducible_loss[:, :, None]\n","        normalized_validation_loss = validation_loss / irreducible_loss[:, :, None]\n","\n","        N = len(irreducible_loss)\n","        for n, (overfit_loss, validation_loss) in list(enumerate(zip(normalized_overfit_loss, normalized_validation_loss)))[::2]:\n","            mean_overfit_loss = torch.mean(overfit_loss, dim=0)[cutoff:]\n","            mean_validation_loss = torch.mean(validation_loss, dim=0)[cutoff:]\n","\n","            c = color(n, scale=N)\n","            axs[h, w].plot(x, mean_overfit_loss, linewidth=1., color=c, label=f'Experiment {n}')\n","            axs[h, w].plot(x, mean_validation_loss, linewidth=1., color=c)\n","            axs[h, w].fill_between(x, mean_overfit_loss, mean_validation_loss, alpha=0.1, color=c)\n","\n","        axs[h, w].set_xlabel('Batch')\n","        axs[h, w].set_ylabel('Normalized Loss')\n","        axs[h, w].set_title(f'{exp_name} - Normalized Overfit Loss')\n","        # axs[h, w].legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vp7Qps54WBoq"},"outputs":[],"source":["H, W = len(optim_configs), len(system_configs)\n","plt.rcParams['figure.figsize'] = (12.0, 20.0)\n","fig, axs = plt.subplots(H, W)\n","\n","tail = 10\n","for h, (optim_config_name, _) in enumerate(optim_configs):\n","    for w, (system_config_name, _) in enumerate(system_configs):\n","        exp_name = system_config_name + optim_config_name + base_exp_name\n","\n","        r = result[optim_config_name][system_config_name]\n","\n","        training_loss, overfit_loss, validation_loss, irreducible_loss = (r[k].detach().cpu() for k in (\n","            'training_loss',\n","            'overfit_loss',\n","            'validation_loss',\n","            'irreducible_loss'\n","        ))\n","\n","        normalized_overfit_loss = overfit_loss / irreducible_loss[:, :, None]\n","        normalized_validation_loss = validation_loss / irreducible_loss[:, :, None]\n","\n","        irreducible_, indices = torch.sort(irreducible_loss[:, 0])\n","        tail_ = torch.mean(normalized_overfit_loss[:, :, -tail:], dim=-1)\n","        mean_ = torch.mean(tail_, dim=1)[indices]\n","        std_ = torch.std(tail_, dim=1)[indices]\n","        min_ = tail_[torch.arange(len(mean_)), torch.argmin(tail_, dim=1)][indices]\n","        max_ = tail_[torch.arange(len(mean_)), torch.argmax(tail_, dim=1)][indices]\n","\n","\n","        axs_twinx = axs[h, w].twinx()\n","        axs[h, w].plot(irreducible_, torch.zeros_like(mean_), linewidth=1., linestyle='--', marker='.', color='black', label=f'Mean loss')\n","        axs_twinx.plot(irreducible_, mean_, linewidth=1., marker='.', color='blue', label='mean overfit loss')\n","\n","        axs[h, w].plot(irreducible_, min_ - mean_, linewidth=0.5, marker='.', color='turquoise')\n","        # axs[h, w].plot(mean_, max_ - mean_, linewidth=0.5, marker='.', color='turquoise')\n","\n","        axs[h, w].fill_between(irreducible_, min_ - mean_, max_ - mean_, color='aquamarine', alpha=0.2, label='min-max')\n","        axs[h, w].fill_between(irreducible_, -std_, std_, color='aquamarine', alpha=0.5, label='1 std')\n","\n","        axs[h, w].set_xlabel('Normalized mean loss per system')\n","        axs[h, w].set_title(f'{exp_name}')\n","        # axs[h, w].legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1zBSjk02yXHW"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1lcHhNw_r_eetYfC5dd7wEm_Cgw7yytr7","timestamp":1698522777293},{"file_id":"1q9Qx12ZP6MjTkUXpm6XF0Tw68M9eUD0c","timestamp":1693268309398}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}