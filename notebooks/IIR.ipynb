{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QupgVmcZgvyx",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700976383092,
     "user_tz": 480,
     "elapsed": 4,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     }
    }
   },
   "outputs": [],
   "source": [
    "## Created by Wentinn Liao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k722vkzdWafR"
   },
   "source": [
    "# Kalman Filter Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17459,
     "status": "ok",
     "timestamp": 1700976400548,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     },
     "user_tz": 480
    },
    "id": "S27iMYAOuWiB",
    "outputId": "17d6e69d-0c60-4f8f-a6be-bdac49e6e44d"
   },
   "outputs": [],
   "source": [
    "#@title Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1700976400548,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     },
     "user_tz": 480
    },
    "id": "0xHh9PF6hl3R",
    "outputId": "bd7f976b-b47a-4778-b027-114ed1a873a1"
   },
   "outputs": [],
   "source": [
    "#@title Symlink Setup\n",
    "import os\n",
    "\n",
    "def ptpp(PATH: str) -> str: # Converts path to python path\n",
    "    return PATH.replace('\\\\', '')\n",
    "\n",
    "DRIVE_PATH = '/content/gdrive/My\\ Drive/KF_RNN'\n",
    "if not os.path.exists(ptpp(DRIVE_PATH)):\n",
    "    %mkdir $DRIVE_PATH\n",
    "SYM_PATH = '/content/KF_RNN'\n",
    "if not os.path.exists(ptpp(SYM_PATH)):\n",
    "    !ln -s $DRIVE_PATH $SYM_PATH\n",
    "%cd $SYM_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 173676,
     "status": "ok",
     "timestamp": 1700976574222,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     },
     "user_tz": 480
    },
    "id": "-h7SwLD3uWiC",
    "outputId": "9d535db0-7d61-44bd-c83d-b803373692f3"
   },
   "outputs": [],
   "source": [
    "!pip install numpy imageio matplotlib ipympl scikit-learn torch==2.0.0 tensordict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9pbdKYaruWiD",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700976574547,
     "user_tz": 480,
     "elapsed": 329,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     }
    }
   },
   "outputs": [],
   "source": [
    "#@title Configure Jupyter Notebook\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uK2SmUy3uWiD",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700979063688,
     "user_tz": 480,
     "elapsed": 328,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     }
    }
   },
   "outputs": [],
   "source": [
    "#@title Library Setup\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import *\n",
    "from argparse import Namespace\n",
    "import copy\n",
    "import itertools\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fn\n",
    "import torch.utils as ptu\n",
    "import tensordict\n",
    "from tensordict import TensorDict\n",
    "from matplotlib.collections import PolyCollection\n",
    "\n",
    "from model.linear_system import LinearSystem\n",
    "from model.analytical_kf import AnalyticalKF\n",
    "from model.rnn_kf import RnnKF\n",
    "from model.cnn_kf import CnnKF\n",
    "\n",
    "from infrastructure import utils\n",
    "from infrastructure.train import *\n",
    "\n",
    "\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "dev_type = 'cpu'\n",
    "if dev_type == 'xla':\n",
    "    !pip install torch-xla cloud-tpu-client https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl\n",
    "    import torch_xla\n",
    "    import torch_xla.core.xla_model as xm\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (7.0, 5.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1700976582004,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     },
     "user_tz": 480
    },
    "id": "k0CCnpY3yIej",
    "outputId": "6aa27499-1729-4006-beb0-71ad674d3b09"
   },
   "outputs": [],
   "source": [
    "modelArgs = Namespace(\n",
    "    S_D = 2,\n",
    "    I_D = 2,\n",
    "    O_D = 1,\n",
    "    SNR = 2.\n",
    ")\n",
    "B, L = 1, 4\n",
    "\n",
    "system = LinearSystem.sample_stable_system(modelArgs)\n",
    "optimal_kf = KF(system)\n",
    "learned_kf = RnnKF(modelArgs)\n",
    "\n",
    "test_state = torch.randint(-10, 11, (B, modelArgs.S_D), dtype=float)\n",
    "test_inputs = torch.randint(-10, 11, (B, L, modelArgs.I_D), dtype=float)\n",
    "test_observations = torch.randint(-10, 11, (B, L, modelArgs.O_D), dtype=float)\n",
    "\n",
    "# print(system(test_state, test_inputs))\n",
    "# print(optimal_kf(test_state, test_inputs, test_observations))\n",
    "result1 = learned_kf(test_state, test_inputs, test_observations)\n",
    "result2 = learned_kf(test_state, test_inputs, test_observations, mode='form')\n",
    "result3 = learned_kf(test_state, test_inputs, test_observations, mode='form_sqrt')\n",
    "\n",
    "# print(torch.norm(result1['state_estimation'] - result2['state_estimation']))\n",
    "# print(torch.norm(result1['observation_estimation'] - result2['observation_estimation']))\n",
    "print(result1['state_estimation'])\n",
    "print(result2['state_estimation'])\n",
    "print(result3['state_estimation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zi9Hzsb9ndKp"
   },
   "source": [
    "# Infinite Impulse Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pQ5I3Zj7slTY",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700976582347,
     "user_tz": 480,
     "elapsed": 5,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     }
    }
   },
   "outputs": [],
   "source": [
    "#@title Model Parameters\n",
    "ModelArgs = Namespace(\n",
    "    S_D = 6,\n",
    "    I_D = 6,\n",
    "    O_D = 3,\n",
    "    SNR = 2.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Y8dOrQZLUF8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700976582347,
     "user_tz": 480,
     "elapsed": 4,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     }
    }
   },
   "outputs": [],
   "source": [
    "#@title Training Parameters\n",
    "BaseTrainArgs = Namespace(\n",
    "    # Dataset\n",
    "    train_dataset_size = 1,\n",
    "    valid_dataset_size = 100,\n",
    "    total_train_sequence_length = 2048,\n",
    "    total_valid_sequence_length = 20000,\n",
    "\n",
    "    # Batch sampling\n",
    "    subsequence_length = 10,\n",
    "    subsequence_initial_mode = \"random\",    # {\"random\", \"replay_buffer\"}\n",
    "    sample_efficiency = 5,\n",
    "    replay_buffer = 10,\n",
    "    batch_size = 128,\n",
    "\n",
    "    # Optimizer\n",
    "    beta = 0.1,\n",
    "    lr = 3e-4,\n",
    "    momentum = 0.9,\n",
    "    lr_decay = 0.95,\n",
    "    optim_type = \"Adam\",                    # {\"GD\", \"SGD\", \"SGDMomentum\", \"Adam\"}\n",
    "    l2_reg = 0.1,\n",
    "\n",
    "    # Iteration\n",
    "    iterations_per_epoch = 100,\n",
    "    epochs = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uB91NPDbt1Uw",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700976582347,
     "user_tz": 480,
     "elapsed": 4,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     }
    }
   },
   "outputs": [],
   "source": [
    "#@title Experiment Parameters\n",
    "BaseExperimentArgs = Namespace(\n",
    "    n_systems = 4,\n",
    "    ensemble_size = 8,\n",
    "    log_frequency = 5,\n",
    "    print_frequency = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7861,
     "status": "ok",
     "timestamp": 1700976590204,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     },
     "user_tz": 480
    },
    "id": "fRwnxK3zYJW1",
    "outputId": "c0f9478d-eb66-49dc-d042-d88023d9fdb8"
   },
   "outputs": [],
   "source": [
    "#@title Experiment Configurations\n",
    "base_exp_name = 'IIR'\n",
    "output_dir = 'infinite_impulse_response_backup'\n",
    "output_fname = 'result'\n",
    "\n",
    "optim_configs = [\n",
    "    ('SGDMomentum', {\n",
    "        'lr': 1.5e-4\n",
    "    }),\n",
    "    ('Adam', {\n",
    "        'lr': 1.5e-2\n",
    "    }),\n",
    "    ('GD', {\n",
    "        'lr': 5.e-4\n",
    "    })\n",
    "]\n",
    "system_configs = [\n",
    "    ('', {\n",
    "        'fname': 'systems'\n",
    "    })\n",
    "]\n",
    "\n",
    "result = {}\n",
    "for (optim_config_name, optim_config), (system_config_name, system_config) in itertools.product(\n",
    "    optim_configs,\n",
    "    system_configs\n",
    "):\n",
    "    TrainArgs = copy.copy(BaseTrainArgs)\n",
    "    TrainArgs.__dict__.update(optim_config)\n",
    "    TrainArgs.optim_type = optim_config_name\n",
    "\n",
    "    ExperimentArgs = copy.copy(BaseExperimentArgs)\n",
    "    ExperimentArgs.exp_name = f'Full{system_config_name}{optim_config_name}{base_exp_name}'\n",
    "\n",
    "    Args = Namespace(\n",
    "        model = ModelArgs,\n",
    "        train = TrainArgs,\n",
    "        experiment = ExperimentArgs\n",
    "    )\n",
    "\n",
    "    result[optim_config_name, system_config_name] = run_experiments(\n",
    "        Args, [], dev_type, {\n",
    "            'dir': output_dir,\n",
    "            'fname': output_fname\n",
    "        }, system_kwargs=system_config\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATSBHyS4ezp8"
   },
   "source": [
    "# Eigenvalue Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1538,
     "status": "ok",
     "timestamp": 1700976591738,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     },
     "user_tz": 480
    },
    "id": "JcVgS_-eb_d8",
    "outputId": "5c9c8a4a-b1cb-456a-f170-e29075ecab3d"
   },
   "outputs": [],
   "source": [
    "H, W = len(optim_configs), len(system_configs)\n",
    "plt.rcParams['figure.figsize'] = (20.0, 12.0)\n",
    "\n",
    "\n",
    "loss_type = 'validation'\n",
    "\n",
    "tail = 10\n",
    "threshold = 5.\n",
    "for w, (system_config_name, system_config) in enumerate(system_configs):\n",
    "    systems = torch.load(f'output/{output_dir}/{system_config[\"fname\"]}.pt', map_location='cpu')\n",
    "    ensembled_systems = TensorDict(torch.func.stack_module_state(systems)[0], batch_size=(BaseExperimentArgs.n_systems,))\n",
    "\n",
    "    for h, (optim_config_name, _) in enumerate(optim_configs):\n",
    "        exp_name = system_config_name + optim_config_name + base_exp_name\n",
    "        r = result[optim_config_name, system_config_name].to('cpu')\n",
    "\n",
    "        learned_kfs = r['learned_kf']\n",
    "\n",
    "        il, l = r['irreducible_loss'].detach(), r['loss'][loss_type].detach()\n",
    "        nl = torch.mean(l[:, :, -tail:], dim=-1) / il\n",
    "        nl[nl > threshold] = float('nan')\n",
    "\n",
    "        n_idx = 0\n",
    "        # diverged = torch.sum(torch.isnan(learned_kfs['F']) + torch.isinf(learned_kfs['F']), dim=(-2, -1))[n_idx]\n",
    "        # print(torch.sum(diverged))\n",
    "        I = torch.eye(ModelArgs.S_D)\n",
    "        eig_lkf_F = torch.linalg.eig(learned_kfs['F'][n_idx])[0]\n",
    "        eig_lkf_M = torch.linalg.eig(((I - learned_kfs['K'] @ learned_kfs['H']) @ learned_kfs['F'])[n_idx])[0]\n",
    "\n",
    "        print(nl[n_idx])\n",
    "        c = nl[n_idx, :, None].expand(-1, ModelArgs.S_D)\n",
    "        plt.scatter(\n",
    "            torch.real(eig_lkf_M).detach(),\n",
    "            torch.imag(eig_lkf_M).detach(),\n",
    "            s=128 / (c ** 10),\n",
    "            c=c,\n",
    "            cmap='inferno',\n",
    "            label='RnnKF'\n",
    "        )\n",
    "\n",
    "        eig_sys_F = torch.linalg.eig(ensembled_systems['F'])[0][n_idx]\n",
    "        eig_sys_M = torch.linalg.eig((I - ensembled_systems['K'] @ ensembled_systems['H']) @ ensembled_systems['F'])[0][n_idx]\n",
    "        plt.scatter(\n",
    "            torch.real(eig_sys_M),\n",
    "            torch.imag(eig_sys_M),\n",
    "            s=256,\n",
    "            color='black',\n",
    "            label='System'\n",
    "        )\n",
    "\n",
    "        plt.title(f'{exp_name} eigenvalues')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvbhMlSTe3se"
   },
   "source": [
    "# Infinite Impulse Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 2927,
     "status": "ok",
     "timestamp": 1700983343977,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     },
     "user_tz": 480
    },
    "id": "K-vHA1WL5uR2",
    "outputId": "fd9f2ce6-2f89-4a82-cfec-f14b172c508d"
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from google.colab import output\n",
    "output.disable_custom_widget_manager()\n",
    "# %matplotlib widget\n",
    "\n",
    "H, W = len(optim_configs), 2 * len(system_configs)\n",
    "plt.rcParams['figure.figsize'] = (12.0, 18.0)\n",
    "\n",
    "\n",
    "loss_type = 'validation'\n",
    "\n",
    "tail = 10\n",
    "threshold = 5.\n",
    "for w, (system_config_name, system_config) in enumerate(system_configs):\n",
    "    systems = torch.load(f'output/{output_dir}/{system_config[\"fname\"]}.pt', map_location='cpu')\n",
    "    ensembled_systems = TensorDict(torch.func.stack_module_state(systems)[0], batch_size=(BaseExperimentArgs.n_systems,))\n",
    "\n",
    "    kfs = [KF(sys) for sys in systems]\n",
    "    ensembled_kfs = TensorDict(torch.func.stack_module_state(kfs)[0], batch_size=(BaseExperimentArgs.n_systems,))\n",
    "\n",
    "    for h, (optim_config_name, _) in enumerate(optim_configs):\n",
    "        exp_name = system_config_name + optim_config_name + base_exp_name\n",
    "        r = result[optim_config_name, system_config_name].to('cpu')\n",
    "\n",
    "        il, l = r['irreducible_loss'].detach(), r['loss'][loss_type].detach()\n",
    "        nl = torch.mean(l[:, :, -tail:], dim=-1) / il\n",
    "        nl[nl > threshold] = float('nan')\n",
    "\n",
    "        # Setup impulses\n",
    "        iir_length = 16\n",
    "        n_models = BaseExperimentArgs.n_systems * BaseExperimentArgs.ensemble_size\n",
    "\n",
    "        X_initial_iir = torch.zeros(1, ModelArgs.O_D, ModelArgs.S_D)\n",
    "        X_input_iir = torch.zeros(1, ModelArgs.O_D, iir_length, ModelArgs.I_D)\n",
    "        y_iir = torch.cat([\n",
    "            torch.eye(ModelArgs.O_D)[None, :, None, :],\n",
    "            torch.zeros(1, ModelArgs.O_D, iir_length - 1, ModelArgs.O_D)\n",
    "        ], dim=2)\n",
    "\n",
    "        # Impulse response for true KF\n",
    "        base_KF = KF(systems[0]).to(dev_type)\n",
    "        def run_kf(kf_dicts, state, inputs, observations):\n",
    "            return torch.func.functional_call(base_KF, kf_dicts, (state, inputs, observations), {'steady_state': True})\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            kf_iir = torch.func.vmap(run_kf)(\n",
    "                dict(ensembled_kfs),\n",
    "                X_initial_iir.expand(BaseExperimentArgs.n_systems, -1, -1),\n",
    "                X_input_iir.expand(BaseExperimentArgs.n_systems, -1, -1, -1),\n",
    "                y_iir.expand(BaseExperimentArgs.n_systems, -1, -1, -1)\n",
    "            )['observation_estimation']\n",
    "\n",
    "        # Impulse response for learned KF\n",
    "        base_RnnKF = RnnKF(ModelArgs).to(dev_type)\n",
    "        def run_lkf(kf_dicts, state, inputs, observations):\n",
    "            return torch.func.functional_call(base_RnnKF, kf_dicts, (state, inputs, observations))\n",
    "\n",
    "        n_models = BaseExperimentArgs.n_systems * BaseExperimentArgs.ensemble_size\n",
    "        with torch.set_grad_enabled(False):\n",
    "            lkf_iir = torch.func.vmap(run_lkf)(\n",
    "                dict(r['learned_kf'].flatten()),\n",
    "                X_initial_iir.expand(n_models, -1, -1),\n",
    "                X_input_iir.expand(n_models, -1, -1, -1),\n",
    "                y_iir.expand(n_models, -1, -1, -1)\n",
    "            )['observation_estimation'].view(\n",
    "                BaseExperimentArgs.n_systems,\n",
    "                BaseExperimentArgs.ensemble_size,\n",
    "                ModelArgs.O_D,\n",
    "                iir_length,\n",
    "                ModelArgs.O_D\n",
    "            )\n",
    "\n",
    "        n_idx = 1\n",
    "        iir_d = lkf_iir - kf_iir[:, None]   # [N x E x I x L x O_D]\n",
    "\n",
    "        # Projections of IIR error\n",
    "        ax = plt.subplot(H, W, W * h + w + 1)\n",
    "        c = matplotlib.cm.inferno(torch.linspace(0, 1, iir_length) ** 0.5)\n",
    "        s = torch.pow(2, torch.linspace(8, 4, iir_length))\n",
    "\n",
    "        reshaped_iir_d = iir_d.flatten(1, -2)\n",
    "        _, _, Vh = torch.svd(reshaped_iir_d, some=True)\n",
    "        iir_d_reduced = (reshaped_iir_d @ Vh[:, :, :2]).unflatten(1, (\n",
    "            BaseExperimentArgs.ensemble_size,\n",
    "            ModelArgs.O_D,\n",
    "            iir_length\n",
    "        ))\n",
    "\n",
    "        for impulse in range(3):\n",
    "            for l in range(BaseExperimentArgs.ensemble_size):\n",
    "                ax.scatter(\n",
    "                    *iir_d_reduced[n_idx, l, impulse].T,\n",
    "                    c=c,\n",
    "                    s=s\n",
    "                )\n",
    "\n",
    "        ax.set_xlim(left=-0.15, right=0.15)\n",
    "        ax.set_ylim(bottom=-0.15, top=0.15)\n",
    "        ax.legend()\n",
    "        ax.set_title(f'{exp_name} Error Projection')\n",
    "\n",
    "        # Frobenius norm of IIR error\n",
    "        ax = plt.subplot(H, W, W * h + w + 2)\n",
    "\n",
    "        iir_d_fnorm = torch.mean(torch.norm(iir_d, dim=(2, -1)), dim=1)\n",
    "        for n in range(BaseExperimentArgs.n_systems):\n",
    "            ax.plot(iir_d_fnorm[n], marker='.', label=f'sys{n}')\n",
    "        ax.legend()\n",
    "        ax.set_title(f'{exp_name} Error Frobenius Norm')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "Fn.conv2d(torch.randn(3, 100, 100), torch.randn(1, 3, 5, 5)).shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5cObuOM9DNVi",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700976593879,
     "user_tz": 480,
     "elapsed": 9,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     }
    },
    "outputId": "cab2bca3-208b-4325-d7d1-beba45012fea"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "M1 = torch.randint(0, 4, (5, 5))\n",
    "M2 = torch.randint(0, 4, (2, 2))\n",
    "print(M1)\n",
    "print(M2)\n",
    "print(Fn.conv2d(M1[None], M2[None, None]))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B6yRa_nkFDZf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700976593879,
     "user_tz": 480,
     "elapsed": 6,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     }
    },
    "outputId": "1748863f-c130-45be-f277-5d96fda0515a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.zeros(5, 7).index_select(1, torch.arange(3))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "366WFsPXMFO2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700978168001,
     "user_tz": 480,
     "elapsed": 6,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     }
    },
    "outputId": "999bdf97-1bcd-4ed8-a135-d265f44b3d0e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ir_length = 256\n",
    "filter = torch.cat([\n",
    "    torch.zeros(ModelArgs.O_D, ModelArgs.O_D, 1),\n",
    "    nn.Parameter(torch.randn(ModelArgs.O_D, ModelArgs.O_D, ir_length - 1))\n",
    "], dim=-1)\n",
    "\n",
    "B, L = 5, 2048\n",
    "inputs = torch.randn(B, L, ModelArgs.I_D)\n",
    "observations = torch.randn(B, L, ModelArgs.O_D)\n",
    "\n",
    "print(observations.shape)\n",
    "print(CnnKF(ModelArgs)(None, inputs, observations)['observation_estimation'].shape)\n",
    "\n",
    "# Fn.conv2d(filter, observations[:, :, None], padding=(0, L)).squeeze(0).shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDEZiIFAAFmw",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700979359860,
     "user_tz": 480,
     "elapsed": 910,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     }
    },
    "outputId": "a73c872a-e886-4ee5-a93b-dbf7763330d1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from"
   ],
   "metadata": {
    "id": "JjHho8YSQFs6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "error",
     "timestamp": 1700600838998,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     },
     "user_tz": 480
    },
    "id": "ySyo5rO2k5sP",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "fa29bb93-3b43-4358-a985-d0e48a2ad35c"
   },
   "outputs": [],
   "source": [
    "H, W = len(optim_configs), len(system_configs)\n",
    "plt.rcParams['figure.figsize'] = (12.0, 20.0)\n",
    "fig, axs = plt.subplots(H, W)\n",
    "\n",
    "tail = 10\n",
    "cutoff = 100\n",
    "for h, (optim_config_name, _) in enumerate(optim_configs):\n",
    "    for w, (system_config_name, _) in enumerate(system_configs):\n",
    "        exp_name = system_config_name + optim_config_name + base_exp_name\n",
    "\n",
    "        r = result[optim_config_name][system_config_name]\n",
    "\n",
    "        training_loss, overfit_loss, validation_loss, irreducible_loss = (r[k].detach().cpu() for k in (\n",
    "            'training_loss',\n",
    "            'overfit_loss',\n",
    "            'validation_loss',\n",
    "            'irreducible_loss'\n",
    "        ))\n",
    "\n",
    "        x = torch.arange(cutoff, training_loss.shape[-1], dtype=float)\n",
    "\n",
    "        axs[h, w].plot(x, torch.ones_like(x), linestyle='--', linewidth=1., color='black', label='normalized irreducible_loss')\n",
    "        normalized_overfit_loss = overfit_loss / irreducible_loss[:, :, None]\n",
    "        normalized_validation_loss = validation_loss / irreducible_loss[:, :, None]\n",
    "\n",
    "        N = len(irreducible_loss)\n",
    "        for n, (overfit_loss, validation_loss) in list(enumerate(zip(normalized_overfit_loss, normalized_validation_loss)))[::2]:\n",
    "            mean_overfit_loss = torch.mean(overfit_loss, dim=0)[cutoff:]\n",
    "            mean_validation_loss = torch.mean(validation_loss, dim=0)[cutoff:]\n",
    "\n",
    "            c = color(n, scale=N)\n",
    "            axs[h, w].plot(x, mean_overfit_loss, linewidth=1., color=c, label=f'Experiment {n}')\n",
    "            axs[h, w].plot(x, mean_validation_loss, linewidth=1., color=c)\n",
    "            axs[h, w].fill_between(x, mean_overfit_loss, mean_validation_loss, alpha=0.1, color=c)\n",
    "\n",
    "        axs[h, w].set_xlabel('Batch')\n",
    "        axs[h, w].set_ylabel('Normalized Loss')\n",
    "        axs[h, w].set_title(f'{exp_name} - Normalized Overfit Loss')\n",
    "        # axs[h, w].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vp7Qps54WBoq"
   },
   "outputs": [],
   "source": [
    "H, W = len(optim_configs), len(system_configs)\n",
    "plt.rcParams['figure.figsize'] = (12.0, 20.0)\n",
    "fig, axs = plt.subplots(H, W)\n",
    "\n",
    "tail = 10\n",
    "for h, (optim_config_name, _) in enumerate(optim_configs):\n",
    "    for w, (system_config_name, _) in enumerate(system_configs):\n",
    "        exp_name = system_config_name + optim_config_name + base_exp_name\n",
    "\n",
    "        r = result[optim_config_name][system_config_name]\n",
    "\n",
    "        training_loss, overfit_loss, validation_loss, irreducible_loss = (r[k].detach().cpu() for k in (\n",
    "            'training_loss',\n",
    "            'overfit_loss',\n",
    "            'validation_loss',\n",
    "            'irreducible_loss'\n",
    "        ))\n",
    "\n",
    "        normalized_overfit_loss = overfit_loss / irreducible_loss[:, :, None]\n",
    "        normalized_validation_loss = validation_loss / irreducible_loss[:, :, None]\n",
    "\n",
    "        irreducible_, indices = torch.sort(irreducible_loss[:, 0])\n",
    "        tail_ = torch.mean(normalized_overfit_loss[:, :, -tail:], dim=-1)\n",
    "        mean_ = torch.mean(tail_, dim=1)[indices]\n",
    "        std_ = torch.std(tail_, dim=1)[indices]\n",
    "        min_ = tail_[torch.arange(len(mean_)), torch.argmin(tail_, dim=1)][indices]\n",
    "        max_ = tail_[torch.arange(len(mean_)), torch.argmax(tail_, dim=1)][indices]\n",
    "\n",
    "\n",
    "        axs_twinx = axs[h, w].twinx()\n",
    "        axs[h, w].plot(irreducible_, torch.zeros_like(mean_), linewidth=1., linestyle='--', marker='.', color='black', label=f'Mean loss')\n",
    "        axs_twinx.plot(irreducible_, mean_, linewidth=1., marker='.', color='blue', label='mean overfit loss')\n",
    "\n",
    "        axs[h, w].plot(irreducible_, min_ - mean_, linewidth=0.5, marker='.', color='turquoise')\n",
    "        # axs[h, w].plot(mean_, max_ - mean_, linewidth=0.5, marker='.', color='turquoise')\n",
    "\n",
    "        axs[h, w].fill_between(irreducible_, min_ - mean_, max_ - mean_, color='aquamarine', alpha=0.2, label='min-max')\n",
    "        axs[h, w].fill_between(irreducible_, -std_, std_, color='aquamarine', alpha=0.5, label='1 std')\n",
    "\n",
    "        axs[h, w].set_xlabel('Normalized mean loss per system')\n",
    "        axs[h, w].set_title(f'{exp_name}')\n",
    "        # axs[h, w].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1zBSjk02yXHW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1lcHhNw_r_eetYfC5dd7wEm_Cgw7yytr7",
     "timestamp": 1698522777293
    },
    {
     "file_id": "1q9Qx12ZP6MjTkUXpm6XF0Tw68M9eUD0c",
     "timestamp": 1693268309398
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}