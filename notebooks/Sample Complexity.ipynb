{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QupgVmcZgvyx",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700601347639,
     "user_tz": 480,
     "elapsed": 8,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     }
    }
   },
   "outputs": [],
   "source": [
    "## Created by Wentinn Liao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k722vkzdWafR"
   },
   "source": [
    "# Kalman Filter Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28993,
     "status": "ok",
     "timestamp": 1700601376625,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     },
     "user_tz": 480
    },
    "id": "S27iMYAOuWiB",
    "outputId": "8b048e8c-6099-4a65-cbe0-f232d894b82f"
   },
   "outputs": [],
   "source": [
    "#@title Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1700601376626,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     },
     "user_tz": 480
    },
    "id": "0xHh9PF6hl3R",
    "outputId": "021135d1-5d55-40a1-ec69-45d5f5ce50e2"
   },
   "outputs": [],
   "source": [
    "#@title Symlink Setup\n",
    "import os\n",
    "\n",
    "def ptpp(PATH: str) -> str: # Converts path to python path\n",
    "    return PATH.replace('\\\\', '')\n",
    "\n",
    "DRIVE_PATH = '/content/gdrive/My\\ Drive/KF_RNN'\n",
    "if not os.path.exists(ptpp(DRIVE_PATH)):\n",
    "    %mkdir $DRIVE_PATH\n",
    "SYM_PATH = '/content/KF_RNN'\n",
    "if not os.path.exists(ptpp(SYM_PATH)):\n",
    "    !ln -s $DRIVE_PATH $SYM_PATH\n",
    "%cd $SYM_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 122553,
     "status": "ok",
     "timestamp": 1700601499174,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     },
     "user_tz": 480
    },
    "id": "-h7SwLD3uWiC",
    "outputId": "412e4bdd-ca8d-457f-8f5c-2a21bee09d71"
   },
   "outputs": [],
   "source": [
    "!pip install numpy imageio matplotlib scikit-learn torch==2.0.0 tensordict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9pbdKYaruWiD",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700601499174,
     "user_tz": 480,
     "elapsed": 8,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     }
    }
   },
   "outputs": [],
   "source": [
    "#@title Configure Jupyter Notebook\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uK2SmUy3uWiD",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700601509424,
     "user_tz": 480,
     "elapsed": 10257,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     }
    }
   },
   "outputs": [],
   "source": [
    "#@title Library Setup\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import *\n",
    "from argparse import Namespace\n",
    "import copy\n",
    "import itertools\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fn\n",
    "import torch.utils as ptu\n",
    "import tensordict\n",
    "from tensordict import TensorDict\n",
    "from matplotlib.collections import PolyCollection\n",
    "\n",
    "from model.linear_system import LinearSystem\n",
    "from model.kf import KF\n",
    "from model.rnn_kf import RnnKF\n",
    "\n",
    "from infrastructure import utils\n",
    "from infrastructure.train import *\n",
    "\n",
    "# seed = 7\n",
    "# torch.manual_seed(seed)\n",
    "# random.seed(seed)\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "dev_type = 'cuda'\n",
    "if dev_type == 'xla':\n",
    "    !pip install torch-xla cloud-tpu-client https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl\n",
    "    import torch_xla\n",
    "    import torch_xla.core.xla_model as xm\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (7.0, 5.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "error",
     "timestamp": 1700601509424,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     },
     "user_tz": 480
    },
    "id": "k0CCnpY3yIej",
    "outputId": "b895156d-575e-40e8-ea03-cd5dbce01325"
   },
   "outputs": [],
   "source": [
    "S_D, I_D, O_D, SNR = 2, 2, 1, 2.\n",
    "B, L = 1, 4\n",
    "\n",
    "system = LinearSystem.sample_stable_system(Namespace(\n",
    "    S_D = S_D,\n",
    "    I_D = I_D,\n",
    "    O_D = O_D,\n",
    "    SNR = SNR\n",
    "))\n",
    "optimal_kf = KF(system)\n",
    "learned_kf = RnnKF(S_D, I_D, O_D)\n",
    "learned_kf.K = nn.Parameter(torch.randn(S_D, O_D))\n",
    "\n",
    "test_state = torch.randint(-10, 11, (B, S_D), dtype=float)\n",
    "test_inputs = torch.randint(-10, 11, (B, L, I_D), dtype=float)\n",
    "test_observations = torch.randint(-10, 11, (B, L, O_D), dtype=float)\n",
    "\n",
    "# print(system(test_state, test_inputs))\n",
    "# print(optimal_kf(test_state, test_inputs, test_observations))\n",
    "result1 = learned_kf(test_state, test_inputs, test_observations)\n",
    "result2 = learned_kf(test_state, test_inputs, test_observations, mode='form')\n",
    "result3 = learned_kf(test_state, test_inputs, test_observations, mode='form_sqrt')\n",
    "\n",
    "# print(torch.norm(result1['state_estimation'] - result2['state_estimation']))\n",
    "# print(torch.norm(result1['observation_estimation'] - result2['observation_estimation']))\n",
    "print(result1['state_estimation'])\n",
    "print(result2['state_estimation'])\n",
    "print(result3['state_estimation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zi9Hzsb9ndKp"
   },
   "source": [
    "# Sample Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pQ5I3Zj7slTY",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1700601509426,
     "user_tz": 480,
     "elapsed": 11,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     }
    }
   },
   "outputs": [],
   "source": [
    "#@title Model Parameters\n",
    "ModelArgs = Namespace(\n",
    "    S_D = 6,\n",
    "    I_D = 6,\n",
    "    O_D = 4,\n",
    "    SNR = 2.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Y8dOrQZLUF8",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1700601509426,
     "user_tz": 480,
     "elapsed": 11,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     }
    }
   },
   "outputs": [],
   "source": [
    "#@title Training Parameters\n",
    "total_trace_lengths = sorted(set(torch.ceil(torch.pow(2, torch.arange(7., 12.5, 0.5))).to(int).tolist()))\n",
    "num_traces = sorted(set(torch.ceil(torch.pow(2, torch.arange(0., 7.5, 0.5))).to(int).tolist()))\n",
    "\n",
    "BaseTrainArgs = Namespace(\n",
    "    # Dataset\n",
    "    train_dataset_size = num_traces,\n",
    "    valid_dataset_size = 100,\n",
    "    total_train_sequence_length = total_trace_lengths,\n",
    "    total_valid_sequence_length = 20000,\n",
    "\n",
    "    # Batch sampling\n",
    "    subsequence_length = 10,\n",
    "    subsequence_initial_mode = \"random\",    # {\"random\", \"replay_buffer\"}\n",
    "    sample_efficiency = 5,\n",
    "    replay_buffer = 10,\n",
    "    batch_size = 128,\n",
    "\n",
    "    # Optimizer\n",
    "    beta = 0.1,\n",
    "    lr = 3e-4,\n",
    "    momentum = 0.9,\n",
    "    lr_decay = 0.95,\n",
    "    optim_type = \"Adam\",                    # {\"GD\", \"SGD\", \"SGDMomentum\", \"Adam\"}\n",
    "    l2_reg = 0.1,\n",
    "\n",
    "    # Iteration\n",
    "    iterations_per_epoch = 100,\n",
    "    epochs = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uB91NPDbt1Uw",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1700601509426,
     "user_tz": 480,
     "elapsed": 10,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     }
    }
   },
   "outputs": [],
   "source": [
    "#@title Experiment Parameters\n",
    "BaseExperimentArgs = Namespace(\n",
    "    n_systems = 16,\n",
    "    ensemble_size = 1,\n",
    "    log_frequency = 5,\n",
    "    print_frequency = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fRwnxK3zYJW1",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1700601509426,
     "user_tz": 480,
     "elapsed": 10,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     }
    }
   },
   "outputs": [],
   "source": [
    "#@title Experiment Configurations\n",
    "base_exp_name = 'SC'\n",
    "output_dir = 'sample_complexity_strong_convergence'\n",
    "output_fname = 'result'\n",
    "\n",
    "optim_configs = [\n",
    "    ('SGDMomentum', {\n",
    "        'lr': 1.5e-4\n",
    "    }),\n",
    "    ('Adam', {\n",
    "        'lr': 1.5e-2\n",
    "    }),\n",
    "    ('GD', {\n",
    "        'lr': 5.e-4\n",
    "    })\n",
    "]\n",
    "system_configs = [\n",
    "    ('', {\n",
    "        'fname': 'systems'\n",
    "    })\n",
    "]\n",
    "\n",
    "result = {}\n",
    "for (optim_config_name, optim_config), (system_config_name, system_config) in itertools.product(\n",
    "    optim_configs,\n",
    "    system_configs\n",
    "):\n",
    "    TrainArgs = copy.copy(BaseTrainArgs)\n",
    "    TrainArgs.__dict__.update(optim_config)\n",
    "    TrainArgs.optim_type = optim_config_name\n",
    "\n",
    "    ExperimentArgs = copy.copy(BaseExperimentArgs)\n",
    "    ExperimentArgs.exp_name = f'Full{system_config_name}{optim_config_name}{base_exp_name}'\n",
    "\n",
    "    Args = Namespace(\n",
    "        model = ModelArgs,\n",
    "        train = TrainArgs,\n",
    "        experiment = ExperimentArgs\n",
    "    )\n",
    "\n",
    "    result[optim_config_name, system_config_name] = run_experiments(\n",
    "        Args, [\n",
    "            'total_train_sequence_length',\n",
    "            'train_dataset_size'\n",
    "        ], dev_type, {\n",
    "            'dir': output_dir,\n",
    "            'fname': output_fname\n",
    "        }, system_kwargs=system_config\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5L7sjPbUd4zh"
   },
   "source": [
    "# Sample Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9gX_uXwu92R",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1700601509427,
     "user_tz": 480,
     "elapsed": 11,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     }
    }
   },
   "outputs": [],
   "source": [
    "H, W = len(optim_configs), len(system_configs)\n",
    "plt.rcParams['figure.figsize'] = (20.0, 24.0)\n",
    "\n",
    "loss_type = 'overfit'\n",
    "\n",
    "tail = 10\n",
    "threshold = 5.\n",
    "for (h, (optim_config_name, _)), (w, (system_config_name, _)) in itertools.product(\n",
    "    enumerate(optim_configs),\n",
    "    enumerate(system_configs)\n",
    "):\n",
    "    exp_name = system_config_name + optim_config_name + base_exp_name\n",
    "    r = result[optim_config_name, system_config_name]\n",
    "\n",
    "    mean_nl = torch.zeros(len(total_trace_lengths), len(num_traces))\n",
    "    std_nl = torch.zeros(len(total_trace_lengths), len(num_traces))\n",
    "    for (i, t), (j, n) in itertools.product(enumerate(total_trace_lengths), enumerate(num_traces)):\n",
    "        str_args = (str(t), str(n))\n",
    "        il, l = r[str_args]['irreducible_loss'].detach(), r[str_args]['loss'][loss_type].detach()\n",
    "\n",
    "        nl = torch.mean(l[:, :, -tail:], dim=-1) / il\n",
    "        nl[nl > threshold] = float('nan')\n",
    "\n",
    "        converged_nl = utils.remove_nans_and_infs(nl)\n",
    "        mean_nl[i, j] = torch.mean(converged_nl)\n",
    "        std_nl[i, j] = torch.std(converged_nl)\n",
    "\n",
    "\n",
    "    x_range, y_range = torch.log2(torch.tensor(total_trace_lengths)), torch.log2(torch.tensor(num_traces))\n",
    "    x_mesh, y_mesh = torch.meshgrid(x_range, y_range)\n",
    "\n",
    "\n",
    "    # Plot 3D\n",
    "    ax_3d = plt.subplot(H, 3 * W, (3 * W) * h + 3 * w + 1, projection='3d')\n",
    "\n",
    "    ax_3d.view_init(elev=15., azim=30.)\n",
    "    ax_3d.plot_wireframe(x_mesh, y_mesh, mean_nl, color='black', linewidth=0.5)\n",
    "    ax_3d.scatter(x_mesh, y_mesh, mean_nl, s=12, c=mean_nl.flatten(), cmap=plt.cm.YlOrRd_r, alpha=1)\n",
    "    ax_3d.contour(x_mesh, y_mesh, mean_nl, zdir='y', offset=-1, cmap='plasma')\n",
    "    ax_3d.plot_surface(x_mesh, y_mesh, torch.ones_like(x_mesh), color='black', alpha=0.2)\n",
    "    ax_3d.add_collection3d(PolyCollection(\n",
    "        torch.stack([\n",
    "            torch.cat([x_mesh, torch.flip(x_mesh, dims=(0,))], dim=0),\n",
    "            torch.cat([mean_nl + std_nl, torch.flip(mean_nl - std_nl, dims=(0,))], dim=0)\n",
    "        ], dim=-1).permute(1, 0, 2),\n",
    "        facecolors=plt.cm.plasma(torch.linspace(0, 1, len(num_traces))),\n",
    "        alpha=0.5\n",
    "    ), zs=y_range, zdir='y')\n",
    "\n",
    "\n",
    "    ax_3d.set_xlabel('total_trace_length')\n",
    "    ax_3d.set_ylabel('num_traces')\n",
    "    ax_3d.set_zlim(bottom=0)\n",
    "    ax_3d.set_zlabel(f'normalized_{loss_type}_loss')\n",
    "    ax_3d.set_title(f'{exp_name} 3D')\n",
    "\n",
    "    # Plot 2D\n",
    "    ax_2d_n = plt.subplot(H, 3 * W, (3 * W) * h + 3 * w + 2)\n",
    "\n",
    "    c = np.log2(num_traces)\n",
    "    c = plt.cm.plasma((c - np.min(c)) / np.ptp(c))\n",
    "    for j, n in enumerate(num_traces):\n",
    "        m, s = mean_nl[:, j], std_nl[:, j]\n",
    "        ax_2d_n.plot(\n",
    "            total_trace_lengths, m,\n",
    "            linewidth=0.5,\n",
    "            marker='.',\n",
    "            color=c[j],\n",
    "            label=f'num_traces{n}'\n",
    "        )\n",
    "        ax_2d_n.fill_between(\n",
    "            total_trace_lengths, m - s, m + s,\n",
    "            color=c[j],\n",
    "            alpha=0.05\n",
    "        )\n",
    "    ax_2d_n.plot(total_trace_lengths, torch.ones(len(total_trace_lengths)), color='black', linestyle='--')\n",
    "\n",
    "\n",
    "    ax_2d_n.set_xlabel('total_trace_length')\n",
    "    ax_2d_n.set_xscale('log')\n",
    "    ax_2d_n.set_ylabel(f'normalized_{loss_type}_loss')\n",
    "    ax_2d_n.set_title(f'{exp_name} 2D')\n",
    "    ax_2d_n.legend()\n",
    "\n",
    "\n",
    "    # Plot 2D\n",
    "    ax_2d_t = plt.subplot(H, 3 * W, (3 * W) * h + 3 * w + 3)\n",
    "\n",
    "    c = np.log2(total_trace_lengths)\n",
    "    c = plt.cm.twilight_shifted((c - np.min(c)) / np.ptp(c))\n",
    "    for i, t in list(enumerate(total_trace_lengths)):\n",
    "        m, s = mean_nl[i], std_nl[i]\n",
    "        ax_2d_t.plot(\n",
    "            num_traces, m,\n",
    "            linewidth=0.5,\n",
    "            marker='.',\n",
    "            color=c[i],\n",
    "            label=f'total_trace_length{t}'\n",
    "        )\n",
    "    ax_2d_t.plot(num_traces, torch.ones(len(num_traces)), color='black', linestyle='--')\n",
    "\n",
    "\n",
    "    ax_2d_t.set_xlabel('num_traces')\n",
    "    ax_2d_t.set_xscale('log')\n",
    "    ax_2d_t.set_ylabel(f'normalized_{loss_type}_loss')\n",
    "    ax_2d_t.set_title(f'{exp_name} 2D')\n",
    "    ax_2d_t.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j4U0zXpJQXCj",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1700601509427,
     "user_tz": 480,
     "elapsed": 11,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     }
    }
   },
   "outputs": [],
   "source": [
    "H, W = len(optim_configs), len(system_configs)\n",
    "plt.rcParams['figure.figsize'] = (20.0, 24.0)\n",
    "\n",
    "loss_type = 'validation'\n",
    "\n",
    "tail = 10\n",
    "threshold = 5.\n",
    "for (h, (optim_config_name, _)), (w, (system_config_name, _)) in itertools.product(\n",
    "    enumerate(optim_configs),\n",
    "    enumerate(system_configs)\n",
    "):\n",
    "    exp_name = system_config_name + optim_config_name + base_exp_name\n",
    "    r = result[optim_config_name, system_config_name]\n",
    "\n",
    "    mean_nl = torch.zeros(len(total_trace_lengths), len(num_traces))\n",
    "    std_nl = torch.zeros(len(total_trace_lengths), len(num_traces))\n",
    "    for (i, t), (j, n) in itertools.product(enumerate(total_trace_lengths), enumerate(num_traces)):\n",
    "        str_args = (str(t), str(n))\n",
    "        il, l = r[str_args]['irreducible_loss'].detach(), r[str_args]['loss'][loss_type].detach()\n",
    "\n",
    "        nl = torch.mean(l[:, :, -tail:], dim=-1) / il\n",
    "        nl[nl > threshold] = float('nan')\n",
    "\n",
    "        converged_nl = utils.remove_nans_and_infs(nl)\n",
    "        mean_nl[i, j] = torch.mean(converged_nl)\n",
    "        std_nl[i, j] = torch.std(converged_nl)\n",
    "\n",
    "\n",
    "    x_range, y_range = torch.log2(torch.tensor(total_trace_lengths)), torch.log2(torch.tensor(num_traces))\n",
    "    x_mesh, y_mesh = torch.meshgrid(x_range, y_range)\n",
    "\n",
    "\n",
    "    # Plot 3D\n",
    "    ax_3d = plt.subplot(H, 3 * W, (3 * W) * h + 3 * w + 1, projection='3d')\n",
    "\n",
    "    ax_3d.view_init(elev=15., azim=30.)\n",
    "    ax_3d.plot_wireframe(x_mesh, y_mesh, mean_nl, color='black', linewidth=0.5)\n",
    "    ax_3d.scatter(x_mesh, y_mesh, mean_nl, s=12, c=mean_nl.flatten(), cmap=plt.cm.YlOrRd_r, alpha=1)\n",
    "    ax_3d.contour(x_mesh, y_mesh, mean_nl, zdir='y', offset=-1, cmap='plasma')\n",
    "    ax_3d.plot_surface(x_mesh, y_mesh, torch.ones_like(x_mesh), color='black', alpha=0.2)\n",
    "    ax_3d.add_collection3d(PolyCollection(\n",
    "        torch.stack([\n",
    "            torch.cat([x_mesh, torch.flip(x_mesh, dims=(0,))], dim=0),\n",
    "            torch.cat([mean_nl + std_nl, torch.flip(mean_nl - std_nl, dims=(0,))], dim=0)\n",
    "        ], dim=-1).permute(1, 0, 2),\n",
    "        facecolors=plt.cm.plasma(torch.linspace(0, 1, len(num_traces))),\n",
    "        alpha=0.5\n",
    "    ), zs=y_range, zdir='y')\n",
    "\n",
    "\n",
    "    ax_3d.set_xlabel('total_trace_length')\n",
    "    ax_3d.set_ylabel('num_traces')\n",
    "    ax_3d.set_zlim(bottom=0)\n",
    "    ax_3d.set_zlabel(f'normalized_{loss_type}_loss')\n",
    "    ax_3d.set_title(f'{exp_name} 3D')\n",
    "\n",
    "    # Plot 2D\n",
    "    ax_2d_n = plt.subplot(H, 3 * W, (3 * W) * h + 3 * w + 2)\n",
    "\n",
    "    c = np.log2(num_traces)\n",
    "    c = plt.cm.plasma((c - np.min(c)) / np.ptp(c))\n",
    "    for j, n in enumerate(num_traces):\n",
    "        m, s = mean_nl[:, j], std_nl[:, j]\n",
    "        ax_2d_n.plot(\n",
    "            total_trace_lengths, m,\n",
    "            linewidth=0.5,\n",
    "            marker='.',\n",
    "            color=c[j],\n",
    "            label=f'num_traces{n}'\n",
    "        )\n",
    "        ax_2d_n.fill_between(\n",
    "            total_trace_lengths, m - s, m + s,\n",
    "            color=c[j],\n",
    "            alpha=0.05\n",
    "        )\n",
    "    ax_2d_n.plot(total_trace_lengths, torch.ones(len(total_trace_lengths)), color='black', linestyle='--')\n",
    "\n",
    "\n",
    "    ax_2d_n.set_xlabel('total_trace_length')\n",
    "    ax_2d_n.set_xscale('log')\n",
    "    ax_2d_n.set_ylabel(f'normalized_{loss_type}_loss')\n",
    "    ax_2d_n.set_title(f'{exp_name} 2D')\n",
    "    ax_2d_n.legend()\n",
    "\n",
    "\n",
    "    # Plot 2D\n",
    "    ax_2d_t = plt.subplot(H, 3 * W, (3 * W) * h + 3 * w + 3)\n",
    "\n",
    "    c = np.log2(total_trace_lengths)\n",
    "    c = plt.cm.twilight_shifted((c - np.min(c)) / np.ptp(c))\n",
    "    for i, t in list(enumerate(total_trace_lengths)):\n",
    "        m, s = mean_nl[i], std_nl[i]\n",
    "        ax_2d_t.plot(\n",
    "            num_traces, m,\n",
    "            linewidth=0.5,\n",
    "            marker='.',\n",
    "            color=c[i],\n",
    "            label=f'total_trace_length{t}'\n",
    "        )\n",
    "    ax_2d_t.plot(num_traces, torch.ones(len(num_traces)), color='black', linestyle='--')\n",
    "\n",
    "\n",
    "    ax_2d_t.set_xlabel('num_traces')\n",
    "    ax_2d_t.set_xscale('log')\n",
    "    ax_2d_t.set_ylabel(f'normalized_{loss_type}_loss')\n",
    "    ax_2d_t.set_title(f'{exp_name} 2D')\n",
    "    ax_2d_t.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATSBHyS4ezp8"
   },
   "source": [
    "# Kalman Filter Eigenvalue Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JcVgS_-eb_d8",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1700601509427,
     "user_tz": 480,
     "elapsed": 10,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     }
    }
   },
   "outputs": [],
   "source": [
    "H, W = len(optim_configs), len(system_configs)\n",
    "plt.rcParams['figure.figsize'] = (20.0, 12.0)\n",
    "\n",
    "\n",
    "loss_type = 'validation'\n",
    "\n",
    "tail = 10\n",
    "threshold = 5.\n",
    "for w, (system_config_name, system_config) in enumerate(system_configs):\n",
    "    systems = tensordict.utils.expand_right(\n",
    "        TensorDict(torch.func.stack_module_state(\n",
    "            torch.load(f'output/{output_dir}/{system_config[\"fname\"]}.pt', map_location='cpu')\n",
    "        )[0], batch_size=(BaseExperimentArgs.n_systems,)),\n",
    "        (BaseExperimentArgs.n_systems, BaseExperimentArgs.ensemble_size)\n",
    "    )\n",
    "\n",
    "    for h, (optim_config_name, _) in enumerate(optim_configs):\n",
    "        exp_name = system_config_name + optim_config_name + base_exp_name\n",
    "        r = result[optim_config_name, system_config_name]\n",
    "\n",
    "        learned_kfs = tensordict.utils.expand_right(TensorDict(\n",
    "            RnnKF(ModelArgs.S_D, ModelArgs.I_D, ModelArgs.O_D).state_dict(),\n",
    "        batch_size=())[None, None, None, None], (\n",
    "            len(total_trace_lengths),\n",
    "            len(num_traces),\n",
    "            BaseExperimentArgs.n_systems,\n",
    "            BaseExperimentArgs.ensemble_size\n",
    "        )).clone()\n",
    "\n",
    "        mean_nl = torch.zeros(len(total_trace_lengths), len(num_traces))\n",
    "        I = torch.eye(ModelArgs.S_D)\n",
    "        for (i, t), (j, n) in itertools.product(enumerate(total_trace_lengths), enumerate(num_traces)):\n",
    "            learned_kfs[i, j] = r[str(t), str(n), 'learned_kf']\n",
    "\n",
    "            il, l = r[str(t), str(n), 'irreducible_loss'].detach(), r[str(t), str(n), 'loss'][loss_type].detach()\n",
    "            nl = torch.mean(l[:, :, -tail:], dim=-1) / il\n",
    "            nl[nl > threshold] = float('nan')\n",
    "            mean_nl[i, j] = torch.mean(utils.remove_nans_and_infs(nl))\n",
    "\n",
    "        n_idx, e_idx = 0, 0\n",
    "\n",
    "        eig_lkf_F = torch.linalg.eig(learned_kfs['F'])[0][:, :, n_idx, e_idx]\n",
    "        eig_lkf_M = torch.linalg.eig((I - learned_kfs['K'] @ learned_kfs['H']) @ learned_kfs['F'])[0][:, :, n_idx, e_idx]\n",
    "\n",
    "        c = mean_nl[:, :, None].expand(-1, -1, ModelArgs.S_D)\n",
    "        plt.scatter(\n",
    "            torch.real(eig_lkf_F),\n",
    "            torch.imag(eig_lkf_F),\n",
    "            s=64 / (c ** 10),\n",
    "            c=mean_nl[:, :, None].expand(-1, -1, ModelArgs.S_D),\n",
    "            cmap='plasma',\n",
    "            label='RnnKF'\n",
    "        )\n",
    "\n",
    "        eig_sys_F = torch.linalg.eig(systems['F'])[0][n_idx, e_idx]\n",
    "        eig_sys_M = torch.linalg.eig((I - systems['K'] @ systems['H']) @ systems['F'])[0][n_idx, e_idx]\n",
    "        plt.scatter(\n",
    "            torch.real(eig_sys_F),\n",
    "            torch.imag(eig_sys_F),\n",
    "            s=256,\n",
    "            color='black',\n",
    "            label='System'\n",
    "        )\n",
    "\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-vHA1WL5uR2",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1700601509427,
     "user_tz": 480,
     "elapsed": 10,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     }
    }
   },
   "outputs": [],
   "source": [
    "H, W = len(optim_configs), len(system_configs)\n",
    "plt.rcParams['figure.figsize'] = (12.0, 20.0)\n",
    "fig, axs = plt.subplots(H, W)\n",
    "\n",
    "for h, (optim_config_name, _) in enumerate(optim_configs):\n",
    "    for w, (system_config_name, _) in enumerate(system_configs):\n",
    "        exp_name = system_config_name + optim_config_name + base_exp_name\n",
    "\n",
    "        r = result[optim_config_name][system_config_name]\n",
    "\n",
    "        training_loss, overfit_loss, validation_loss, irreducible_loss = (r[k].detach().cpu() for k in (\n",
    "            'training_loss',\n",
    "            'overfit_loss',\n",
    "            'validation_loss',\n",
    "            'irreducible_loss'\n",
    "        ))\n",
    "\n",
    "        x = torch.arange(training_loss.shape[-1], dtype=float)\n",
    "        irreducible_loss = irreducible_loss[:, :1]\n",
    "\n",
    "        axs[h, w].plot(x, torch.ones_like(x), linestyle='--', linewidth=0.5, color='black', label='normalized irreducible_loss')\n",
    "        for lname in ('training_loss', 'overfit_loss', 'validation_loss'):\n",
    "            loss = torch.mean(eval(lname), dim=1)\n",
    "            normalized_loss = loss / irreducible_loss\n",
    "\n",
    "            mean_normalized_loss = torch.mean(normalized_loss, dim=0)\n",
    "            min_normalized_loss = torch.min(normalized_loss, dim=0)\n",
    "            max_normalized_loss = torch.max(normalized_loss, dim=0)\n",
    "\n",
    "            axs[h, w].plot(x, min_normalized_loss.values, linewidth=0.5, label=f'mean normalized {lname}')\n",
    "        #     plt.fill_between(x, min_normalized_loss, max_normalized_loss, alpha=0.2)\n",
    "\n",
    "        axs[h, w].set_xlabel('Batch')\n",
    "        axs[h, w].set_ylabel('Normalized Loss')\n",
    "        axs[h, w].set_title(exp_name)\n",
    "        # axs[h, w].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ySyo5rO2k5sP",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1700601509427,
     "user_tz": 480,
     "elapsed": 10,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     }
    }
   },
   "outputs": [],
   "source": [
    "H, W = len(optim_configs), len(system_configs)\n",
    "plt.rcParams['figure.figsize'] = (12.0, 20.0)\n",
    "fig, axs = plt.subplots(H, W)\n",
    "\n",
    "tail = 10\n",
    "cutoff = 100\n",
    "for h, (optim_config_name, _) in enumerate(optim_configs):\n",
    "    for w, (system_config_name, _) in enumerate(system_configs):\n",
    "        exp_name = system_config_name + optim_config_name + base_exp_name\n",
    "\n",
    "        r = result[optim_config_name][system_config_name]\n",
    "\n",
    "        training_loss, overfit_loss, validation_loss, irreducible_loss = (r[k].detach().cpu() for k in (\n",
    "            'training_loss',\n",
    "            'overfit_loss',\n",
    "            'validation_loss',\n",
    "            'irreducible_loss'\n",
    "        ))\n",
    "\n",
    "        x = torch.arange(cutoff, training_loss.shape[-1], dtype=float)\n",
    "\n",
    "        axs[h, w].plot(x, torch.ones_like(x), linestyle='--', linewidth=1., color='black', label='normalized irreducible_loss')\n",
    "        normalized_overfit_loss = overfit_loss / irreducible_loss[:, :, None]\n",
    "        normalized_validation_loss = validation_loss / irreducible_loss[:, :, None]\n",
    "\n",
    "        N = len(irreducible_loss)\n",
    "        for n, (overfit_loss, validation_loss) in list(enumerate(zip(normalized_overfit_loss, normalized_validation_loss)))[::2]:\n",
    "            mean_overfit_loss = torch.mean(overfit_loss, dim=0)[cutoff:]\n",
    "            mean_validation_loss = torch.mean(validation_loss, dim=0)[cutoff:]\n",
    "\n",
    "            c = color(n, scale=N)\n",
    "            axs[h, w].plot(x, mean_overfit_loss, linewidth=1., color=c, label=f'Experiment {n}')\n",
    "            axs[h, w].plot(x, mean_validation_loss, linewidth=1., color=c)\n",
    "            axs[h, w].fill_between(x, mean_overfit_loss, mean_validation_loss, alpha=0.1, color=c)\n",
    "\n",
    "        axs[h, w].set_xlabel('Batch')\n",
    "        axs[h, w].set_ylabel('Normalized Loss')\n",
    "        axs[h, w].set_title(f'{exp_name} - Normalized Overfit Loss')\n",
    "        # axs[h, w].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vp7Qps54WBoq",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1700601509427,
     "user_tz": 480,
     "elapsed": 10,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     }
    }
   },
   "outputs": [],
   "source": [
    "H, W = len(optim_configs), len(system_configs)\n",
    "plt.rcParams['figure.figsize'] = (12.0, 20.0)\n",
    "fig, axs = plt.subplots(H, W)\n",
    "\n",
    "tail = 10\n",
    "for h, (optim_config_name, _) in enumerate(optim_configs):\n",
    "    for w, (system_config_name, _) in enumerate(system_configs):\n",
    "        exp_name = system_config_name + optim_config_name + base_exp_name\n",
    "\n",
    "        r = result[optim_config_name][system_config_name]\n",
    "\n",
    "        training_loss, overfit_loss, validation_loss, irreducible_loss = (r[k].detach().cpu() for k in (\n",
    "            'training_loss',\n",
    "            'overfit_loss',\n",
    "            'validation_loss',\n",
    "            'irreducible_loss'\n",
    "        ))\n",
    "\n",
    "        normalized_overfit_loss = overfit_loss / irreducible_loss[:, :, None]\n",
    "        normalized_validation_loss = validation_loss / irreducible_loss[:, :, None]\n",
    "\n",
    "        irreducible_, indices = torch.sort(irreducible_loss[:, 0])\n",
    "        tail_ = torch.mean(normalized_overfit_loss[:, :, -tail:], dim=-1)\n",
    "        mean_ = torch.mean(tail_, dim=1)[indices]\n",
    "        std_ = torch.std(tail_, dim=1)[indices]\n",
    "        min_ = tail_[torch.arange(len(mean_)), torch.argmin(tail_, dim=1)][indices]\n",
    "        max_ = tail_[torch.arange(len(mean_)), torch.argmax(tail_, dim=1)][indices]\n",
    "\n",
    "\n",
    "        axs_twinx = axs[h, w].twinx()\n",
    "        axs[h, w].plot(irreducible_, torch.zeros_like(mean_), linewidth=1., linestyle='--', marker='.', color='black', label=f'Mean loss')\n",
    "        axs_twinx.plot(irreducible_, mean_, linewidth=1., marker='.', color='blue', label='mean overfit loss')\n",
    "\n",
    "        axs[h, w].plot(irreducible_, min_ - mean_, linewidth=0.5, marker='.', color='turquoise')\n",
    "        # axs[h, w].plot(mean_, max_ - mean_, linewidth=0.5, marker='.', color='turquoise')\n",
    "\n",
    "        axs[h, w].fill_between(irreducible_, min_ - mean_, max_ - mean_, color='aquamarine', alpha=0.2, label='min-max')\n",
    "        axs[h, w].fill_between(irreducible_, -std_, std_, color='aquamarine', alpha=0.5, label='1 std')\n",
    "\n",
    "        axs[h, w].set_xlabel('Normalized mean loss per system')\n",
    "        axs[h, w].set_title(f'{exp_name}')\n",
    "        # axs[h, w].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1zBSjk02yXHW",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1700601509427,
     "user_tz": 480,
     "elapsed": 10,
     "user": {
      "displayName": "Wentinn Liao",
      "userId": "16122904268462266963"
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1lcHhNw_r_eetYfC5dd7wEm_Cgw7yytr7",
     "timestamp": 1698522777293
    },
    {
     "file_id": "1q9Qx12ZP6MjTkUXpm6XF0Tw68M9eUD0c",
     "timestamp": 1693268309398
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}